{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"full_mesh\": {\n",
      "    \"topology_json\": \"./topologies\\\\full_mesh\\\\topology.json\",\n",
      "    \"meta_json\": \"./topologies\\\\full_mesh\\\\topology_meta.json\",\n",
      "    \"connection_matrix_csv\": \"./topologies\\\\full_mesh\\\\connection_matrix.csv\",\n",
      "    \"graph_png\": \"./topologies\\\\full_mesh\\\\topology_graph.png\",\n",
      "    \"report_md\": \"./topologies\\\\full_mesh\\\\topology_report.md\"\n",
      "  },\n",
      "  \"clustered\": {\n",
      "    \"topology_json\": \"./topologies\\\\clustered\\\\topology.json\",\n",
      "    \"meta_json\": \"./topologies\\\\clustered\\\\topology_meta.json\",\n",
      "    \"connection_matrix_csv\": \"./topologies\\\\clustered\\\\connection_matrix.csv\",\n",
      "    \"graph_png\": \"./topologies\\\\clustered\\\\topology_graph.png\",\n",
      "    \"report_md\": \"./topologies\\\\clustered\\\\topology_report.md\"\n",
      "  },\n",
      "  \"sparse_ring\": {\n",
      "    \"topology_json\": \"./topologies\\\\sparse_ring\\\\topology.json\",\n",
      "    \"meta_json\": \"./topologies\\\\sparse_ring\\\\topology_meta.json\",\n",
      "    \"connection_matrix_csv\": \"./topologies\\\\sparse_ring\\\\connection_matrix.csv\",\n",
      "    \"graph_png\": \"./topologies\\\\sparse_ring\\\\topology_graph.png\",\n",
      "    \"report_md\": \"./topologies\\\\sparse_ring\\\\topology_report.md\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "HOODIE–style Topology Builder (enhanced, 3 variants)\n",
    "- Separate private/public capacities (not merged)\n",
    "- Connection matrix: shape (K, K+1), last column = MEC→Cloud\n",
    "- Styles: 'fully_connected' | 'skip_connections' | 'clustered'\n",
    "- Inputs per-second -> scaled by Delta to per-slot (HOODIE-compatible)\n",
    "\n",
    "Core outputs per topology: topology.json, topology_meta.json\n",
    "Extras per topology: connection_matrix.csv, topology_graph.png, topology_report.md\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "import numpy as np\n",
    "import json, os, time, hashlib, platform, getpass\n",
    "\n",
    "# Optional deps for graph/report\n",
    "try:\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    _GRAPH_OK = True\n",
    "except Exception:\n",
    "    _GRAPH_OK = False\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Data classes\n",
    "# =========================\n",
    "@dataclass\n",
    "class TopologyHyper:\n",
    "    number_of_servers: int              # K (MEC count)\n",
    "    time_step: float                    # Δ (sec per slot)\n",
    "\n",
    "    # ----- Compute capacities (per second); scaled by Δ -> per slot\n",
    "    private_cpu_min: Optional[float] = None\n",
    "    private_cpu_max: Optional[float] = None\n",
    "    public_cpu_min: Optional[float] = None\n",
    "    public_cpu_max: Optional[float] = None\n",
    "\n",
    "    # If you don't have separate ranges, provide totals + public_share in [0,1]\n",
    "    cpu_total_min: Optional[float] = None\n",
    "    cpu_total_max: Optional[float] = None\n",
    "    public_share: Optional[float] = None\n",
    "\n",
    "    # Cloud capacity (per second) — fixed or range\n",
    "    cloud_capacity: Optional[float] = None\n",
    "    cloud_capacity_min: Optional[float] = None\n",
    "    cloud_capacity_max: Optional[float] = None\n",
    "\n",
    "    # ----- Links (per second); scaled by Δ -> per slot\n",
    "    horiz_cap_min: float = 8.0         # MB/s (MEC↔MEC)\n",
    "    horiz_cap_max: float = 12.0\n",
    "    cloud_cap_min: float = 50.0        # MB/s (MEC→Cloud)\n",
    "    cloud_cap_max: float = 200.0\n",
    "\n",
    "    # ----- Generator\n",
    "    topology_type: str = \"skip_connections\"  # 'fully_connected' | 'skip_connections' | 'clustered'\n",
    "    skip_k: int = 5                           # for skip_connections\n",
    "    symmetric: bool = True\n",
    "\n",
    "    # For clustered\n",
    "    num_clusters: int = 3\n",
    "\n",
    "    # ----- RNG\n",
    "    seed: int = 2025\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def _fp(obj: dict) -> str:\n",
    "    s = json.dumps(obj, sort_keys=True).encode(\"utf-8\")\n",
    "    return hashlib.sha256(s).hexdigest()[:16]\n",
    "\n",
    "def _save_json(obj: dict, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "    return path\n",
    "\n",
    "def _save_text(text: str, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    return path\n",
    "\n",
    "def _save_matrix_csv(M: np.ndarray, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    K = M.shape[0]\n",
    "    header = [f\"mec_{i}\" for i in range(K)] + [\"cloud\"]\n",
    "    lines = [\",\".join([\"\"] + header)]\n",
    "    for i in range(K):\n",
    "        row = \",\".join([f\"mec_{i}\"] + [str(float(x)) for x in M[i, :]])\n",
    "        lines.append(row)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    return path\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Builders: compute & cloud\n",
    "# =========================\n",
    "def _sample_cloud_capacity(h: TopologyHyper, rng: np.random.Generator) -> float:\n",
    "    if h.cloud_capacity is not None:\n",
    "        return float(h.cloud_capacity)\n",
    "    if h.cloud_capacity_min is not None and h.cloud_capacity_max is not None:\n",
    "        return float(rng.uniform(h.cloud_capacity_min, h.cloud_capacity_max))\n",
    "    return 3.0e10  # fallback per-second\n",
    "\n",
    "def _build_compute_caps(h: TopologyHyper, rng: np.random.Generator) -> Tuple[List[float], List[float]]:\n",
    "    K = h.number_of_servers\n",
    "    if (h.private_cpu_min is not None and h.private_cpu_max is not None and\n",
    "        h.public_cpu_min  is not None and h.public_cpu_max  is not None):\n",
    "        priv_sec = rng.uniform(h.private_cpu_min, h.private_cpu_max, size=K)\n",
    "        pub_sec  = rng.uniform(h.public_cpu_min,  h.public_cpu_max,  size=K)\n",
    "    else:\n",
    "        tot_sec  = rng.uniform(float(h.cpu_total_min or 2.0e9),\n",
    "                               float(h.cpu_total_max or 3.0e9),\n",
    "                               size=K)\n",
    "        share = float(h.public_share if h.public_share is not None else 0.3)\n",
    "        pub_sec  = tot_sec * share\n",
    "        priv_sec = tot_sec - pub_sec\n",
    "\n",
    "    priv_slot = (priv_sec * h.time_step).astype(float).tolist()\n",
    "    pub_slot  = (pub_sec  * h.time_step).astype(float).tolist()\n",
    "    return priv_slot, pub_slot\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Builders: connection matrix\n",
    "# =========================\n",
    "def _set_vertical_mec_to_cloud(M: np.ndarray, h: TopologyHyper, rng: np.random.Generator) -> None:\n",
    "    K = h.number_of_servers\n",
    "    for i in range(K):\n",
    "        cap_sec = rng.uniform(h.cloud_cap_min, h.cloud_cap_max)\n",
    "        M[i, K] = float(cap_sec * h.time_step)\n",
    "\n",
    "def _build_connection_matrix_fully_connected(h: TopologyHyper, rng: np.random.Generator) -> np.ndarray:\n",
    "    K = h.number_of_servers\n",
    "    M = np.zeros((K, K + 1), dtype=float)\n",
    "    _set_vertical_mec_to_cloud(M, h, rng)\n",
    "\n",
    "    # fill upper-triangular, then mirror for symmetry\n",
    "    for i in range(K):\n",
    "        for j in range(i + 1, K):\n",
    "            cap_sec = rng.uniform(h.horiz_cap_min, h.horiz_cap_max)\n",
    "            cap_slot = float(cap_sec * h.time_step)\n",
    "            M[i, j] = cap_slot\n",
    "            M[j, i] = cap_slot  # symmetric\n",
    "    return M\n",
    "\n",
    "def _build_connection_matrix_skip_connections(h: TopologyHyper, rng: np.random.Generator) -> np.ndarray:\n",
    "    K = h.number_of_servers\n",
    "    M = np.zeros((K, K + 1), dtype=float)\n",
    "    _set_vertical_mec_to_cloud(M, h, rng)\n",
    "\n",
    "    step = max(1, int(h.skip_k))\n",
    "    for i in range(K):\n",
    "        for s in range(1, step + 1):\n",
    "            j = (i + s) % K\n",
    "            if i == j:\n",
    "                continue\n",
    "            cap_sec = rng.uniform(h.horiz_cap_min, h.horiz_cap_max)\n",
    "            cap_slot = float(cap_sec * h.time_step)\n",
    "            M[i, j] = cap_slot\n",
    "            if h.symmetric:\n",
    "                M[j, i] = cap_slot\n",
    "    return M\n",
    "\n",
    "def _build_connection_matrix_clustered(h: TopologyHyper, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Clustered = چند خوشه با اتصال کامل درون‌خوشه‌ای (متقارن) و بدون/حداقل اتصال بین‌خوشه‌ای.\n",
    "    \"\"\"\n",
    "    K = h.number_of_servers\n",
    "    C = max(1, int(h.num_clusters))\n",
    "    M = np.zeros((K, K + 1), dtype=float)\n",
    "    _set_vertical_mec_to_cloud(M, h, rng)\n",
    "\n",
    "    # تقسیم K به C خوشه با اندازه‌های تقریباً برابر\n",
    "    sizes = [K // C] * C\n",
    "    for i in range(K % C):\n",
    "        sizes[i] += 1\n",
    "    starts = np.cumsum([0] + sizes[:-1])\n",
    "    clusters = [(int(s), int(s + sz)) for s, sz in zip(starts, sizes)]  # [(start, end), ...]\n",
    "\n",
    "    # اتصال کامل و متقارن درون هر خوشه\n",
    "    for (a, b) in clusters:\n",
    "        for i in range(a, b):\n",
    "            for j in range(i + 1, b):\n",
    "                cap_sec = rng.uniform(h.horiz_cap_min, h.horiz_cap_max)\n",
    "                cap_slot = float(cap_sec * h.time_step)\n",
    "                M[i, j] = cap_slot\n",
    "                M[j, i] = cap_slot\n",
    "\n",
    "    # بین خوشه‌ها: صفر (می‌توان در صورت نیاز مقدار بسیار کم گذاشت)\n",
    "    return M\n",
    "\n",
    "def _build_connection_matrix(h: TopologyHyper, rng: np.random.Generator) -> np.ndarray:\n",
    "    if h.topology_type == \"fully_connected\":\n",
    "        return _build_connection_matrix_fully_connected(h, rng)\n",
    "    elif h.topology_type == \"clustered\":\n",
    "        return _build_connection_matrix_clustered(h, rng)\n",
    "    else:\n",
    "        return _build_connection_matrix_skip_connections(h, rng)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Graph drawing (optional)\n",
    "# =========================\n",
    "def _draw_graph_png(M: np.ndarray,\n",
    "                    out_png: str,\n",
    "                    title: str = \"MEC Graph (MB/slot)\",\n",
    "                    with_cloud: bool = True):\n",
    "    if not _GRAPH_OK:\n",
    "        return None\n",
    "\n",
    "    K = M.shape[0]\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # MEC nodes\n",
    "    for i in range(K):\n",
    "        G.add_node(f\"MEC_{i}\", layer=\"mec\")\n",
    "\n",
    "    # MEC↔MEC edges (only upper triangle to avoid duplicates)\n",
    "    for i in range(K):\n",
    "        for j in range(i + 1, K):\n",
    "            cap = max(M[i, j], M[j, i])\n",
    "            if cap > 0:\n",
    "                G.add_edge(f\"MEC_{i}\", f\"MEC_{j}\", weight=cap)\n",
    "\n",
    "    # Positions: circular for MEC\n",
    "    pos = nx.circular_layout([f\"MEC_{i}\" for i in range(K)])\n",
    "\n",
    "    # Optionally add cloud\n",
    "    if with_cloud:\n",
    "        G.add_node(\"CLOUD\", layer=\"cloud\")\n",
    "        pos[\"CLOUD\"] = np.array([0.0, 1.25])\n",
    "        for i in range(K):\n",
    "            cap_cloud = M[i, K]\n",
    "            if cap_cloud > 0:\n",
    "                G.add_edge(f\"MEC_{i}\", \"CLOUD\", weight=cap_cloud)\n",
    "\n",
    "    # Draw\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=[n for n, d in G.nodes(data=True) if d.get(\"layer\")==\"mec\"])\n",
    "    if with_cloud:\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=[\"CLOUD\"], node_shape=\"s\")\n",
    "\n",
    "    edges_mm = [(u,v) for u,v in G.edges() if \"CLOUD\" not in (u,v)]\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=edges_mm)\n",
    "\n",
    "    edges_mc = [(u,v) for u,v in G.edges() if \"CLOUD\" in (u,v)]\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=edges_mc, style=\"dashed\")\n",
    "\n",
    "    nx.draw_networkx_labels(G, pos, font_size=9)\n",
    "\n",
    "    edge_labels = {(u,v): f\"{G[u][v]['weight']:.1f}\" for u,v in G.edges()}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    os.makedirs(os.path.dirname(out_png), exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "    return out_png\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Report (Markdown)\n",
    "# =========================\n",
    "def _write_markdown_report(topo: dict, meta: dict, graph_png: Optional[str], out_md: str):\n",
    "    K = topo[\"number_of_servers\"]\n",
    "    units = meta.get(\"units\", {})\n",
    "    compute_unit = units.get(\"compute\", \"CPU cycles per slot\")\n",
    "    link_unit = units.get(\"links\", \"MB per slot\")\n",
    "    time_unit = units.get(\"time_step\", \"seconds\")\n",
    "\n",
    "    priv = topo[\"private_cpu_capacities\"]\n",
    "    pub  = topo[\"public_cpu_capacities\"]\n",
    "    cloud = topo[\"cloud_computational_capacity\"]\n",
    "\n",
    "    def s(lst):\n",
    "        if not lst: return \"n/a\"\n",
    "        arr = np.array(lst, dtype=float)\n",
    "        return f\"min={arr.min():.3g}, mean={arr.mean():.3g}, max={arr.max():.3g}\"\n",
    "\n",
    "    M = np.array(topo[\"connection_matrix\"], dtype=float)\n",
    "    horiz = M[:, :K]\n",
    "    vert  = M[:, K]\n",
    "\n",
    "    md = []\n",
    "    md.append(f\"# Topology Report\\n\")\n",
    "    md.append(f\"- **Servers (MEC)**: {K}\")\n",
    "    md.append(f\"- **Time step (Δ)**: {topo['time_step']} {time_unit}\")\n",
    "    md.append(f\"- **Topology type**: {topo.get('topology_type','n/a')}, \"\n",
    "              f\"**skip_k**: {topo.get('skip_k','-')}, **symmetric**: {topo.get('symmetric','-')}, \"\n",
    "              f\"**num_clusters**: {topo.get('num_clusters','-')}\")\n",
    "    md.append(\"\")\n",
    "    md.append(f\"## Compute Capacities ({compute_unit})\")\n",
    "    md.append(f\"- Private (per MEC): {s(priv)}\")\n",
    "    md.append(f\"- Public  (per MEC): {s(pub)}\")\n",
    "    md.append(f\"- Cloud (single): {cloud:.3g}\")\n",
    "    md.append(\"\")\n",
    "    md.append(f\"## Link Capacities ({link_unit})\")\n",
    "    md.append(f\"- Horizontal MEC↔MEC (non-zero entries): {int((horiz>0).sum())}\")\n",
    "    md.append(f\"- MEC→Cloud (length K): min={vert.min():.3g}, mean={vert.mean():.3g}, max={vert.max():.3g}\")\n",
    "    md.append(\"\")\n",
    "    if graph_png:\n",
    "        md.append(f\"## Graph\")\n",
    "        md.append(f\"![Topology Graph]({os.path.basename(graph_png)})\")\n",
    "        md.append(\"\")\n",
    "    md.append(\"## Notes\")\n",
    "    md.append(\"- Values are per slot; per-slot = per-second × Δ.\")\n",
    "    md.append(f\"- Units: compute={compute_unit}, links={link_unit}, time_step={time_unit}.\")\n",
    "    md_txt = \"\\n\".join(md)\n",
    "    _save_text(md_txt, out_md)\n",
    "    return out_md\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main builder\n",
    "# =========================\n",
    "def build_topology(h: TopologyHyper,\n",
    "                   out_topology: str = \"./topology/topology.json\",\n",
    "                   out_meta: str = \"./topology/topology_meta.json\") -> Dict[str, str]:\n",
    "    rng = np.random.default_rng(h.seed)\n",
    "\n",
    "    private_caps, public_caps = _build_compute_caps(h, rng)\n",
    "    cloud_cap_sec = _sample_cloud_capacity(h, rng)\n",
    "    cloud_cap = float(cloud_cap_sec * h.time_step)  # per-slot\n",
    "\n",
    "    M = _build_connection_matrix(h, rng)\n",
    "\n",
    "    topo = {\n",
    "        \"number_of_servers\": h.number_of_servers,\n",
    "        \"private_cpu_capacities\": private_caps,     # cycles/slot\n",
    "        \"public_cpu_capacities\": public_caps,       # cycles/slot\n",
    "        \"cloud_computational_capacity\": cloud_cap,  # cycles/slot\n",
    "        \"connection_matrix\": M.tolist(),            # MB/slot\n",
    "        \"time_step\": h.time_step,\n",
    "        \"topology_type\": h.topology_type,\n",
    "        \"skip_k\": h.skip_k,\n",
    "        \"symmetric\": h.symmetric,\n",
    "        \"num_clusters\": h.num_clusters\n",
    "    }\n",
    "    meta = {\n",
    "        \"generated_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"fingerprint\": _fp(topo),\n",
    "        \"env\": {\"python\": platform.python_version(), \"user\": getpass.getuser()},\n",
    "        \"units\": {\"compute\": \"CPU cycles per slot\", \"links\": \"MB per slot\", \"time_step\": \"seconds\"},\n",
    "        \"notes\": {\"inputs_unit\": {\"compute\": \"CPU cycles per second\", \"links\": \"MB per second\"},\n",
    "                  \"conversion\": \"per_slot = per_second * time_step\"}\n",
    "    }\n",
    "\n",
    "    _save_json(topo, out_topology)\n",
    "    _save_json(meta, out_meta)\n",
    "\n",
    "    out_dir = os.path.dirname(out_topology) or \".\"\n",
    "    cm_csv = os.path.join(out_dir, \"connection_matrix.csv\")\n",
    "    _save_matrix_csv(M, cm_csv)\n",
    "\n",
    "    graph_png = None\n",
    "    if _GRAPH_OK:\n",
    "        graph_png = os.path.join(out_dir, \"topology_graph.png\")\n",
    "        _draw_graph_png(M, graph_png, title=\"MEC Graph (MB/slot)\", with_cloud=True)\n",
    "\n",
    "    report_md = os.path.join(out_dir, \"topology_report.md\")\n",
    "    _write_markdown_report(topo, meta, graph_png, report_md)\n",
    "\n",
    "    return {\n",
    "        \"topology_json\": out_topology,\n",
    "        \"meta_json\": out_meta,\n",
    "        \"connection_matrix_csv\": cm_csv,\n",
    "        \"graph_png\": graph_png if graph_png else \"\",\n",
    "        \"report_md\": report_md\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Build from JSON hyperparams (optional)\n",
    "# =========================\n",
    "def build_from_hyperparameters_json(hparams_path: str,\n",
    "                                    out_dir: str = \"./topology\") -> Dict[str, str]:\n",
    "    with open(hparams_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        hp = json.load(f)\n",
    "\n",
    "    th = TopologyHyper(\n",
    "        number_of_servers = int(hp.get(\"number_of_servers\", 18)),\n",
    "        time_step         = float(hp.get(\"time_step\", 1.0)),\n",
    "        private_cpu_min   = hp.get(\"private_cpu_min\"),\n",
    "        private_cpu_max   = hp.get(\"private_cpu_max\"),\n",
    "        public_cpu_min    = hp.get(\"public_cpu_min\"),\n",
    "        public_cpu_max    = hp.get(\"public_cpu_max\"),\n",
    "        cpu_total_min     = hp.get(\"cpu_total_min\"),\n",
    "        cpu_total_max     = hp.get(\"cpu_total_max\"),\n",
    "        public_share      = hp.get(\"public_share\"),\n",
    "        cloud_capacity    = hp.get(\"cloud_capacity\"),\n",
    "        cloud_capacity_min= hp.get(\"cloud_capacity_min\"),\n",
    "        cloud_capacity_max= hp.get(\"cloud_capacity_max\"),\n",
    "        horiz_cap_min     = float(hp.get(\"horizontal_capacities_min\", 8.0)),\n",
    "        horiz_cap_max     = float(hp.get(\"horizontal_capacities_max\", 12.0)),\n",
    "        cloud_cap_min     = float(hp.get(\"cloud_capacities_min\", 50.0)),\n",
    "        cloud_cap_max     = float(hp.get(\"cloud_capacities_max\", 200.0)),\n",
    "        topology_type     = hp.get(\"topology_type\", \"skip_connections\"),\n",
    "        skip_k            = int(hp.get(\"skip_k\", 5)),\n",
    "        symmetric         = bool(hp.get(\"symmetric\", True)),\n",
    "        num_clusters      = int(hp.get(\"num_clusters\", 3)),\n",
    "        seed              = int(hp.get(\"seed\", 2025))\n",
    "    )\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    return build_topology(\n",
    "        th,\n",
    "        out_topology=os.path.join(out_dir, \"topology.json\"),\n",
    "        out_meta=os.path.join(out_dir, \"topology_meta.json\")\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Build 3 fixed, reproducible topologies (variants)\n",
    "# =========================\n",
    "def build_three_topologies_variants(\n",
    "    K: int,\n",
    "    delta: float,\n",
    "    seed_base: int,\n",
    "    out_root: str = \"./topologies\",\n",
    "    # Compute (per-second)\n",
    "    private_cpu_min: float | None = 1.2e9,\n",
    "    private_cpu_max: float | None = 1.8e9,\n",
    "    public_cpu_min:  float | None = 0.5e9,\n",
    "    public_cpu_max:  float | None = 0.9e9,\n",
    "    cpu_total_min:   float | None = None,\n",
    "    cpu_total_max:   float | None = None,\n",
    "    public_share:    float | None = None,\n",
    "    # Cloud (per-second)\n",
    "    cloud_capacity: float | None = 3.0e10,\n",
    "    cloud_capacity_min: float | None = None,\n",
    "    cloud_capacity_max: float | None = None,\n",
    "    # Links (per-second, MB/s)\n",
    "    horiz_cap_min: float = 8.0,\n",
    "    horiz_cap_max: float = 12.0,\n",
    "    cloud_cap_min: float = 80.0,\n",
    "    cloud_cap_max: float = 120.0,\n",
    "    # Cluster params\n",
    "    num_clusters: int = 3,\n",
    "):\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "    variants = [\n",
    "        dict(\n",
    "            name=\"full_mesh\",\n",
    "            h=TopologyHyper(\n",
    "                number_of_servers=K, time_step=delta,\n",
    "                private_cpu_min=private_cpu_min, private_cpu_max=private_cpu_max,\n",
    "                public_cpu_min=public_cpu_min,   public_cpu_max=public_cpu_max,\n",
    "                cpu_total_min=cpu_total_min, cpu_total_max=cpu_total_max, public_share=public_share,\n",
    "                cloud_capacity=cloud_capacity,\n",
    "                cloud_capacity_min=cloud_capacity_min, cloud_capacity_max=cloud_capacity_max,\n",
    "                horiz_cap_min=horiz_cap_min, horiz_cap_max=horiz_cap_max,\n",
    "                cloud_cap_min=cloud_cap_min, cloud_cap_max=cloud_cap_max,\n",
    "                topology_type=\"fully_connected\", skip_k=1, symmetric=True,\n",
    "                num_clusters=num_clusters,\n",
    "                seed=seed_base + 101\n",
    "            )\n",
    "        ),\n",
    "        dict(\n",
    "            name=\"clustered\",\n",
    "            h=TopologyHyper(\n",
    "                number_of_servers=K, time_step=delta,\n",
    "                private_cpu_min=private_cpu_min, private_cpu_max=private_cpu_max,\n",
    "                public_cpu_min=public_cpu_min,   public_cpu_max=public_cpu_max,\n",
    "                cpu_total_min=cpu_total_min, cpu_total_max=cpu_total_max, public_share=public_share,\n",
    "                cloud_capacity=cloud_capacity,\n",
    "                cloud_capacity_min=cloud_capacity_min, cloud_capacity_max=cloud_capacity_max,\n",
    "                horiz_cap_min=horiz_cap_min, horiz_cap_max=horiz_cap_max,\n",
    "                cloud_cap_min=cloud_cap_min, cloud_cap_max=cloud_cap_max,\n",
    "                topology_type=\"clustered\", symmetric=True,\n",
    "                num_clusters=num_clusters,\n",
    "                seed=seed_base + 202\n",
    "            )\n",
    "        ),\n",
    "        dict(\n",
    "            name=\"sparse_ring\",\n",
    "            h=TopologyHyper(\n",
    "                number_of_servers=K, time_step=delta,\n",
    "                private_cpu_min=private_cpu_min, private_cpu_max=private_cpu_max,\n",
    "                public_cpu_min=public_cpu_min,   public_cpu_max=public_cpu_max,\n",
    "                cpu_total_min=cpu_total_min, cpu_total_max=cpu_total_max, public_share=public_share,\n",
    "                cloud_capacity=cloud_capacity,\n",
    "                cloud_capacity_min=cloud_capacity_min, cloud_capacity_max=cloud_capacity_max,\n",
    "                horiz_cap_min=horiz_cap_min, horiz_cap_max=horiz_cap_max,\n",
    "                cloud_cap_min=cloud_cap_min, cloud_cap_max=cloud_cap_max,\n",
    "                topology_type=\"skip_connections\", skip_k=1, symmetric=True,  # ring\n",
    "                num_clusters=num_clusters,\n",
    "                seed=seed_base + 303\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    results: Dict[str, Dict[str, str]] = {}\n",
    "    for v in variants:\n",
    "        name = v[\"name\"]\n",
    "        h: TopologyHyper = v[\"h\"]\n",
    "        out_dir = os.path.join(out_root, name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        paths = build_topology(\n",
    "            h,\n",
    "            out_topology=os.path.join(out_dir, \"topology.json\"),\n",
    "            out_meta=os.path.join(out_dir, \"topology_meta.json\")\n",
    "        )\n",
    "        results[name] = paths\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Example multi-build run\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    K = 18\n",
    "    DELTA = 1.0\n",
    "    SEED_BASE = 20251027\n",
    "\n",
    "    out = build_three_topologies_variants(\n",
    "        K=K, delta=DELTA, seed_base=SEED_BASE,\n",
    "        private_cpu_min=1.2e9, private_cpu_max=1.8e9,\n",
    "        public_cpu_min=0.5e9,  public_cpu_max=0.9e9,\n",
    "        cloud_capacity=3.0e10,\n",
    "        horiz_cap_min=8.0, horiz_cap_max=12.0,\n",
    "        cloud_cap_min=80.0, cloud_cap_max=120.0,\n",
    "        num_clusters=3,\n",
    "        out_root=\"./topologies\"\n",
    "    )\n",
    "    print(json.dumps(out, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "HOODIE–style Topology Builder (enhanced)\n",
    "- Separate private/public capacities (not merged)\n",
    "- Connection matrix shape: (K, K+1), last column = MEC→Cloud\n",
    "- Styles: 'fully_connected' | 'skip_connections'\n",
    "- Inputs per-second -> scaled by Delta to per-slot (HOODIE-compatible)\n",
    "\n",
    "Extras (without changing the core structure):\n",
    "  * Save connection_matrix.csv\n",
    "  * Draw network graph as PNG (NetworkX + Matplotlib)\n",
    "  * Write a lightweight Markdown report\n",
    "\n",
    "Outputs (core): topology.json, topology_meta.json\n",
    "Extras: connection_matrix.csv, topology_graph.png, topology_report.md\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Optional\n",
    "import numpy as np\n",
    "import json, os, time, hashlib, platform, getpass\n",
    "\n",
    "# Optional deps for graph/report\n",
    "try:\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    _GRAPH_OK = True\n",
    "except Exception:\n",
    "    _GRAPH_OK = False\n",
    "\n",
    "# ----------------------------\n",
    "# Data classes\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class TopologyHyper:\n",
    "    number_of_servers: int              # K (MEC count)\n",
    "    time_step: float                    # Δ (sec per slot)\n",
    "\n",
    "    # ----- Compute capacities (per second); we scale by Δ -> per slot\n",
    "    private_cpu_min: Optional[float] = None\n",
    "    private_cpu_max: Optional[float] = None\n",
    "    public_cpu_min: Optional[float] = None\n",
    "    public_cpu_max: Optional[float] = None\n",
    "\n",
    "    # If you don't have separate ranges, provide totals + public_share in [0,1]\n",
    "    cpu_total_min: Optional[float] = None\n",
    "    cpu_total_max: Optional[float] = None\n",
    "    public_share: Optional[float] = None\n",
    "\n",
    "    # Cloud capacity (per second) — fixed or range\n",
    "    cloud_capacity: Optional[float] = None\n",
    "    cloud_capacity_min: Optional[float] = None\n",
    "    cloud_capacity_max: Optional[float] = None\n",
    "\n",
    "    # ----- Links (per second); we scale by Δ -> per slot\n",
    "    horiz_cap_min: float = 8.0         # MB/s (MEC↔MEC)\n",
    "    horiz_cap_max: float = 12.0\n",
    "    cloud_cap_min: float = 50.0        # MB/s (MEC→Cloud)\n",
    "    cloud_cap_max: float = 200.0\n",
    "\n",
    "    # ----- Generator\n",
    "    topology_type: str = \"skip_connections\"  # 'fully_connected' | 'skip_connections'\n",
    "    skip_k: int = 5\n",
    "    symmetric: bool = True\n",
    "\n",
    "    # ----- RNG\n",
    "    seed: int = 2025\n",
    "\n",
    "# ----------------------------\n",
    "# Utils\n",
    "# ----------------------------\n",
    "def _fp(obj: dict) -> str:\n",
    "    s = json.dumps(obj, sort_keys=True).encode(\"utf-8\")\n",
    "    return hashlib.sha256(s).hexdigest()[:16]\n",
    "\n",
    "def _save_json(obj: dict, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "    return path\n",
    "\n",
    "def _save_text(text: str, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    return path\n",
    "\n",
    "def _save_matrix_csv(M: np.ndarray, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    # header: mec_0,...,mec_{K-1}, cloud\n",
    "    K = M.shape[0]\n",
    "    header = [f\"mec_{i}\" for i in range(K)] + [\"cloud\"]\n",
    "    lines = [\",\".join([\"\"] + header)]\n",
    "    for i in range(K):\n",
    "        row = \",\".join([f\"mec_{i}\"] + [str(float(x)) for x in M[i, :]])\n",
    "        lines.append(row)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    return path\n",
    "\n",
    "# ----------------------------\n",
    "# Builders\n",
    "# ----------------------------\n",
    "def _sample_cloud_capacity(h: TopologyHyper, rng: np.random.Generator) -> float:\n",
    "    if h.cloud_capacity is not None:\n",
    "        return float(h.cloud_capacity)\n",
    "    if h.cloud_capacity_min is not None and h.cloud_capacity_max is not None:\n",
    "        return float(rng.uniform(h.cloud_capacity_min, h.cloud_capacity_max))\n",
    "    return 3.0e10  # fallback per-second\n",
    "\n",
    "def _build_compute_caps(h: TopologyHyper, rng: np.random.Generator):\n",
    "    K = h.number_of_servers\n",
    "    if (h.private_cpu_min is not None and h.private_cpu_max is not None and\n",
    "        h.public_cpu_min  is not None and h.public_cpu_max  is not None):\n",
    "        priv_sec = rng.uniform(h.private_cpu_min, h.private_cpu_max, size=K)\n",
    "        pub_sec  = rng.uniform(h.public_cpu_min,  h.public_cpu_max,  size=K)\n",
    "    else:\n",
    "        tot_sec  = rng.uniform(float(h.cpu_total_min or 2.0e9),\n",
    "                               float(h.cpu_total_max or 3.0e9),\n",
    "                               size=K)\n",
    "        share = float(h.public_share if h.public_share is not None else 0.3)\n",
    "        pub_sec  = tot_sec * share\n",
    "        priv_sec = tot_sec - pub_sec\n",
    "\n",
    "    priv_slot = (priv_sec * h.time_step).astype(float).tolist()\n",
    "    pub_slot  = (pub_sec  * h.time_step).astype(float).tolist()\n",
    "    return priv_slot, pub_slot\n",
    "\n",
    "def _build_connection_matrix(h: TopologyHyper, rng: np.random.Generator):\n",
    "    \"\"\"\n",
    "    Returns M of shape (K, K+1), MB/slot.\n",
    "    cols 0..K-1 : MEC↔MEC horizontal capacities\n",
    "    col  K      : MEC→Cloud vertical capacity\n",
    "    \"\"\"\n",
    "    K = h.number_of_servers\n",
    "    M = np.zeros((K, K + 1), dtype=float)\n",
    "\n",
    "    # vertical MEC→Cloud (per slot)\n",
    "    for i in range(K):\n",
    "        cap_sec = rng.uniform(h.cloud_cap_min, h.cloud_cap_max)\n",
    "        M[i, K] = float(cap_sec * h.time_step)\n",
    "\n",
    "    # horizontal MEC↔MEC (per slot)\n",
    "    if h.topology_type == \"fully_connected\":\n",
    "        for i in range(K):\n",
    "            for j in range(K):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                cap_sec = rng.uniform(h.horiz_cap_min, h.horiz_cap_max)\n",
    "                M[i, j] = float(cap_sec * h.time_step)\n",
    "        if h.symmetric:\n",
    "            M[:, :K] = np.maximum(M[:, :K], M[:, :K].T)\n",
    "    else:  # skip_connections\n",
    "        step = max(1, int(h.skip_k))\n",
    "        for i in range(K):\n",
    "            for s in range(1, step + 1):\n",
    "                j = (i + s) % K\n",
    "                if i == j:\n",
    "                    continue\n",
    "                cap_sec = rng.uniform(h.horiz_cap_min, h.horiz_cap_max)\n",
    "                M[i, j] = float(cap_sec * h.time_step)\n",
    "                if h.symmetric:\n",
    "                    M[j, i] = M[i, j]\n",
    "\n",
    "    return M\n",
    "\n",
    "# ----------------------------\n",
    "# Graph drawing (optional)\n",
    "# ----------------------------\n",
    "def _draw_graph_png(M: np.ndarray,\n",
    "                    out_png: str,\n",
    "                    title: str = \"MEC Graph (MB/slot)\",\n",
    "                    with_cloud: bool = True):\n",
    "    \"\"\"\n",
    "    Draw an undirected MEC↔MEC graph + (optionally) MEC→Cloud spokes.\n",
    "    Edge labels show capacity (MB/slot). Cloud drawn on top.\n",
    "    \"\"\"\n",
    "    if not _GRAPH_OK:\n",
    "        return None\n",
    "\n",
    "    K = M.shape[0]\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # MEC nodes\n",
    "    for i in range(K):\n",
    "        G.add_node(f\"MEC_{i}\", layer=\"mec\")\n",
    "\n",
    "    # MEC↔MEC edges (only upper triangle to avoid duplicates)\n",
    "    for i in range(K):\n",
    "        for j in range(i + 1, K):\n",
    "            cap = max(M[i, j], M[j, i])\n",
    "            if cap > 0:\n",
    "                G.add_edge(f\"MEC_{i}\", f\"MEC_{j}\", weight=cap)\n",
    "\n",
    "    # Positions: circular for MEC\n",
    "    pos = nx.circular_layout([f\"MEC_{i}\" for i in range(K)])\n",
    "\n",
    "    # Optionally add cloud as a separate node\n",
    "    if with_cloud:\n",
    "        G.add_node(\"CLOUD\", layer=\"cloud\")\n",
    "        # place cloud slightly above center\n",
    "        pos[\"CLOUD\"] = np.array([0.0, 1.25])\n",
    "        for i in range(K):\n",
    "            cap_cloud = M[i, K]\n",
    "            if cap_cloud > 0:\n",
    "                G.add_edge(f\"MEC_{i}\", \"CLOUD\", weight=cap_cloud)\n",
    "\n",
    "    # Draw\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=[n for n, d in G.nodes(data=True) if d.get(\"layer\")==\"mec\"])\n",
    "    if with_cloud:\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=[\"CLOUD\"], node_shape=\"s\")\n",
    "\n",
    "    # MEC↔MEC edges\n",
    "    edges_mm = [(u,v) for u,v in G.edges() if \"CLOUD\" not in (u,v)]\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=edges_mm)\n",
    "\n",
    "    # MEC→Cloud edges\n",
    "    edges_mc = [(u,v) for u,v in G.edges() if \"CLOUD\" in (u,v)]\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=edges_mc, style=\"dashed\")\n",
    "\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=9)\n",
    "\n",
    "    # Edge labels with capacities\n",
    "    edge_labels = {(u,v): f\"{G[u][v]['weight']:.1f}\" for u,v in G.edges()}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    os.makedirs(os.path.dirname(out_png), exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "    return out_png\n",
    "\n",
    "# ----------------------------\n",
    "# Report (Markdown)\n",
    "# ----------------------------\n",
    "def _write_markdown_report(topo: dict, meta: dict, graph_png: Optional[str], out_md: str):\n",
    "    K = topo[\"number_of_servers\"]\n",
    "    units = meta.get(\"units\", {})\n",
    "    compute_unit = units.get(\"compute\", \"CPU cycles per slot\")\n",
    "    link_unit = units.get(\"links\", \"MB per slot\")\n",
    "    time_unit = units.get(\"time_step\", \"seconds\")\n",
    "\n",
    "    priv = topo[\"private_cpu_capacities\"]\n",
    "    pub  = topo[\"public_cpu_capacities\"]\n",
    "    cloud = topo[\"cloud_computational_capacity\"]\n",
    "\n",
    "    # Simple summaries\n",
    "    def s(lst): \n",
    "        if not lst: return \"n/a\"\n",
    "        arr = np.array(lst, dtype=float)\n",
    "        return f\"min={arr.min():.3g}, mean={arr.mean():.3g}, max={arr.max():.3g}\"\n",
    "\n",
    "    M = np.array(topo[\"connection_matrix\"], dtype=float)\n",
    "    horiz = M[:, :K]\n",
    "    vert  = M[:, K]\n",
    "\n",
    "    md = []\n",
    "    md.append(f\"# Topology Report\\n\")\n",
    "    md.append(f\"- **Servers (MEC)**: {K}\")\n",
    "    md.append(f\"- **Time step (Δ)**: {topo['time_step']} {time_unit}\")\n",
    "    md.append(f\"- **Topology type**: {topo.get('topology_type','n/a')}, **skip_k**: {topo.get('skip_k','-')}, **symmetric**: {topo.get('symmetric','-')}\")\n",
    "    md.append(\"\")\n",
    "    md.append(f\"## Compute Capacities ({compute_unit})\")\n",
    "    md.append(f\"- Private (per MEC): {s(priv)}\")\n",
    "    md.append(f\"- Public  (per MEC): {s(pub)}\")\n",
    "    md.append(f\"- Cloud (single): {cloud:.3g}\")\n",
    "    md.append(\"\")\n",
    "    md.append(f\"## Link Capacities ({link_unit})\")\n",
    "    md.append(f\"- Horizontal MEC↔MEC (non-zero entries): {int((horiz>0).sum())}\")\n",
    "    md.append(f\"- MEC→Cloud (length K): min={vert.min():.3g}, mean={vert.mean():.3g}, max={vert.max():.3g}\")\n",
    "    md.append(\"\")\n",
    "    if graph_png:\n",
    "        md.append(f\"## Graph\")\n",
    "        md.append(f\"![Topology Graph]({os.path.basename(graph_png)})\")\n",
    "        md.append(\"\")\n",
    "    md.append(\"## Notes\")\n",
    "    md.append(\"- Values are per slot; per-slot = per-second × Δ.\")\n",
    "    md.append(f\"- Units: compute={compute_unit}, links={link_unit}, time_step={time_unit}.\")\n",
    "    md_txt = \"\\n\".join(md)\n",
    "    _save_text(md_txt, out_md)\n",
    "    return out_md\n",
    "\n",
    "# ----------------------------\n",
    "# Main builder\n",
    "# ----------------------------\n",
    "def build_topology(h: TopologyHyper,\n",
    "                   out_topology: str = \"./topology/topology.json\",\n",
    "                   out_meta: str = \"./topology/topology_meta.json\") -> Dict[str, str]:\n",
    "    rng = np.random.default_rng(h.seed)\n",
    "\n",
    "    # compute\n",
    "    private_caps, public_caps = _build_compute_caps(h, rng)\n",
    "    cloud_cap_sec = _sample_cloud_capacity(h, rng)\n",
    "    cloud_cap = float(cloud_cap_sec * h.time_step)  # per-slot\n",
    "\n",
    "    # links\n",
    "    M = _build_connection_matrix(h, rng)\n",
    "\n",
    "    # HOODIE-compatible payload\n",
    "    topo = {\n",
    "        \"number_of_servers\": h.number_of_servers,\n",
    "        \"private_cpu_capacities\": private_caps,     # cycles/slot\n",
    "        \"public_cpu_capacities\": public_caps,       # cycles/slot\n",
    "        \"cloud_computational_capacity\": cloud_cap,  # cycles/slot\n",
    "        \"connection_matrix\": M.tolist(),            # MB/slot\n",
    "        \"time_step\": h.time_step,\n",
    "        \"topology_type\": h.topology_type,\n",
    "        \"skip_k\": h.skip_k,\n",
    "        \"symmetric\": h.symmetric\n",
    "    }\n",
    "    meta = {\n",
    "        \"generated_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"fingerprint\": _fp(topo),\n",
    "        \"env\": {\"python\": platform.python_version(), \"user\": getpass.getuser()},\n",
    "        \"units\": {\n",
    "            \"compute\": \"CPU cycles per slot\",\n",
    "            \"links\": \"MB per slot\",\n",
    "            \"time_step\": \"seconds\"\n",
    "        },\n",
    "        \"notes\": {\n",
    "            \"inputs_unit\": {\"compute\": \"CPU cycles per second\", \"links\": \"MB per second\"},\n",
    "            \"conversion\": \"per_slot = per_second * time_step\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save core outputs\n",
    "    _save_json(topo, out_topology)\n",
    "    _save_json(meta, out_meta)\n",
    "\n",
    "    # Extras (do NOT change core structure)\n",
    "    out_dir = os.path.dirname(out_topology) or \".\"\n",
    "    cm_csv = os.path.join(out_dir, \"connection_matrix.csv\")\n",
    "    _save_matrix_csv(M, cm_csv)\n",
    "\n",
    "    graph_png = None\n",
    "    if _GRAPH_OK:\n",
    "        graph_png = os.path.join(out_dir, \"topology_graph.png\")\n",
    "        _draw_graph_png(M, graph_png, title=\"MEC Graph (MB/slot)\", with_cloud=True)\n",
    "\n",
    "    report_md = os.path.join(out_dir, \"topology_report.md\")\n",
    "    _write_markdown_report(topo, meta, graph_png, report_md)\n",
    "\n",
    "    return {\n",
    "        \"topology_json\": out_topology,\n",
    "        \"meta_json\": out_meta,\n",
    "        \"connection_matrix_csv\": cm_csv,\n",
    "        \"graph_png\": graph_png if graph_png else \"\",\n",
    "        \"report_md\": report_md\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# Quick CLI example\n",
    "# ----------------------------\n",
    "def build_from_hyperparameters_json(hparams_path: str,\n",
    "                                    out_dir: str = \"./topology\") -> Dict[str, str]:\n",
    "    with open(hparams_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        hp = json.load(f)\n",
    "\n",
    "    th = TopologyHyper(\n",
    "        number_of_servers = int(hp.get(\"number_of_servers\", 18)),\n",
    "        time_step         = float(hp.get(\"time_step\", 1.0)),\n",
    "        private_cpu_min   = hp.get(\"private_cpu_min\"),\n",
    "        private_cpu_max   = hp.get(\"private_cpu_max\"),\n",
    "        public_cpu_min    = hp.get(\"public_cpu_min\"),\n",
    "        public_cpu_max    = hp.get(\"public_cpu_max\"),\n",
    "        cpu_total_min     = hp.get(\"cpu_total_min\"),\n",
    "        cpu_total_max     = hp.get(\"cpu_total_max\"),\n",
    "        public_share      = hp.get(\"public_share\"),\n",
    "        cloud_capacity    = hp.get(\"cloud_capacity\"),\n",
    "        cloud_capacity_min= hp.get(\"cloud_capacity_min\"),\n",
    "        cloud_capacity_max= hp.get(\"cloud_capacity_max\"),\n",
    "        horiz_cap_min     = float(hp.get(\"horizontal_capacities_min\", 8.0)),\n",
    "        horiz_cap_max     = float(hp.get(\"horizontal_capacities_max\", 12.0)),\n",
    "        cloud_cap_min     = float(hp.get(\"cloud_capacities_min\", 50.0)),\n",
    "        cloud_cap_max     = float(hp.get(\"cloud_capacities_max\", 200.0)),\n",
    "        topology_type     = hp.get(\"topology_type\", \"skip_connections\"),\n",
    "        skip_k            = int(hp.get(\"skip_k\", 5)),\n",
    "        symmetric         = bool(hp.get(\"symmetric\", True)),\n",
    "        seed              = int(hp.get(\"seed\", 2025))\n",
    "    )\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    return build_topology(\n",
    "        th,\n",
    "        out_topology=os.path.join(out_dir, \"topology.json\"),\n",
    "        out_meta=os.path.join(out_dir, \"topology_meta.json\")\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    H = TopologyHyper(\n",
    "        number_of_servers=18,\n",
    "        time_step=1.0,\n",
    "        private_cpu_min=1.2e9, private_cpu_max=1.8e9,   # cycles/s\n",
    "        public_cpu_min=0.5e9,  public_cpu_max=0.9e9,    # cycles/s\n",
    "        cloud_capacity=3.0e10,                          # cycles/s\n",
    "        horiz_cap_min=8.0, horiz_cap_max=12.0,          # MB/s\n",
    "        cloud_cap_min=80.0, cloud_cap_max=120.0,        # MB/s\n",
    "        topology_type=\"skip_connections\", skip_k=5, symmetric=True,\n",
    "        seed=20251026\n",
    "    )\n",
    "    build_topology(H, out_topology=\"./topology/topology.json\",\n",
    "                      out_meta=\"./topology/topology_meta.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
