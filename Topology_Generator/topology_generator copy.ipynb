{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# HOODIE–style Topology Builder (enhanced, 3 variants)\n",
    "# - Separate private/public capacities (not merged)\n",
    "# - Connection matrix: shape (K, K+1), last column = MEC→Cloud\n",
    "# - Styles: 'fully_connected' | 'skip_connections' (k-nearest ring) | 'clustered'\n",
    "# - Inputs per-second -> scaled by Delta to per-slot (HOODIE-compatible)\n",
    "\n",
    "# Core outputs per topology: topology.json, topology_meta.json\n",
    "# Extras per topology: connection_matrix.csv, topology_graph.png, topology_report.md\n",
    "\n",
    "# Fixes/Improvements:\n",
    "# - Enforce symmetry + zero diagonal (MEC↔MEC)\n",
    "# - Add parameter asserts\n",
    "# - Add hyperparameters dump to meta\n",
    "# - Add link density to report\n",
    "# - Optional weak inter-cluster links via inter_cluster_frac\n",
    "# - Document skip_connections semantics in meta\n",
    "# \"\"\"\n",
    "\n",
    "# from __future__ import annotations\n",
    "# from dataclasses import dataclass, asdict\n",
    "# from typing import Dict, Optional, List, Tuple\n",
    "# import numpy as np\n",
    "# import json, os, time, hashlib, platform, getpass\n",
    "\n",
    "# # Optional deps for graph/report\n",
    "# try:\n",
    "#     import networkx as nx\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     _GRAPH_OK = True\n",
    "# except Exception:\n",
    "#     _GRAPH_OK = False\n",
    "\n",
    "# # =========================\n",
    "# # Data classes\n",
    "# # =========================\n",
    "# @dataclass\n",
    "# class TopologyHyper:\n",
    "#     number_of_servers: int              # K (MEC count)\n",
    "#     time_step: float                    # Δ (sec per slot)\n",
    "\n",
    "#     # ----- Compute capacities (per second); scaled by Δ -> per slot\n",
    "#     private_cpu_min: Optional[float] = None\n",
    "#     private_cpu_max: Optional[float] = None\n",
    "#     public_cpu_min: Optional[float] = None\n",
    "#     public_cpu_max: Optional[float] = None\n",
    "\n",
    "#     # If you don't have separate ranges, provide totals + public_share in [0,1]\n",
    "#     cpu_total_min: Optional[float] = None\n",
    "#     cpu_total_max: Optional[float] = None\n",
    "#     public_share: Optional[float] = None\n",
    "\n",
    "#     # Cloud capacity (per second) — fixed or range\n",
    "#     cloud_capacity: Optional[float] = None\n",
    "#     cloud_capacity_min: Optional[float] = None\n",
    "#     cloud_capacity_max: Optional[float] = None\n",
    "\n",
    "#     # ----- Links (per second); scaled by Δ -> per slot\n",
    "#     horiz_cap_min: float = 8.0         # MB/s (MEC↔MEC)\n",
    "#     horiz_cap_max: float = 12.0\n",
    "#     cloud_cap_min: float = 50.0        # MB/s (MEC→Cloud)\n",
    "#     cloud_cap_max: float = 200.0\n",
    "\n",
    "#     # ----- Generator\n",
    "#     topology_type: str = \"skip_connections\"  # 'fully_connected' | 'skip_connections' | 'clustered'\n",
    "#     skip_k: int = 5                           # for skip_connections (k-nearest ring)\n",
    "#     symmetric: bool = True\n",
    "\n",
    "#     # For clustered\n",
    "#     num_clusters: int = 3\n",
    "#     inter_cluster_frac: float = 0.0  # fraction of horiz_cap_min for weak inter-cluster links (0.0 => none)\n",
    "\n",
    "#     # ----- RNG\n",
    "#     seed: int = 2025\n",
    "\n",
    "# # =========================\n",
    "# # Utils\n",
    "# # =========================\n",
    "# def _fp(obj: dict) -> str:\n",
    "#     s = json.dumps(obj, sort_keys=True).encode(\"utf-8\")\n",
    "#     return hashlib.sha256(s).hexdigest()[:16]\n",
    "\n",
    "# def _save_json(obj: dict, path: str) -> str:\n",
    "#     os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "#     with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "#     return path\n",
    "\n",
    "# def _save_text(text: str, path: str) -> str:\n",
    "#     os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "#     with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(text)\n",
    "#     return path\n",
    "\n",
    "# def _save_matrix_csv(M: np.ndarray, path: str) -> str:\n",
    "#     os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "#     K = M.shape[0]\n",
    "#     header = [f\"mec_{i}\" for i in range(K)] + [\"cloud\"]\n",
    "#     lines = [\",\".join([\"\"] + header)]\n",
    "#     for i in range(K):\n",
    "#         row = \",\".join([f\"mec_{i}\"] + [str(float(x)) for x in M[i, :]])\n",
    "#         lines.append(row)\n",
    "#     with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(\"\\n\".join(lines))\n",
    "#     return path\n",
    "\n",
    "# # =========================\n",
    "# # Validations\n",
    "# # =========================\n",
    "# def _validate_h(h: TopologyHyper) -> None:\n",
    "#     assert h.number_of_servers > 0 and h.time_step > 0\n",
    "#     assert h.horiz_cap_max >= h.horiz_cap_min and h.cloud_cap_max >= h.cloud_cap_min\n",
    "#     if h.private_cpu_min is not None:\n",
    "#         assert h.private_cpu_max is not None and h.private_cpu_max >= h.private_cpu_min\n",
    "#         assert h.public_cpu_min  is not None and h.public_cpu_max  is not None and h.public_cpu_max >= h.public_cpu_min\n",
    "#     if h.cpu_total_min is not None:\n",
    "#         assert h.cpu_total_max is not None and h.cpu_total_max >= h.cpu_total_min\n",
    "#         share = h.public_share if h.public_share is not None else 0.3\n",
    "#         assert 0.0 <= share <= 1.0\n",
    "#     assert h.num_clusters >= 1\n",
    "#     assert h.inter_cluster_frac >= 0.0\n",
    "\n",
    "# # =========================\n",
    "# # Builders: compute & cloud\n",
    "# # =========================\n",
    "# def _sample_cloud_capacity(h: TopologyHyper, rng: np.random.Generator) -> float:\n",
    "#     if h.cloud_capacity is not None:\n",
    "#         return float(h.cloud_capacity)\n",
    "#     if h.cloud_capacity_min is not None and h.cloud_capacity_max is not None:\n",
    "#         return float(rng.uniform(h.cloud_capacity_min, h.cloud_capacity_max))\n",
    "#     return 3.0e10  # fallback per-second\n",
    "\n",
    "# def _build_compute_caps(h: TopologyHyper, rng: np.random.Generator) -> Tuple[List[float], List[float]]:\n",
    "#     K = h.number_of_servers\n",
    "#     if (h.private_cpu_min is not None and h.private_cpu_max is not None and\n",
    "#         h.public_cpu_min  is not None and h.public_cpu_max  is not None):\n",
    "#         priv_sec = rng.uniform(h.private_cpu_min, h.private_cpu_max, size=K)\n",
    "#         pub_sec  = rng.uniform(h.public_cpu_min,  h.public_cpu_max,  size=K)\n",
    "#     else:\n",
    "#         tot_sec  = rng.uniform(float(h.cpu_total_min or 2.0e9),\n",
    "#                                float(h.cpu_total_max or 3.0e9),\n",
    "#                                size=K)\n",
    "#         share = float(h.public_share if h.public_share is not None else 0.3)\n",
    "#         pub_sec  = tot_sec * share\n",
    "#         priv_sec = tot_sec - pub_sec\n",
    "\n",
    "#     priv_slot = (priv_sec * h.time_step).astype(float).tolist()\n",
    "#     pub_slot  = (pub_sec  * h.time_step).astype(float).tolist()\n",
    "#     return priv_slot, pub_slot\n",
    "\n",
    "# # =========================\n",
    "# # Builders: connection matrix\n",
    "# # =========================\n",
    "# def _set_vertical_mec_to_cloud(M: np.ndarray, h: TopologyHyper, rng: np.random.Generator) -> None:\n",
    "#     K = h.number_of_servers\n",
    "#     for i in range(K):\n",
    "#         cap_sec = rng.uniform(h.cloud_cap_min, h.cloud_cap_max)\n",
    "#         M[i, K] = float(cap_sec * h.time_step)\n",
    "\n",
    "# def _build_connection_matrix_fully_connected(h: TopologyHyper, rng: np.random.Generator) -> np.ndarray:\n",
    "#     K = h.number_of_servers\n",
    "#     M = np.zeros((K, K + 1), dtype=float)\n",
    "#     _set_vertical_mec_to_cloud(M, h, rng)\n",
    "\n",
    "#     # fill upper-triangular, then mirror for symmetry\n",
    "#     for i in range(K):\n",
    "#         for j in range(i + 1, K):\n",
    "#             cap_sec = rng.uniform(h.horiz_cap_min, h.horiz_cap_max)\n",
    "#             cap_slot = float(cap_sec * h.time_step)\n",
    "#             M[i, j] = cap_slot\n",
    "#             M[j, i] = cap_slot  # symmetric\n",
    "#     return M\n",
    "\n",
    "# def _build_connection_matrix_skip_connections(h: TopologyHyper, rng: np.random.Generator) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     k-nearest ring on a circular index: each node connects to next 'skip_k' neighbors.\n",
    "#     \"\"\"\n",
    "#     K = h.number_of_servers\n",
    "#     M = np.zeros((K, K + 1), dtype=float)\n",
    "#     _set_vertical_mec_to_cloud(M, h, rng)\n",
    "\n",
    "#     step = max(1, int(h.skip_k))\n",
    "#     for i in range(K):\n",
    "#         for s in range(1, step + 1):\n",
    "#             j = (i + s) % K\n",
    "#             if i == j:\n",
    "#                 continue\n",
    "#             cap_sec = rng.uniform(h.horiz_cap_min, h.horiz_cap_max)\n",
    "#             cap_slot = float(cap_sec * h.time_step)\n",
    "#             M[i, j] = cap_slot\n",
    "#             if h.symmetric:\n",
    "#                 M[j, i] = cap_slot\n",
    "#     return M\n",
    "\n",
    "# def _build_connection_matrix_clustered(h: TopologyHyper, rng: np.random.Generator) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Clustered = several clusters with fully-connected intra-cluster links (symmetric),\n",
    "#     and zero/weak inter-cluster connections controlled by inter_cluster_frac.\n",
    "#     \"\"\"\n",
    "#     K = h.number_of_servers\n",
    "#     C = max(1, int(h.num_clusters))\n",
    "#     M = np.zeros((K, K + 1), dtype=float)\n",
    "#     _set_vertical_mec_to_cloud(M, h, rng)\n",
    "\n",
    "#     # Divide K into C clusters with approximately equal sizes\n",
    "#     sizes = [K // C] * C\n",
    "#     for i in range(K % C):\n",
    "#         sizes[i] += 1\n",
    "#     starts = np.cumsum([0] + sizes[:-1])\n",
    "#     clusters = [(int(s), int(s + sz)) for s, sz in zip(starts, sizes)]  # [(start, end), ...]\n",
    "\n",
    "#     # Fully connected and symmetric links within each cluster\n",
    "#     for (a, b) in clusters:\n",
    "#         for i in range(a, b):\n",
    "#             for j in range(i + 1, b):\n",
    "#                 cap_sec = rng.uniform(h.horiz_cap_min, h.horiz_cap_max)\n",
    "#                 cap_slot = float(cap_sec * h.time_step)\n",
    "#                 M[i, j] = cap_slot\n",
    "#                 M[j, i] = cap_slot\n",
    "\n",
    "#     # Weak inter-cluster links if requested\n",
    "#     if h.inter_cluster_frac > 0.0:\n",
    "#         weak = float(h.horiz_cap_min * h.inter_cluster_frac * h.time_step)\n",
    "#         for c1 in range(len(clusters)):\n",
    "#             for c2 in range(c1 + 1, len(clusters)):\n",
    "#                 a1, b1 = clusters[c1]\n",
    "#                 a2, b2 = clusters[c2]\n",
    "#                 i = a1   # representative node of cluster 1\n",
    "#                 j = a2   # representative node of cluster 2\n",
    "#                 if i != j:\n",
    "#                     M[i, j] = max(M[i, j], weak)\n",
    "#                     if h.symmetric:\n",
    "#                         M[j, i] = max(M[j, i], weak)\n",
    "\n",
    "#     return M\n",
    "\n",
    "# def _build_connection_matrix(h: TopologyHyper, rng: np.random.Generator) -> np.ndarray:\n",
    "#     if h.topology_type == \"fully_connected\":\n",
    "#         M = _build_connection_matrix_fully_connected(h, rng)\n",
    "#     elif h.topology_type == \"clustered\":\n",
    "#         M = _build_connection_matrix_clustered(h, rng)\n",
    "#     else:\n",
    "#         M = _build_connection_matrix_skip_connections(h, rng)\n",
    "\n",
    "#     K = h.number_of_servers\n",
    "#     if h.symmetric:\n",
    "#         M[:, :K] = np.maximum(M[:, :K], M[:, :K].T)\n",
    "#     np.fill_diagonal(M[:, :K], 0.0)\n",
    "#     return M\n",
    "\n",
    "# # =========================\n",
    "# # Graph drawing (optional)\n",
    "# # =========================\n",
    "# def _draw_graph_png(M: np.ndarray,\n",
    "#                     out_png: str,\n",
    "#                     title: str = \"MEC Graph (MB/slot)\",\n",
    "#                     with_cloud: bool = True):\n",
    "#     if not _GRAPH_OK:\n",
    "#         return None\n",
    "\n",
    "#     K = M.shape[0]\n",
    "#     import networkx as nx\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     G = nx.Graph()\n",
    "\n",
    "#     # MEC nodes\n",
    "#     for i in range(K):\n",
    "#         G.add_node(f\"MEC_{i}\", layer=\"mec\")\n",
    "\n",
    "#     # MEC↔MEC edges (only upper triangle to avoid duplicates)\n",
    "#     for i in range(K):\n",
    "#         for j in range(i + 1, K):\n",
    "#             cap = max(M[i, j], M[j, i])\n",
    "#             if cap > 0:\n",
    "#                 G.add_edge(f\"MEC_{i}\", f\"MEC_{j}\", weight=cap)\n",
    "\n",
    "#     # Positions: circular for MEC\n",
    "#     pos = nx.circular_layout([f\"MEC_{i}\" for i in range(K)])\n",
    "\n",
    "#     # Optionally add cloud\n",
    "#     if with_cloud:\n",
    "#         G.add_node(\"CLOUD\", layer=\"cloud\")\n",
    "#         pos[\"CLOUD\"] = np.array([0.0, 1.25])\n",
    "#         for i in range(K):\n",
    "#             cap_cloud = M[i, K]\n",
    "#             if cap_cloud > 0:\n",
    "#                 G.add_edge(f\"MEC_{i}\", \"CLOUD\", weight=cap_cloud)\n",
    "\n",
    "#     # Draw\n",
    "#     plt.figure(figsize=(7, 7))\n",
    "#     nx.draw_networkx_nodes(G, pos, nodelist=[n for n, d in G.nodes(data=True) if d.get(\"layer\")==\"mec\"])\n",
    "#     if with_cloud:\n",
    "#         nx.draw_networkx_nodes(G, pos, nodelist=[\"CLOUD\"], node_shape=\"s\")\n",
    "\n",
    "#     edges_mm = [(u,v) for u,v in G.edges() if \"CLOUD\" not in (u,v)]\n",
    "#     nx.draw_networkx_edges(G, pos, edgelist=edges_mm)\n",
    "\n",
    "#     edges_mc = [(u,v) for u,v in G.edges() if \"CLOUD\" in (u,v)]\n",
    "#     nx.draw_networkx_edges(G, pos, edgelist=edges_mc, style=\"dashed\")\n",
    "\n",
    "#     nx.draw_networkx_labels(G, pos, font_size=9)\n",
    "\n",
    "#     edge_labels = {(u,v): f\"{G[u][v]['weight']:.1f}\" for u,v in G.edges()}\n",
    "#     nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "\n",
    "#     plt.title(title)\n",
    "#     plt.axis(\"off\")\n",
    "#     os.makedirs(os.path.dirname(out_png), exist_ok=True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(out_png, dpi=160)\n",
    "#     plt.close()\n",
    "#     return out_png\n",
    "\n",
    "# # =========================\n",
    "# # Report (Markdown)\n",
    "# # =========================\n",
    "# def _write_markdown_report(topo: dict, meta: dict, graph_png: Optional[str], out_md: str):\n",
    "#     K = topo[\"number_of_servers\"]\n",
    "#     units = meta.get(\"units\", {})\n",
    "#     compute_unit = units.get(\"compute\", \"CPU cycles per slot\")\n",
    "#     link_unit = units.get(\"links\", \"MB per slot\")\n",
    "#     time_unit = units.get(\"time_step\", \"seconds\")\n",
    "\n",
    "#     priv = topo[\"private_cpu_capacities\"]\n",
    "#     pub  = topo[\"public_cpu_capacities\"]\n",
    "#     cloud = topo[\"cloud_computational_capacity\"]\n",
    "\n",
    "#     def s(lst):\n",
    "#         if not lst: return \"n/a\"\n",
    "#         arr = np.array(lst, dtype=float)\n",
    "#         return f\"min={arr.min():.3g}, mean={arr.mean():.3g}, max={arr.max():.3g}\"\n",
    "\n",
    "#     M = np.array(topo[\"connection_matrix\"], dtype=float)\n",
    "#     horiz = M[:, :K]\n",
    "#     vert  = M[:, K]\n",
    "#     nonzero = int((horiz > 0).sum())\n",
    "#     density = nonzero / float(K * (K - 1)) if K > 1 else 0.0\n",
    "\n",
    "#     md = []\n",
    "#     md.append(f\"# Topology Report\\n\")\n",
    "#     md.append(f\"- **Servers (MEC)**: {K}\")\n",
    "#     md.append(f\"- **Time step (Δ)**: {topo['time_step']} {time_unit}\")\n",
    "#     md.append(f\"- **Topology type**: {topo.get('topology_type','n/a')}, \"\n",
    "#               f\"**skip_k**: {topo.get('skip_k','-')}, **symmetric**: {topo.get('symmetric','-')}, \"\n",
    "#               f\"**num_clusters**: {topo.get('num_clusters','-')}\")\n",
    "#     md.append(\"\")\n",
    "#     md.append(f\"## Compute Capacities ({compute_unit})\")\n",
    "#     md.append(f\"- Private (per MEC): {s(priv)}\")\n",
    "#     md.append(f\"- Public  (per MEC): {s(pub)}\")\n",
    "#     md.append(f\"- Cloud (single): {cloud:.3g}\")\n",
    "#     md.append(\"\")\n",
    "#     md.append(f\"## Link Capacities ({link_unit})\")\n",
    "#     md.append(f\"- Horizontal MEC↔MEC (non-zero entries): {nonzero} (density={density:.3f})\")\n",
    "#     md.append(f\"- MEC→Cloud (length K): min={vert.min():.3g}, mean={vert.mean():.3g}, max={vert.max():.3g}\")\n",
    "#     md.append(\"\")\n",
    "#     if graph_png:\n",
    "#         md.append(f\"## Graph\")\n",
    "#         md.append(f\"![Topology Graph]({os.path.basename(graph_png)})\")\n",
    "#         md.append(\"\")\n",
    "#     md.append(\"## Notes\")\n",
    "#     md.append(\"- Values are per slot; per-slot = per-second × Δ.\")\n",
    "#     md.append(f\"- Units: compute={compute_unit}, links={link_unit}, time_step={time_unit}.\")\n",
    "#     md_txt = \"\\n\".join(md)\n",
    "#     _save_text(md_txt, out_md)\n",
    "#     return out_md\n",
    "\n",
    "# # =========================\n",
    "# # Main builder\n",
    "# # =========================\n",
    "# def build_topology(h: TopologyHyper,\n",
    "#                    out_topology: str = \"./topology/topology.json\",\n",
    "#                    out_meta: str = \"./topology/topology_meta.json\") -> Dict[str, str]:\n",
    "#     _validate_h(h)\n",
    "#     rng = np.random.default_rng(h.seed)\n",
    "\n",
    "#     private_caps, public_caps = _build_compute_caps(h, rng)\n",
    "#     cloud_cap_sec = _sample_cloud_capacity(h, rng)\n",
    "#     cloud_cap = float(cloud_cap_sec * h.time_step)  # per-slot\n",
    "\n",
    "#     M = _build_connection_matrix(h, rng)\n",
    "\n",
    "#     topo = {\n",
    "#         \"number_of_servers\": h.number_of_servers,\n",
    "#         \"private_cpu_capacities\": private_caps,     # cycles/slot\n",
    "#         \"public_cpu_capacities\": public_caps,       # cycles/slot\n",
    "#         \"cloud_computational_capacity\": cloud_cap,  # cycles/slot\n",
    "#         \"connection_matrix\": M.tolist(),            # MB/slot\n",
    "#         \"time_step\": h.time_step,\n",
    "#         \"topology_type\": h.topology_type,\n",
    "#         \"skip_k\": h.skip_k,\n",
    "#         \"symmetric\": h.symmetric,\n",
    "#         \"num_clusters\": h.num_clusters\n",
    "#     }\n",
    "#     meta = {\n",
    "#         \"generated_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "#         \"fingerprint\": _fp(topo),\n",
    "#         \"env\": {\"python\": platform.python_version(), \"user\": getpass.getuser()},\n",
    "#         \"units\": {\"compute\": \"CPU cycles per slot\", \"links\": \"MB per slot\", \"time_step\": \"seconds\"},\n",
    "#         \"notes\": {\n",
    "#             \"inputs_unit\": {\"compute\": \"CPU cycles per second\", \"links\": \"MB per second\"},\n",
    "#             \"conversion\": \"per_slot = per_second * time_step\",\n",
    "#             \"topology_semantics\": {\n",
    "#                 \"skip_connections\": \"k-nearest ring; each MEC connects to next 'skip_k' neighbors on a circle\"\n",
    "#             }\n",
    "#         },\n",
    "#         \"hyperparameters\": asdict(h)\n",
    "#     }\n",
    "\n",
    "#     _save_json(topo, out_topology)\n",
    "#     _save_json(meta, out_meta)\n",
    "\n",
    "#     out_dir = os.path.dirname(out_topology) or \".\"\n",
    "#     cm_csv = os.path.join(out_dir, \"connection_matrix.csv\")\n",
    "#     _save_matrix_csv(M, cm_csv)\n",
    "\n",
    "#     graph_png = None\n",
    "#     if _GRAPH_OK:\n",
    "#         graph_png = os.path.join(out_dir, \"topology_graph.png\")\n",
    "#         _draw_graph_png(M, graph_png, title=\"MEC Graph (MB/slot)\", with_cloud=True)\n",
    "\n",
    "#     report_md = os.path.join(out_dir, \"topology_report.md\")\n",
    "#     _write_markdown_report(topo, meta, graph_png, report_md)\n",
    "\n",
    "#     return {\n",
    "#         \"topology_json\": out_topology,\n",
    "#         \"meta_json\": out_meta,\n",
    "#         \"connection_matrix_csv\": cm_csv,\n",
    "#         \"graph_png\": graph_png if graph_png else \"\",\n",
    "#         \"report_md\": report_md\n",
    "#     }\n",
    "\n",
    "# # =========================\n",
    "# # Build from JSON hyperparams (optional)\n",
    "# # =========================\n",
    "# def build_from_hyperparameters_json(hparams_path: str,\n",
    "#                                     out_dir: str = \"./topology\") -> Dict[str, str]:\n",
    "#     with open(hparams_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         hp = json.load(f)\n",
    "\n",
    "#     th = TopologyHyper(\n",
    "#         number_of_servers = int(hp.get(\"number_of_servers\", 18)),\n",
    "#         time_step         = float(hp.get(\"time_step\", 1.0)),\n",
    "#         private_cpu_min   = hp.get(\"private_cpu_min\"),\n",
    "#         private_cpu_max   = hp.get(\"private_cpu_max\"),\n",
    "#         public_cpu_min    = hp.get(\"public_cpu_min\"),\n",
    "#         public_cpu_max    = hp.get(\"public_cpu_max\"),\n",
    "#         cpu_total_min     = hp.get(\"cpu_total_min\"),\n",
    "#         cpu_total_max     = hp.get(\"cpu_total_max\"),\n",
    "#         public_share      = hp.get(\"public_share\"),\n",
    "#         cloud_capacity    = hp.get(\"cloud_capacity\"),\n",
    "#         cloud_capacity_min= hp.get(\"cloud_capacity_min\"),\n",
    "#         cloud_capacity_max= hp.get(\"cloud_capacity_max\"),\n",
    "#         horiz_cap_min     = float(hp.get(\"horizontal_capacities_min\", 8.0)),\n",
    "#         horiz_cap_max     = float(hp.get(\"horizontal_capacities_max\", 12.0)),\n",
    "#         cloud_cap_min     = float(hp.get(\"cloud_capacities_min\", 50.0)),\n",
    "#         cloud_cap_max     = float(hp.get(\"cloud_capacities_max\", 200.0)),\n",
    "#         topology_type     = hp.get(\"topology_type\", \"skip_connections\"),\n",
    "#         skip_k            = int(hp.get(\"skip_k\", 5)),\n",
    "#         symmetric         = bool(hp.get(\"symmetric\", True)),\n",
    "#         num_clusters      = int(hp.get(\"num_clusters\", 3)),\n",
    "#         inter_cluster_frac= float(hp.get(\"inter_cluster_frac\", 0.0)),\n",
    "#         seed              = int(hp.get(\"seed\", 2025))\n",
    "#     )\n",
    "\n",
    "#     os.makedirs(out_dir, exist_ok=True)\n",
    "#     return build_topology(\n",
    "#         th,\n",
    "#         out_topology=os.path.join(out_dir, \"topology.json\"),\n",
    "#         out_meta=os.path.join(out_dir, \"topology_meta.json\")\n",
    "#     )\n",
    "\n",
    "# # =========================\n",
    "# # Build 3 fixed, reproducible topologies (variants)\n",
    "# # =========================\n",
    "# def build_three_topologies_variants(\n",
    "#     K: int,\n",
    "#     delta: float,\n",
    "#     seed_base: int,\n",
    "#     out_root: str = \"./topologies\",\n",
    "#     # Compute (per-second)\n",
    "#     private_cpu_min: float | None = 1.2e9,\n",
    "#     private_cpu_max: float | None = 1.8e9,\n",
    "#     public_cpu_min:  float | None = 0.5e9,\n",
    "#     public_cpu_max:  float | None = 0.9e9,\n",
    "#     cpu_total_min:   float | None = None,\n",
    "#     cpu_total_max:   float | None = None,\n",
    "#     public_share:    float | None = None,\n",
    "#     # Cloud (per-second)\n",
    "#     cloud_capacity: float | None = 3.0e10,\n",
    "#     cloud_capacity_min: float | None = None,\n",
    "#     cloud_capacity_max: float | None = None,\n",
    "#     # Links (per-second, MB/s)\n",
    "#     horiz_cap_min: float = 8.0,\n",
    "#     horiz_cap_max: float = 12.0,\n",
    "#     cloud_cap_min: float = 80.0,\n",
    "#     cloud_cap_max: float = 120.0,\n",
    "#     # Cluster params\n",
    "#     num_clusters: int = 3,\n",
    "#     inter_cluster_frac: float = 0.0,\n",
    "# ):\n",
    "#     os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "#     variants = [\n",
    "#         dict(\n",
    "#             name=\"full_mesh\",\n",
    "#             h=TopologyHyper(\n",
    "#                 number_of_servers=K, time_step=delta,\n",
    "#                 private_cpu_min=private_cpu_min, private_cpu_max=private_cpu_max,\n",
    "#                 public_cpu_min=public_cpu_min,   public_cpu_max=public_cpu_max,\n",
    "#                 cpu_total_min=cpu_total_min, cpu_total_max=cpu_total_max, public_share=public_share,\n",
    "#                 cloud_capacity=cloud_capacity,\n",
    "#                 cloud_capacity_min=cloud_capacity_min, cloud_capacity_max=cloud_capacity_max,\n",
    "#                 horiz_cap_min=horiz_cap_min, horiz_cap_max=horiz_cap_max,\n",
    "#                 cloud_cap_min=cloud_cap_min, cloud_cap_max=cloud_cap_max,\n",
    "#                 topology_type=\"fully_connected\", skip_k=1, symmetric=True,\n",
    "#                 num_clusters=num_clusters, inter_cluster_frac=inter_cluster_frac,\n",
    "#                 seed=seed_base + 101\n",
    "#             )\n",
    "#         ),\n",
    "#         dict(\n",
    "#             name=\"clustered\",\n",
    "#             h=TopologyHyper(\n",
    "#                 number_of_servers=K, time_step=delta,\n",
    "#                 private_cpu_min=private_cpu_min, private_cpu_max=private_cpu_max,\n",
    "#                 public_cpu_min=public_cpu_min,   public_cpu_max=public_cpu_max,\n",
    "#                 cpu_total_min=cpu_total_min, cpu_total_max=cpu_total_max, public_share=public_share,\n",
    "#                 cloud_capacity=cloud_capacity,\n",
    "#                 cloud_capacity_min=cloud_capacity_min, cloud_capacity_max=cloud_capacity_max,\n",
    "#                 horiz_cap_min=horiz_cap_min, horiz_cap_max=horiz_cap_max,\n",
    "#                 cloud_cap_min=cloud_cap_min, cloud_cap_max=cloud_cap_max,\n",
    "#                 topology_type=\"clustered\", symmetric=True,\n",
    "#                 num_clusters=num_clusters, inter_cluster_frac=inter_cluster_frac,\n",
    "#                 seed=seed_base + 202\n",
    "#             )\n",
    "#         ),\n",
    "#         dict(\n",
    "#             name=\"sparse_ring\",\n",
    "#             h=TopologyHyper(\n",
    "#                 number_of_servers=K, time_step=delta,\n",
    "#                 private_cpu_min=private_cpu_min, private_cpu_max=private_cpu_max,\n",
    "#                 public_cpu_min=public_cpu_min,   public_cpu_max=public_cpu_max,\n",
    "#                 cpu_total_min=cpu_total_min, cpu_total_max=cpu_total_max, public_share=public_share,\n",
    "#                 cloud_capacity=cloud_capacity,\n",
    "#                 cloud_capacity_min=cloud_capacity_min, cloud_capacity_max=cloud_capacity_max,\n",
    "#                 horiz_cap_min=horiz_cap_min, horiz_cap_max=horiz_cap_max,\n",
    "#                 cloud_cap_min=cloud_cap_min, cloud_cap_max=cloud_cap_max,\n",
    "#                 topology_type=\"skip_connections\", skip_k=1, symmetric=True,  # ring\n",
    "#                 num_clusters=num_clusters, inter_cluster_frac=inter_cluster_frac,\n",
    "#                 seed=seed_base + 303\n",
    "#             )\n",
    "#         ),\n",
    "#     ]\n",
    "\n",
    "#     results: Dict[str, Dict[str, str]] = {}\n",
    "#     for v in variants:\n",
    "#         name = v[\"name\"]\n",
    "#         h: TopologyHyper = v[\"h\"]\n",
    "#         out_dir = os.path.join(out_root, name)\n",
    "#         os.makedirs(out_dir, exist_ok=True)\n",
    "#         paths = build_topology(\n",
    "#             h,\n",
    "#             out_topology=os.path.join(out_dir, \"topology.json\"),\n",
    "#             out_meta=os.path.join(out_dir, \"topology_meta.json\")\n",
    "#         )\n",
    "#         results[name] = paths\n",
    "\n",
    "#     return results\n",
    "\n",
    "# # =========================\n",
    "# # Example multi-build run\n",
    "# # =========================\n",
    "# if __name__ == \"__main__\":\n",
    "#     K = 18\n",
    "#     DELTA = 1.0\n",
    "#     SEED_BASE = 20251027\n",
    "\n",
    "#     out = build_three_topologies_variants(\n",
    "#         K=K, delta=DELTA, seed_base=SEED_BASE,\n",
    "#         private_cpu_min=1.2e9, private_cpu_max=1.8e9,\n",
    "#         public_cpu_min=0.5e9,  public_cpu_max=0.9e9,\n",
    "#         cloud_capacity=3.0e10,\n",
    "#         horiz_cap_min=8.0, horiz_cap_max=12.0,\n",
    "#         cloud_cap_min=80.0, cloud_cap_max=120.0,\n",
    "#         num_clusters=3, inter_cluster_frac=0.0,\n",
    "#         out_root=\"./topologies\"\n",
    "#     )\n",
    "#     print(json.dumps(out, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "import numpy as np\n",
    "import json, os, time, hashlib, platform, getpass\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_environment(mec_csv_path: str, cloud_csv_path: str):\n",
    "    import pandas as pd\n",
    "    mec_df = pd.read_csv(mec_csv_path)\n",
    "    cloud_df = pd.read_csv(cloud_csv_path)\n",
    "\n",
    "    num_mecs = len(mec_df)\n",
    "\n",
    "    mec_private = mec_df[\"Private CPU Capacity\"].tolist()\n",
    "    mec_public  = mec_df[\"Public CPU Capacity\"].tolist()\n",
    "    cloud_cap   = float(cloud_df[\"computational_capacity\"].iloc[0])\n",
    "\n",
    "    return num_mecs, mec_private, mec_public, cloud_cap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "HOODIE–style Topology Builder (final revised version)\n",
    "-----------------------------------------------------\n",
    "\n",
    "این نسخه نسخه‌ی نهایی است که:\n",
    "\n",
    "1. داده‌های MEC و Cloud را از فایل environment خوانده و ظرفیت‌ها را ست می‌کند.\n",
    "2. لینک‌های MEC↔MEC = 3 و MEC→Cloud = 5 ثابت هستند.\n",
    "3. همچنان انواع توپولوژی‌های fully/clustered/skip_connections را پشتیبانی می‌کند.\n",
    "4. تمام بخش‌های نسخه‌ی اصلی (گزارش، گراف، fingerprint، meta) حفظ شده‌اند.\n",
    "5. build_three_topologies_variants نیز از فایل‌های محیط برای ساخت چند توپولوژی استفاده می‌کند.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "import numpy as np\n",
    "import json, os, time, hashlib, platform, getpass\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "# Optional deps (for graph)\n",
    "try:\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    _GRAPH_OK = True\n",
    "except Exception:\n",
    "    _GRAPH_OK = False\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Utility functions\n",
    "# ============================================================\n",
    "def _fp(obj: dict) -> str:\n",
    "    s = json.dumps(obj, sort_keys=True).encode(\"utf-8\")\n",
    "    return hashlib.sha256(s).hexdigest()[:16]\n",
    "\n",
    "def _save_json(obj: dict, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "    return path\n",
    "\n",
    "def _save_text(text: str, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    return path\n",
    "\n",
    "def _save_matrix_csv(M: np.ndarray, path: str) -> str:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    K = M.shape[0]\n",
    "    header = [f\"mec_{i}\" for i in range(K)] + [\"cloud\"]\n",
    "    lines = [\",\".join([\"\"] + header)]\n",
    "    for i in range(K):\n",
    "        row = \",\".join([f\"mec_{i}\"] + [str(float(x)) for x in M[i, :]])\n",
    "        lines.append(row)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    return path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Data classes (TopologyHyper)\n",
    "# ============================================================\n",
    "@dataclass\n",
    "class TopologyHyper:\n",
    "    \"\"\"\n",
    "    این کلاس فقط پارامترهای مرتبط با توپولوژی را نگه می‌دارد.\n",
    "    ظرفیت‌ها از فایل محیط خوانده می‌شوند، نه از این کلاس!\n",
    "    \"\"\"\n",
    "\n",
    "    time_step: float\n",
    "\n",
    "    # bandwidths\n",
    "    bw_mec_mec: float = 3.0\n",
    "    bw_mec_cloud: float = 5.0\n",
    "\n",
    "    # Topology structure\n",
    "    topology_type: str = \"skip_connections\"\n",
    "    skip_k: int = 3\n",
    "    symmetric: bool = True\n",
    "    num_clusters: int = 3\n",
    "    inter_cluster_frac: float = 0.0\n",
    "\n",
    "    # Paths for environment CSV files\n",
    "    environment_mec_file: Optional[str] = None\n",
    "    environment_cloud_file: Optional[str] = None\n",
    "\n",
    "    seed: int = 2025\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Reading MEC / Cloud data\n",
    "# ============================================================\n",
    "def read_environment_files(mec_file: str, cloud_file: str):\n",
    "    mec_df = pd.read_csv(mec_file)\n",
    "    cloud_df = pd.read_csv(cloud_file)\n",
    "\n",
    "    num_mec = len(mec_df)\n",
    "    private_caps = mec_df[\"Private CPU Capacity\"].tolist()\n",
    "    public_caps = mec_df[\"Public CPU Capacity\"].tolist()\n",
    "\n",
    "    cloud_cap = float(cloud_df[\"computational_capacity\"].iloc[0])\n",
    "\n",
    "    return num_mec, private_caps, public_caps, cloud_cap\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Build Connection Matrix (final fixed link version)\n",
    "# ============================================================\n",
    "def _build_connection_matrix(h: TopologyHyper, K: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build connection matrix of shape (K, K+1):\n",
    "\n",
    "    - Columns 0..K-1  : MEC↔MEC horizontal links\n",
    "    - Column K        : MEC→Cloud vertical links\n",
    "\n",
    "    Link capacities are NOT random here:\n",
    "    - MEC↔MEC links use h.bw_mec_mec\n",
    "    - MEC→Cloud links use h.bw_mec_cloud\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize matrix with zeros\n",
    "    M = np.zeros((K, K + 1), dtype=float)\n",
    "\n",
    "    # Read bandwidth parameters from hyper\n",
    "    bw_mm = float(h.bw_mec_mec)     # MEC↔MEC bandwidth\n",
    "    bw_mc = float(h.bw_mec_cloud)   # MEC→Cloud bandwidth\n",
    "\n",
    "    # ---------------------------\n",
    "    # Horizontal MEC↔MEC links\n",
    "    # ---------------------------\n",
    "    if h.topology_type == \"fully_connected\":\n",
    "        # Fully connected: all MECs interconnected\n",
    "        for i in range(K):\n",
    "            for j in range(i + 1, K):\n",
    "                M[i, j] = bw_mm\n",
    "                if h.symmetric:\n",
    "                    M[j, i] = bw_mm\n",
    "\n",
    "    elif h.topology_type == \"skip_connections\":\n",
    "        # k-nearest ring\n",
    "        step = max(1, int(h.skip_k))\n",
    "        for i in range(K):\n",
    "            for s in range(1, step + 1):\n",
    "                j = (i + s) % K\n",
    "                if i == j:\n",
    "                    continue\n",
    "                M[i, j] = bw_mm\n",
    "                if h.symmetric:\n",
    "                    M[j, i] = bw_mm\n",
    "\n",
    "    elif h.topology_type == \"clustered\":\n",
    "        # Clustered topology: fully connected inside clusters\n",
    "        C = max(1, int(h.num_clusters))\n",
    "\n",
    "        # Compute cluster sizes\n",
    "        sizes = [K // C] * C\n",
    "        for idx in range(K % C):\n",
    "            sizes[idx] += 1\n",
    "        starts = np.cumsum([0] + sizes[:-1])\n",
    "        clusters = [(int(s), int(s + sz)) for s, sz in zip(starts, sizes)]  # [(start, end), ...]\n",
    "\n",
    "        # Intra-cluster links (fully connected)\n",
    "        for (a, b) in clusters:\n",
    "            for i in range(a, b):\n",
    "                for j in range(i + 1, b):\n",
    "                    M[i, j] = bw_mm\n",
    "                    if h.symmetric:\n",
    "                        M[j, i] = bw_mm\n",
    "\n",
    "        # Optional weak inter-cluster links\n",
    "        if h.inter_cluster_frac > 0.0:\n",
    "            weak = bw_mm * float(h.inter_cluster_frac)\n",
    "            for c1 in range(len(clusters)):\n",
    "                for c2 in range(c1 + 1, len(clusters)):\n",
    "                    a1, b1 = clusters[c1]\n",
    "                    a2, b2 = clusters[c2]\n",
    "                    i = a1   # representative node of cluster 1\n",
    "                    j = a2   # representative node of cluster 2\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    M[i, j] = max(M[i, j], weak)\n",
    "                    if h.symmetric:\n",
    "                        M[j, i] = max(M[j, i], weak)\n",
    "\n",
    "    else:\n",
    "        # Unknown topology_type → no horizontal links\n",
    "        pass\n",
    "\n",
    "    # Ensure zero diagonal for MEC↔MEC\n",
    "    for i in range(K):\n",
    "        M[i, i] = 0.0\n",
    "\n",
    "    # ---------------------------\n",
    "    # Vertical MEC→Cloud links\n",
    "    # ---------------------------\n",
    "    for i in range(K):\n",
    "        M[i, K] = bw_mc\n",
    "\n",
    "    return M\n",
    "\n",
    "# ============================================================\n",
    "# Graph drawing (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "def _draw_graph_png(M: np.ndarray,\n",
    "                    out_png: str,\n",
    "                    title: str = \"MEC Graph (MB/slot)\",\n",
    "                    with_cloud: bool = True):\n",
    "    if not _GRAPH_OK:\n",
    "        return None\n",
    "\n",
    "    K = M.shape[0]\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # MEC nodes\n",
    "    for i in range(K):\n",
    "        G.add_node(f\"MEC_{i}\", layer=\"mec\")\n",
    "\n",
    "    for i in range(K):\n",
    "        for j in range(i + 1, K):\n",
    "            cap = max(M[i, j], M[j, i])\n",
    "            if cap > 0:\n",
    "                G.add_edge(f\"MEC_{i}\", f\"MEC_{j}\", weight=cap)\n",
    "\n",
    "    pos = nx.circular_layout([f\"MEC_{i}\" for i in range(K)])\n",
    "\n",
    "    if with_cloud:\n",
    "        G.add_node(\"CLOUD\", layer=\"cloud\")\n",
    "        pos[\"CLOUD\"] = np.array([0.0, 1.25])\n",
    "        for i in range(K):\n",
    "            cap_cloud = M[i, K]\n",
    "            if cap_cloud > 0:\n",
    "                G.add_edge(f\"MEC_{i}\", \"CLOUD\", weight=cap_cloud)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=[n for n, d in G.nodes(data=True) if d.get(\"layer\")==\"mec\"])\n",
    "    if with_cloud:\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=[\"CLOUD\"], node_shape=\"s\")\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos)\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "    edge_labels = {(u,v): f\"{G[u][v]['weight']:.1f}\" for u,v in G.edges()}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    os.makedirs(os.path.dirname(out_png), exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "    return out_png\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Markdown Report Writer (unchanged)\n",
    "# ============================================================\n",
    "\n",
    "def _write_markdown_report(topo: dict, meta: dict, graph_png: Optional[str], out_md: str):\n",
    "    K = topo[\"number_of_servers\"]\n",
    "    priv = topo[\"private_cpu_capacities\"]\n",
    "    pub  = topo[\"public_cpu_capacities\"]\n",
    "    cloud = topo[\"cloud_computational_capacity\"]\n",
    "\n",
    "    M = np.array(topo[\"connection_matrix\"], dtype=float)\n",
    "    horiz = M[:, :K]\n",
    "    vert  = M[:, K]\n",
    "\n",
    "    nonzero = int((horiz > 0).sum())\n",
    "    density = nonzero / float(K * (K - 1)) if K > 1 else 0.0\n",
    "\n",
    "    md = []\n",
    "    md.append(f\"# Topology Report\\n\")\n",
    "    md.append(f\"- **Servers (MEC)**: {K}\")\n",
    "    md.append(f\"- **Topology type**: {topo['topology_type']}\")\n",
    "    md.append(\"\")\n",
    "    md.append(f\"## Compute Capacities\")\n",
    "    md.append(f\"- Private: {priv}\")\n",
    "    md.append(f\"- Public:  {pub}\")\n",
    "    md.append(f\"- Cloud:   {cloud}\")\n",
    "    md.append(\"\")\n",
    "    md.append(f\"## Link Capacities\")\n",
    "    md.append(f\"- MEC↔MEC: fixed 3\")\n",
    "    md.append(f\"- MEC→Cloud: fixed 5\")\n",
    "    md.append(\"\")\n",
    "    if graph_png:\n",
    "        md.append(f\"## Graph\")\n",
    "        md.append(f\"![Topology Graph]({os.path.basename(graph_png)})\")\n",
    "        md.append(\"\")\n",
    "\n",
    "    _save_text(\"\\n\".join(md), out_md)\n",
    "    return out_md\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main builder (final)\n",
    "# ============================================================\n",
    "\n",
    "def build_topology(\n",
    "    h: TopologyHyper,\n",
    "    mec_csv_path: str,\n",
    "    cloud_csv_path: str,\n",
    "    out_topology: str = \"./topology/topology.json\",\n",
    "    out_meta: str = \"./topology/topology_meta.json\"\n",
    "):\n",
    "\n",
    "    rng = np.random.default_rng(h.seed)\n",
    "\n",
    "    # STEP 1 — Read MEC + Cloud data\n",
    "    K, private_caps, public_caps, cloud_cap = read_environment_files(\n",
    "        mec_csv_path, cloud_csv_path\n",
    "    )\n",
    "\n",
    "    # STEP 2 — Build connection matrix\n",
    "    M = _build_connection_matrix(h, K)\n",
    "\n",
    "    # STEP 3 — Construct topology dict\n",
    "    topo = {\n",
    "        \"number_of_servers\": K,\n",
    "        \"private_cpu_capacities\": private_caps,\n",
    "        \"public_cpu_capacities\": public_caps,\n",
    "        \"cloud_computational_capacity\": cloud_cap,\n",
    "        \"connection_matrix\": M.tolist(),\n",
    "        \"time_step\": h.time_step,\n",
    "        \"topology_type\": h.topology_type,\n",
    "        \"skip_k\": h.skip_k,\n",
    "        \"symmetric\": h.symmetric,\n",
    "        \"num_clusters\": h.num_clusters\n",
    "    }\n",
    "\n",
    "    # Meta info\n",
    "    meta = {\n",
    "        \"generated_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"fingerprint\": _fp(topo),\n",
    "        \"env\": {\"python\": platform.python_version(), \"user\": getpass.getuser()},\n",
    "        \"hyperparameters\": asdict(h),\n",
    "    }\n",
    "\n",
    "    # Save data\n",
    "    _save_json(topo, out_topology)\n",
    "    _save_json(meta, out_meta)\n",
    "\n",
    "    out_dir = os.path.dirname(out_topology) or \".\"\n",
    "    cm_csv = os.path.join(out_dir, \"connection_matrix.csv\")\n",
    "    _save_matrix_csv(M, cm_csv)\n",
    "\n",
    "    # Optional Graph\n",
    "    graph_png = None\n",
    "    if _GRAPH_OK:\n",
    "        graph_png = os.path.join(out_dir, \"topology_graph.png\")\n",
    "        _draw_graph_png(M, graph_png, with_cloud=True)\n",
    "\n",
    "    # Markdown report\n",
    "    report_md = os.path.join(out_dir, \"topology_report.md\")\n",
    "    _write_markdown_report(topo, meta, graph_png, report_md)\n",
    "\n",
    "    return {\n",
    "        \"topology_json\": out_topology,\n",
    "        \"meta_json\": out_meta,\n",
    "        \"connection_matrix_csv\": cm_csv,\n",
    "        \"graph_png\": graph_png if graph_png else \"\",\n",
    "        \"report_md\": report_md\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Build multiple variants (final)\n",
    "# ============================================================\n",
    "\n",
    "def build_three_topologies_variants(\n",
    "    mec_csv_path: str,\n",
    "    cloud_csv_path: str,\n",
    "    delta: float,\n",
    "    seed_base: int,\n",
    "    out_root: str = \"./topologies\",\n",
    "):\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "    variants = [\"fully_connected\", \"clustered\", \"skip_connections\"]\n",
    "\n",
    "    results: Dict[str, Dict[str, str]] = {}\n",
    "\n",
    "    for idx, topo_type in enumerate(variants):\n",
    "        h = TopologyHyper(\n",
    "            time_step=delta,\n",
    "            topology_type=topo_type,\n",
    "            skip_k=3,\n",
    "            symmetric=True,\n",
    "            num_clusters=3,\n",
    "            environment_mec_file=mec_csv_path,\n",
    "            environment_cloud_file=cloud_csv_path,\n",
    "            seed=seed_base + idx * 100\n",
    "        )\n",
    "\n",
    "        out_dir = os.path.join(out_root, topo_type)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        paths = build_topology(\n",
    "            h,\n",
    "            mec_csv_path=mec_csv_path,\n",
    "            cloud_csv_path=cloud_csv_path,\n",
    "            out_topology=os.path.join(out_dir, \"topology.json\"),\n",
    "            out_meta=os.path.join(out_dir, \"topology_meta.json\")\n",
    "        )\n",
    "\n",
    "        results[topo_type] = paths\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
