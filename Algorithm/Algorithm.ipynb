{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Imports </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\Users\\niush\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Step 1: Prepare data and configure the environment </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1. Data Loading (Data I/O) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directories\n",
    "dataset_dir = '../Data_Generator/datasets'\n",
    "topology_dir = '../Topology_Generator/topologies'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global container\n",
    "datasets = {}\n",
    "\n",
    "def load_datasets_from_directory(dataset_dir, verbose=True):\n",
    "    \"\"\"\n",
    "    Build 'episode-first' structure:\n",
    "    datasets = {\n",
    "        \"ep_000\": {\n",
    "            \"light\":   { \"episodes\": df, \"agents\": df, \"arrivals\": df, \"tasks\": df },\n",
    "            \"moderate\":{ ... },\n",
    "            \"heavy\":   { ... }\n",
    "        },\n",
    "        \"ep_001\": { ... },\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Step 1 — detect scenarios (light/moderate/heavy/...)\n",
    "    scenarios = [\n",
    "        name for name in os.listdir(dataset_dir)\n",
    "        if os.path.isdir(os.path.join(dataset_dir, name))\n",
    "    ]\n",
    "\n",
    "    # Step 2 — load per scenario and per episode (ep_XXX)\n",
    "    scenario_to_episodes = {}\n",
    "    for scenario in scenarios:\n",
    "        scn_path = os.path.join(dataset_dir, scenario)\n",
    "        ep_dirs = sorted([\n",
    "            ep for ep in os.listdir(scn_path)\n",
    "            if os.path.isdir(os.path.join(scn_path, ep)) and ep.startswith(\"ep_\")\n",
    "        ])\n",
    "        if not ep_dirs and verbose:\n",
    "            print(f\"[warn] no ep_* folders found under scenario '{scenario}'\")\n",
    "\n",
    "        scenario_to_episodes[scenario] = {}\n",
    "        for ep_name in ep_dirs:\n",
    "            ep_path = os.path.join(scn_path, ep_name)\n",
    "            try:\n",
    "                scenario_to_episodes[scenario][ep_name] = {\n",
    "                    \"episodes\": pd.read_csv(os.path.join(ep_path, \"episodes.csv\")),\n",
    "                    \"agents\":   pd.read_csv(os.path.join(ep_path, \"agents.csv\")),\n",
    "                    \"arrivals\": pd.read_csv(os.path.join(ep_path, \"arrivals.csv\")),\n",
    "                    \"tasks\":    pd.read_csv(os.path.join(ep_path, \"tasks.csv\")),\n",
    "                }\n",
    "            except FileNotFoundError as e:\n",
    "                if verbose:\n",
    "                    print(f\"[error] missing CSV in {ep_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Step 3 — invert structure: episodes → scenarios\n",
    "    datasets.clear()\n",
    "    for scenario, eps in scenario_to_episodes.items():\n",
    "        for ep_name, dfs in eps.items():\n",
    "            if ep_name not in datasets:\n",
    "                datasets[ep_name] = {}\n",
    "            datasets[ep_name][scenario] = dfs\n",
    "\n",
    "    # Optional summary printing\n",
    "    if verbose:\n",
    "        print(\"=== Dataset Summary (episode-first) ===\")\n",
    "        print(f\"episodes: {len(datasets)}  | scenarios detected: {len(scenarios)} -> {sorted(scenarios)}\")\n",
    "        for ep_name in sorted(datasets.keys()):\n",
    "            scenarios_here = sorted(datasets[ep_name].keys())\n",
    "            print(f\"  - {ep_name}: scenarios = {scenarios_here}\")\n",
    "            for scn in scenarios_here:\n",
    "                dfs = datasets[ep_name][scn]\n",
    "                n_ep   = len(dfs['episodes'])\n",
    "                n_ag   = len(dfs['agents'])\n",
    "                n_arr  = len(dfs['arrivals'])\n",
    "                n_task = len(dfs['tasks'])\n",
    "                print(f\"      {scn:9s} → episodes:{n_ep:3d}  agents:{n_ag:4d}  arrivals:{n_arr:6d}  tasks:{n_task:6d}\")\n",
    "        print(\"=======================================\")\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Summary (episode-first) ===\n",
      "episodes: 1  | scenarios detected: 3 -> ['heavy', 'light', 'moderate']\n",
      "  - ep_000: scenarios = ['heavy', 'light', 'moderate']\n",
      "      heavy     → episodes:  1  agents:  18  arrivals: 30636  tasks: 30636\n",
      "      light     → episodes:  1  agents:  18  arrivals:  2113  tasks:  2113\n",
      "      moderate  → episodes:  1  agents:  18  arrivals:  8262  tasks:  8262\n",
      "=======================================\n",
      "\n",
      "[info] printing from episode='ep_000', scenario='heavy'\n",
      "\n",
      "agents:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>f_local</th>\n",
       "      <th>m_local</th>\n",
       "      <th>lam_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>0.708673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>0.234989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>0.228174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>0.310369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>0.548990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id       f_local      m_local   lam_sec\n",
       "0         0  1.741183e+09  5713.849721  0.708673\n",
       "1         1  1.352326e+09  4566.428755  0.234989\n",
       "2         2  1.726668e+09  5815.120004  0.228174\n",
       "3         3  1.543616e+09  3539.850245  0.310369\n",
       "4         4  1.130883e+09  4161.367769  0.548990"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   agent_id  18 non-null     int64  \n",
      " 1   f_local   18 non-null     float64\n",
      " 2   m_local   18 non-null     float64\n",
      " 3   lam_sec   18 non-null     float64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 704.0 bytes\n",
      "\n",
      "arrivals:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>t_slot</th>\n",
       "      <th>t_time</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>task_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "0    heavy           0       0     0.0         0        0\n",
       "1    heavy           0       0     0.0         1        1\n",
       "2    heavy           0       0     0.0         4        2\n",
       "3    heavy           0       0     0.0         7        3\n",
       "4    heavy           0       0     0.0        10        4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30636 entries, 0 to 30635\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   scenario    30636 non-null  object \n",
      " 1   episode_id  30636 non-null  int64  \n",
      " 2   t_slot      30636 non-null  int64  \n",
      " 3   t_time      30636 non-null  float64\n",
      " 4   agent_id    30636 non-null  int64  \n",
      " 5   task_id     30636 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 1.4+ MB\n",
      "\n",
      "episodes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>Delta</th>\n",
       "      <th>T_slots</th>\n",
       "      <th>hours</th>\n",
       "      <th>N_agents</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "0    heavy           0    1.0     3600    1.0        18   345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   scenario    1 non-null      object \n",
      " 1   episode_id  1 non-null      int64  \n",
      " 2   Delta       1 non-null      float64\n",
      " 3   T_slots     1 non-null      int64  \n",
      " 4   hours       1 non-null      float64\n",
      " 5   N_agents    1 non-null      int64  \n",
      " 6   seed        1 non-null      int64  \n",
      "dtypes: float64(2), int64(4), object(1)\n",
      "memory usage: 184.0+ bytes\n",
      "\n",
      "tasks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>t_arrival_slot</th>\n",
       "      <th>t_arrival_time</th>\n",
       "      <th>b_mb</th>\n",
       "      <th>rho_cyc_per_mb</th>\n",
       "      <th>c_cycles</th>\n",
       "      <th>mem_mb</th>\n",
       "      <th>modality</th>\n",
       "      <th>has_deadline</th>\n",
       "      <th>deadline_s</th>\n",
       "      <th>deadline_time</th>\n",
       "      <th>non_atomic</th>\n",
       "      <th>split_ratio</th>\n",
       "      <th>action_space_hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.202096</td>\n",
       "      <td>9.727147e+08</td>\n",
       "      <td>7.005585e+09</td>\n",
       "      <td>66.611010</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800726</td>\n",
       "      <td>0.800726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.479984</td>\n",
       "      <td>1.314973e+09</td>\n",
       "      <td>7.206031e+09</td>\n",
       "      <td>77.928800</td>\n",
       "      <td>image</td>\n",
       "      <td>1</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.421977</td>\n",
       "      <td>2.500222e+09</td>\n",
       "      <td>2.105681e+10</td>\n",
       "      <td>72.966446</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323007</td>\n",
       "      <td>0.323007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539704</td>\n",
       "      <td>continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.324986</td>\n",
       "      <td>1.779582e+09</td>\n",
       "      <td>1.125583e+10</td>\n",
       "      <td>56.492900</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481587</td>\n",
       "      <td>0.481587</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.473269</td>\n",
       "      <td>1.087572e+09</td>\n",
       "      <td>1.247800e+10</td>\n",
       "      <td>73.389854</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594564</td>\n",
       "      <td>0.594564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "0    heavy           0        0         0               0             0.0   \n",
       "1    heavy           0        1         1               0             0.0   \n",
       "2    heavy           0        2         4               0             0.0   \n",
       "3    heavy           0        3         7               0             0.0   \n",
       "4    heavy           0        4        10               0             0.0   \n",
       "\n",
       "        b_mb  rho_cyc_per_mb      c_cycles     mem_mb modality  has_deadline  \\\n",
       "0   7.202096    9.727147e+08  7.005585e+09  66.611010   sensor             1   \n",
       "1   5.479984    1.314973e+09  7.206031e+09  77.928800    image             1   \n",
       "2   8.421977    2.500222e+09  2.105681e+10  72.966446     text             1   \n",
       "3   6.324986    1.779582e+09  1.125583e+10  56.492900   sensor             1   \n",
       "4  11.473269    1.087572e+09  1.247800e+10  73.389854   sensor             1   \n",
       "\n",
       "   deadline_s  deadline_time  non_atomic  split_ratio action_space_hint  \n",
       "0    0.800726       0.800726           0     0.000000          discrete  \n",
       "1    0.615113       0.615113           0     0.000000          discrete  \n",
       "2    0.323007       0.323007           1     0.539704        continuous  \n",
       "3    0.481587       0.481587           0     0.000000          discrete  \n",
       "4    0.594564       0.594564           0     0.000000          discrete  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30636 entries, 0 to 30635\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   scenario           30636 non-null  object \n",
      " 1   episode_id         30636 non-null  int64  \n",
      " 2   task_id            30636 non-null  int64  \n",
      " 3   agent_id           30636 non-null  int64  \n",
      " 4   t_arrival_slot     30636 non-null  int64  \n",
      " 5   t_arrival_time     30636 non-null  float64\n",
      " 6   b_mb               30636 non-null  float64\n",
      " 7   rho_cyc_per_mb     30636 non-null  float64\n",
      " 8   c_cycles           30636 non-null  float64\n",
      " 9   mem_mb             30636 non-null  float64\n",
      " 10  modality           30636 non-null  object \n",
      " 11  has_deadline       30636 non-null  int64  \n",
      " 12  deadline_s         10673 non-null  float64\n",
      " 13  deadline_time      10673 non-null  float64\n",
      " 14  non_atomic         30636 non-null  int64  \n",
      " 15  split_ratio        30636 non-null  float64\n",
      " 16  action_space_hint  30636 non-null  object \n",
      "dtypes: float64(8), int64(6), object(3)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# ---- load all datasets (episode-first) ----\n",
    "datasets = load_datasets_from_directory(dataset_dir, verbose=True)\n",
    "\n",
    "# ---- choose an episode and a scenario for printing ----\n",
    "# pick first available episode if you don't want to hardcode\n",
    "ep_name = sorted(datasets.keys())[0] if datasets else None\n",
    "scenario = \"heavy\"  # you can change to \"light\"/\"moderate\" if needed\n",
    "\n",
    "if ep_name is not None and scenario in datasets[ep_name]:\n",
    "    print(f\"\\n[info] printing from episode='{ep_name}', scenario='{scenario}'\")\n",
    "\n",
    "    print(\"\\nagents:\")\n",
    "    display(datasets[ep_name][scenario]['agents'].head())\n",
    "    datasets[ep_name][scenario]['agents'].info()\n",
    "\n",
    "    print(\"\\narrivals:\")\n",
    "    display(datasets[ep_name][scenario]['arrivals'].head())\n",
    "    datasets[ep_name][scenario]['arrivals'].info()\n",
    "\n",
    "    print(\"\\nepisodes:\")\n",
    "    display(datasets[ep_name][scenario]['episodes'].head())\n",
    "    datasets[ep_name][scenario]['episodes'].info()\n",
    "\n",
    "    print(\"\\ntasks:\")\n",
    "    display(datasets[ep_name][scenario]['tasks'].head())\n",
    "    datasets[ep_name][scenario]['tasks'].info()\n",
    "else:\n",
    "    print(\"[error] no datasets found or requested scenario is missing for the chosen episode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global container\n",
    "topologies = {}\n",
    "\n",
    "def load_topologies_from_directory(topology_dir):\n",
    "    \n",
    "    for topology_name in os.listdir(topology_dir):\n",
    "        topology_path = os.path.join(topology_dir, topology_name)\n",
    "        \n",
    "        # Only process directories\n",
    "        if os.path.isdir(topology_path):\n",
    "            topology_json_path = os.path.join(topology_path, \"topology.json\")\n",
    "            meta_json_path = os.path.join(topology_path, \"topology_meta.json\")\n",
    "            connection_matrix_csv_path = os.path.join(topology_path, \"connection_matrix.csv\")\n",
    "            \n",
    "             # --- Load JSON & CSV files ---\n",
    "            topology_data = None\n",
    "            meta_data = None\n",
    "            with open(topology_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                topology_data = json.load(f)\n",
    "            with open(meta_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                meta_data = json.load(f)\n",
    "            \n",
    "            # The first column is just for displaying row names, not part of the capacity matrix. \n",
    "            # So the best way is to index the first column. (index_col=0)\n",
    "            connection_matrix = pd.read_csv(connection_matrix_csv_path, index_col=0)\n",
    "            \n",
    "            # Store the topology details and the loaded CSV\n",
    "            topologies[topology_name] = {\n",
    "                \"topology_data\": topology_data,\n",
    "                \"meta_data\": meta_data,\n",
    "                \"connection_matrix\": connection_matrix  # Store the loaded CSV data\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topology clustered -> connection_matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mec_0</th>\n",
       "      <th>mec_1</th>\n",
       "      <th>mec_2</th>\n",
       "      <th>mec_3</th>\n",
       "      <th>mec_4</th>\n",
       "      <th>mec_5</th>\n",
       "      <th>mec_6</th>\n",
       "      <th>mec_7</th>\n",
       "      <th>mec_8</th>\n",
       "      <th>mec_9</th>\n",
       "      <th>mec_10</th>\n",
       "      <th>mec_11</th>\n",
       "      <th>mec_12</th>\n",
       "      <th>mec_13</th>\n",
       "      <th>mec_14</th>\n",
       "      <th>mec_15</th>\n",
       "      <th>mec_16</th>\n",
       "      <th>mec_17</th>\n",
       "      <th>cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mec_0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.798801</td>\n",
       "      <td>11.958295</td>\n",
       "      <td>11.470404</td>\n",
       "      <td>9.980195</td>\n",
       "      <td>8.814050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.912800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_1</th>\n",
       "      <td>9.798801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.375143</td>\n",
       "      <td>11.535600</td>\n",
       "      <td>10.702584</td>\n",
       "      <td>9.136893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.609202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_2</th>\n",
       "      <td>11.958295</td>\n",
       "      <td>8.375143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.814632</td>\n",
       "      <td>9.637714</td>\n",
       "      <td>9.170700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.055348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_3</th>\n",
       "      <td>11.470404</td>\n",
       "      <td>11.535600</td>\n",
       "      <td>8.814632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.377054</td>\n",
       "      <td>11.920252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.851664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_4</th>\n",
       "      <td>9.980195</td>\n",
       "      <td>10.702584</td>\n",
       "      <td>9.637714</td>\n",
       "      <td>10.377054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.105383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.076301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mec_0      mec_1      mec_2      mec_3      mec_4      mec_5  \\\n",
       "mec_0   0.000000   9.798801  11.958295  11.470404   9.980195   8.814050   \n",
       "mec_1   9.798801   0.000000   8.375143  11.535600  10.702584   9.136893   \n",
       "mec_2  11.958295   8.375143   0.000000   8.814632   9.637714   9.170700   \n",
       "mec_3  11.470404  11.535600   8.814632   0.000000  10.377054  11.920252   \n",
       "mec_4   9.980195  10.702584   9.637714  10.377054   0.000000   8.105383   \n",
       "\n",
       "       mec_6  mec_7  mec_8  mec_9  mec_10  mec_11  mec_12  mec_13  mec_14  \\\n",
       "mec_0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mec_1    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mec_2    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mec_3    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mec_4    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       mec_15  mec_16  mec_17       cloud  \n",
       "mec_0     0.0     0.0     0.0   98.912800  \n",
       "mec_1     0.0     0.0     0.0  104.609202  \n",
       "mec_2     0.0     0.0     0.0   92.055348  \n",
       "mec_3     0.0     0.0     0.0   84.851664  \n",
       "mec_4     0.0     0.0     0.0   99.076301  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18 entries, mec_0 to mec_17\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mec_0   18 non-null     float64\n",
      " 1   mec_1   18 non-null     float64\n",
      " 2   mec_2   18 non-null     float64\n",
      " 3   mec_3   18 non-null     float64\n",
      " 4   mec_4   18 non-null     float64\n",
      " 5   mec_5   18 non-null     float64\n",
      " 6   mec_6   18 non-null     float64\n",
      " 7   mec_7   18 non-null     float64\n",
      " 8   mec_8   18 non-null     float64\n",
      " 9   mec_9   18 non-null     float64\n",
      " 10  mec_10  18 non-null     float64\n",
      " 11  mec_11  18 non-null     float64\n",
      " 12  mec_12  18 non-null     float64\n",
      " 13  mec_13  18 non-null     float64\n",
      " 14  mec_14  18 non-null     float64\n",
      " 15  mec_15  18 non-null     float64\n",
      " 16  mec_16  18 non-null     float64\n",
      " 17  mec_17  18 non-null     float64\n",
      " 18  cloud   18 non-null     float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 2.8+ KB\n",
      "\n",
      "topology clustered -> topology_data\n",
      "{'number_of_servers': 18, 'private_cpu_capacities': [1417026512.123894, 1465835517.1380253, 1400296152.8672054, 1219863115.6758468, 1270376631.237273, 1348019534.1092064, 1786161289.9722981, 1380932007.7716885, 1739680378.9314957, 1606151704.3138125, 1722792016.067419, 1452119690.3718696, 1575323717.1732426, 1675176049.772993, 1465269239.5654364, 1565743740.4168038, 1715259832.5839007, 1225832428.456285], 'public_cpu_capacities': [768946447.3896191, 753418540.8443304, 702715947.6715652, 545197668.8935852, 670994513.1813464, 680525151.7601619, 811159071.5491732, 782943570.2288362, 501997671.50295806, 685198791.9005744, 822519853.1111488, 716138690.9607652, 822355072.296565, 556428866.3646028, 805978940.2755054, 790274917.5537901, 602437544.1146357, 709495765.381235], 'cloud_computational_capacity': 30000000000.0, 'connection_matrix': [[0.0, 9.798800609449902, 11.958295388571093, 11.470404384171585, 9.980195439399376, 8.8140500666217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.91279981562592], [9.798800609449902, 0.0, 8.375143239602235, 11.535600106180025, 10.702584376249934, 9.136893120492793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.60920207554163], [11.958295388571093, 8.375143239602235, 0.0, 8.814631907625701, 9.637714071509851, 9.170700424264968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 92.05534806322484], [11.470404384171585, 11.535600106180025, 8.814631907625701, 0.0, 10.37705391001423, 11.920252079923895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 84.85166371762908], [9.980195439399376, 10.702584376249934, 9.637714071509851, 10.37705391001423, 0.0, 8.10538323609413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.0763009651688], [8.8140500666217, 9.136893120492793, 9.170700424264968, 11.920252079923895, 8.10538323609413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 115.0792791055983], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.844690223161571, 9.566567838535661, 11.01158338193066, 10.132206014485726, 11.731761213672993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 115.87637059619391], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.844690223161571, 0.0, 8.17265481777462, 11.317250164676846, 9.944330066939582, 11.698994881774604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 85.49730491373893], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.566567838535661, 8.17265481777462, 0.0, 11.919271797879857, 9.162931925532463, 11.22074688068535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.13111014716404], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.01158338193066, 11.317250164676846, 11.919271797879857, 0.0, 11.8680001020066, 11.393785145055949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 87.20532264682294], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.132206014485726, 9.944330066939582, 9.162931925532463, 11.8680001020066, 0.0, 9.548734790752288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.89380625765318], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.731761213672993, 11.698994881774604, 11.22074688068535, 11.393785145055949, 9.548734790752288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.16242880696842], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.573089728358958, 10.155633210306574, 11.202595781660758, 10.69123291440641, 11.439129446848145, 94.68338717140213], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.573089728358958, 0.0, 10.795539716597093, 9.382485758460357, 8.156515169162681, 10.108953651086749, 86.2148806997884], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.155633210306574, 10.795539716597093, 0.0, 8.183423253938845, 9.055460579237527, 8.857865582666564, 100.51802149006446], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.202595781660758, 9.382485758460357, 8.183423253938845, 0.0, 10.922031113226154, 8.777507498932518, 85.56329833615376], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.69123291440641, 8.156515169162681, 9.055460579237527, 10.922031113226154, 0.0, 11.48804541896262, 109.44902761831553], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.439129446848145, 10.108953651086749, 8.857865582666564, 8.777507498932518, 11.48804541896262, 0.0, 119.21419244342577]], 'time_step': 1.0, 'topology_type': 'clustered', 'skip_k': 5, 'symmetric': True, 'num_clusters': 3}\n",
      "\n",
      "topology clustered -> meta_data\n",
      "{'generated_at_utc': '2025-11-05T07:48:30Z', 'fingerprint': '9a3a6cc2768b6834', 'env': {'python': '3.10.9', 'user': 'niush'}, 'units': {'compute': 'CPU cycles per slot', 'links': 'MB per slot', 'time_step': 'seconds'}, 'notes': {'inputs_unit': {'compute': 'CPU cycles per second', 'links': 'MB per second'}, 'conversion': 'per_slot = per_second * time_step', 'topology_semantics': {'skip_connections': \"k-nearest ring; each MEC connects to next 'skip_k' neighbors on a circle\"}}, 'hyperparameters': {'number_of_servers': 18, 'time_step': 1.0, 'private_cpu_min': 1200000000.0, 'private_cpu_max': 1800000000.0, 'public_cpu_min': 500000000.0, 'public_cpu_max': 900000000.0, 'cpu_total_min': None, 'cpu_total_max': None, 'public_share': None, 'cloud_capacity': 30000000000.0, 'cloud_capacity_min': None, 'cloud_capacity_max': None, 'horiz_cap_min': 8.0, 'horiz_cap_max': 12.0, 'cloud_cap_min': 80.0, 'cloud_cap_max': 120.0, 'topology_type': 'clustered', 'skip_k': 5, 'symmetric': True, 'num_clusters': 3, 'inter_cluster_frac': 0.0, 'seed': 20251229}}\n"
     ]
    }
   ],
   "source": [
    "load_topologies_from_directory(topology_dir)\n",
    "\n",
    "print('topology clustered -> connection_matrix')\n",
    "display(topologies['clustered']['connection_matrix'].head())\n",
    "topologies['clustered']['connection_matrix'].info()\n",
    "\n",
    "print('\\ntopology clustered -> topology_data')\n",
    "print(topologies['clustered']['topology_data'])\n",
    "\n",
    "print('\\ntopology clustered -> meta_data')\n",
    "print(topologies['clustered']['meta_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.2. Data Validation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the data, we must validate that required columns exist and that IDs match properly.\n",
    "\n",
    "**The code below performs three layers of checks:** \n",
    "\n",
    "- Validate each dataset (episodes/agents/arrivals/tasks)\n",
    "- Validate each topology (JSON and connection matrix)\n",
    "- Validate dataset–topology pairs for unit alignment and overall consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Generic helpers ----------\n",
    "def _require(cond: bool, msg: str, errors: list):\n",
    "    # Collect errors instead of stopping at first failure\n",
    "    if not cond:\n",
    "        errors.append(msg)\n",
    "\n",
    "def _has_cols(df: pd.DataFrame, cols: list) -> bool:\n",
    "    return all(c in df.columns for c in cols)\n",
    "\n",
    "# ---------- Dataset-level validation ----------\n",
    "def validate_one_dataset(dataset_key: str, ds: dict) -> list:\n",
    "    \"\"\"\n",
    "    Validate a single dataset pack (episodes/agents/arrivals/tasks) for one (episode, scenario).\n",
    "    'dataset_key' is just a label for error messages, e.g. 'ep_000/heavy'.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    episodes = ds.get(\"episodes\")\n",
    "    agents   = ds.get(\"agents\")\n",
    "    arrivals = ds.get(\"arrivals\")\n",
    "    tasks    = ds.get(\"tasks\")\n",
    "\n",
    "    # 1) Presence checks\n",
    "    _require(isinstance(episodes, pd.DataFrame), f\"[{dataset_key}] episodes missing or not a DataFrame\", errors)\n",
    "    _require(isinstance(agents,   pd.DataFrame), f\"[{dataset_key}] agents missing or not a DataFrame\", errors)\n",
    "    _require(isinstance(arrivals, pd.DataFrame), f\"[{dataset_key}] arrivals missing or not a DataFrame\", errors)\n",
    "    _require(isinstance(tasks,    pd.DataFrame), f\"[{dataset_key}] tasks missing or not a DataFrame\", errors)\n",
    "    if errors:\n",
    "        return errors\n",
    "\n",
    "    # 2) Required columns (based on your generators)\n",
    "    req_ep_cols  = [\"scenario\", \"episode_id\", \"Delta\", \"T_slots\", \"hours\", \"N_agents\", \"seed\"]\n",
    "    req_ag_cols  = [\"agent_id\", \"f_local\", \"m_local\", \"lam_sec\"]\n",
    "    req_ar_cols  = [\"scenario\", \"episode_id\", \"t_slot\", \"t_time\", \"agent_id\", \"task_id\"]\n",
    "    req_tk_cols  = [\n",
    "        \"scenario\",\"episode_id\",\"task_id\",\"agent_id\",\"t_arrival_slot\",\"t_arrival_time\",\n",
    "        \"b_mb\",\"rho_cyc_per_mb\",\"c_cycles\",\"mem_mb\",\"modality\",\n",
    "        \"has_deadline\",\"deadline_s\",\"deadline_time\",\"non_atomic\",\"split_ratio\",\"action_space_hint\"\n",
    "    ]\n",
    "    _require(_has_cols(episodes, req_ep_cols), f\"[{dataset_key}] episodes missing required columns\", errors)\n",
    "    _require(_has_cols(agents,   req_ag_cols), f\"[{dataset_key}] agents missing required columns\", errors)\n",
    "    _require(_has_cols(arrivals, req_ar_cols), f\"[{dataset_key}] arrivals missing required columns\", errors)\n",
    "    _require(_has_cols(tasks,    req_tk_cols), f\"[{dataset_key}] tasks missing required columns\", errors)\n",
    "    if errors:\n",
    "        return errors\n",
    "\n",
    "    # 3) Integrity checks\n",
    "    # unique task_id\n",
    "    _require(tasks[\"task_id\"].is_unique, f\"[{dataset_key}] task_id is not unique\", errors)\n",
    "\n",
    "    # agent id range & count vs episodes.N_agents\n",
    "    if len(agents):\n",
    "        min_id = agents[\"agent_id\"].min()\n",
    "        max_id = agents[\"agent_id\"].max()\n",
    "        expected_n = int(episodes[\"N_agents\"].iloc[0])\n",
    "        _require(min_id == 0, f\"[{dataset_key}] agent_id should start at 0 (got {min_id})\", errors)\n",
    "        _require(max_id == expected_n - 1,\n",
    "                 f\"[{dataset_key}] agent_id max should be N_agents-1 ({expected_n-1}), got {max_id}\", errors)\n",
    "\n",
    "    # cross refs\n",
    "    valid_agents = set(agents[\"agent_id\"].tolist())\n",
    "    bad_arr_agents = set(arrivals[\"agent_id\"]) - valid_agents\n",
    "    bad_task_agents = set(tasks[\"agent_id\"]) - valid_agents\n",
    "    _require(len(bad_arr_agents) == 0, f\"[{dataset_key}] arrivals contain unknown agent_id(s): {sorted(bad_arr_agents)}\", errors)\n",
    "    _require(len(bad_task_agents) == 0, f\"[{dataset_key}] tasks contain unknown agent_id(s): {sorted(bad_task_agents)}\", errors)\n",
    "\n",
    "    # non-negative task numerics\n",
    "    for col in [\"b_mb\",\"rho_cyc_per_mb\",\"c_cycles\",\"mem_mb\"]:\n",
    "        if col in tasks.columns:\n",
    "            _require((tasks[col] >= 0).all(), f\"[{dataset_key}] tasks.{col} has negative values\", errors)\n",
    "\n",
    "    # deadline coherence\n",
    "    if \"has_deadline\" in tasks.columns and \"deadline_s\" in tasks.columns:\n",
    "        bad_deadline = tasks[(tasks[\"has_deadline\"] == 1) & ((tasks[\"deadline_s\"].isna()) | (tasks[\"deadline_s\"] <= 0))]\n",
    "        _require(len(bad_deadline) == 0, f\"[{dataset_key}] tasks with deadline have invalid deadline_s\", errors)\n",
    "\n",
    "    # single Delta / T_slots inside this (episode, scenario)\n",
    "    _require(episodes[\"Delta\"].nunique() == 1, f\"[{dataset_key}] multiple Delta values in episodes\", errors)\n",
    "    _require(episodes[\"T_slots\"].nunique() == 1, f\"[{dataset_key}] multiple T_slots in episodes\", errors)\n",
    "\n",
    "    # arrivals inside range\n",
    "    T_slots = int(episodes[\"T_slots\"].iloc[0])\n",
    "    _require(int(tasks[\"t_arrival_slot\"].max()) <= T_slots - 1,\n",
    "             f\"[{dataset_key}] t_arrival_slot exceeds T_slots-1\", errors)\n",
    "\n",
    "    return errors\n",
    "\n",
    "# ---------- Topology-level validation ----------\n",
    "def validate_one_topology(topology_name: str, topo_entry: dict) -> list:\n",
    "    errors = []\n",
    "    topo = topo_entry.get(\"topology_data\")\n",
    "    meta = topo_entry.get(\"meta_data\")\n",
    "    Mdf  = topo_entry.get(\"connection_matrix\")\n",
    "\n",
    "    _require(isinstance(topo, dict), f\"[{topology_name}] topology_data missing or not a dict\", errors)\n",
    "    _require(isinstance(meta, dict), f\"[{topology_name}] meta_data missing or not a dict\", errors)\n",
    "    _require(isinstance(Mdf,  pd.DataFrame), f\"[{topology_name}] connection_matrix CSV missing or not a DataFrame\", errors)\n",
    "    if errors:\n",
    "        return errors\n",
    "\n",
    "    req_keys = [\n",
    "        \"number_of_servers\",\"private_cpu_capacities\",\"public_cpu_capacities\",\n",
    "        \"cloud_computational_capacity\",\"connection_matrix\",\"time_step\"\n",
    "    ]\n",
    "    for k in req_keys:\n",
    "        _require(k in topo, f\"[{topology_name}] topology.json missing key: {k}\", errors)\n",
    "    if errors:\n",
    "        return errors\n",
    "\n",
    "    K = int(topo[\"number_of_servers\"])\n",
    "    _require(len(topo[\"private_cpu_capacities\"]) == K, f\"[{topology_name}] private_cpu_capacities length != K\", errors)\n",
    "    _require(len(topo[\"public_cpu_capacities\"])  == K, f\"[{topology_name}] public_cpu_capacities length != K\", errors)\n",
    "\n",
    "    Mjson = topo[\"connection_matrix\"]\n",
    "    _require(isinstance(Mjson, list) and len(Mjson) == K and (K == 0 or len(Mjson[0]) == K+1),\n",
    "             f\"[{topology_name}] connection_matrix in JSON must be K x (K+1)\", errors)\n",
    "    _require(Mdf.shape == (K, K+1), f\"[{topology_name}] connection_matrix.csv shape must be K x (K+1)\", errors)\n",
    "\n",
    "    vert_csv = Mdf.iloc[:, K]\n",
    "    _require((vert_csv > 0).all(), f\"[{topology_name}] MEC->Cloud capacities must be > 0\", errors)\n",
    "    horiz_csv = Mdf.iloc[:, :K]\n",
    "    _require((horiz_csv.values >= 0).all(), f\"[{topology_name}] MEC<->MEC capacities contain negatives\", errors)\n",
    "\n",
    "    _require(\"time_step\" in topo, f\"[{topology_name}] missing time_step\", errors)\n",
    "    return errors\n",
    "\n",
    "# ---------- Pairwise validation (dataset <-> topology) ----------\n",
    "def validate_dataset_topology_pair(ep_name: str, scenario: str, ds: dict,\n",
    "                                   topology_name: str, topo_entry: dict) -> list:\n",
    "    \"\"\"\n",
    "    Validate alignment between one (episode, scenario) dataset and one topology.\n",
    "    Ensures Delta == time_step and basic feasibility checks.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    episodes = ds[\"episodes\"]\n",
    "    topo     = topo_entry[\"topology_data\"]\n",
    "    K        = int(topo[\"number_of_servers\"])\n",
    "\n",
    "    # Delta vs time_step\n",
    "    Delta = float(episodes[\"Delta\"].iloc[0])\n",
    "    time_step = float(topo[\"time_step\"])\n",
    "    _require(abs(Delta - time_step) < 1e-9,\n",
    "             f\"[{ep_name}/{scenario} x {topology_name}] Delta ({Delta}) != time_step ({time_step})\", errors)\n",
    "\n",
    "    # Non-negative compute capacities\n",
    "    priv = topo[\"private_cpu_capacities\"]\n",
    "    pub  = topo[\"public_cpu_capacities\"]\n",
    "    cloud = topo[\"cloud_computational_capacity\"]\n",
    "    _require(all(x >= 0 for x in priv) and all(x >= 0 for x in pub) and cloud >= 0,\n",
    "             f\"[{ep_name}/{scenario} x {topology_name}] negative compute capacities detected\", errors)\n",
    "\n",
    "    # Simple agent→MEC mapping (modulo) is within bounds\n",
    "    N_agents = int(episodes[\"N_agents\"].iloc[0])\n",
    "    mapped = [(aid % K) for aid in range(N_agents)] if K > 0 else []\n",
    "    _require(all(0 <= m < K for m in mapped) if mapped else True,\n",
    "             f\"[{ep_name}/{scenario} x {topology_name}] agent->MEC mapping out of bounds\", errors)\n",
    "\n",
    "    return errors\n",
    "\n",
    "# ---------- Episode-level Delta consistency across scenarios ----------\n",
    "def validate_episode_delta_consistency(ep_name: str, ep_dict: dict) -> list:\n",
    "    \"\"\"\n",
    "    Check that all scenarios inside one episode share the same Delta and T_slots.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    deltas = set()\n",
    "    tslots = set()\n",
    "    for scenario, ds in ep_dict.items():\n",
    "        ep_df = ds[\"episodes\"]\n",
    "        if len(ep_df):\n",
    "            deltas.add(float(ep_df[\"Delta\"].iloc[0]))\n",
    "            tslots.add(int(ep_df[\"T_slots\"].iloc[0]))\n",
    "        else:\n",
    "            errors.append(f\"[{ep_name}/{scenario}] episodes.csv is empty\")\n",
    "    if len(deltas) > 1:\n",
    "        errors.append(f\"[{ep_name}] multiple Delta values across scenarios: {sorted(deltas)}\")\n",
    "    if len(tslots) > 1:\n",
    "        errors.append(f\"[{ep_name}] multiple T_slots values across scenarios: {sorted(tslots)}\")\n",
    "    return errors\n",
    "\n",
    "# ---------- Orchestrator over ALL datasets (episode-first) and ALL topologies ----------\n",
    "def validate_everything_episode_first(datasets: dict, topologies: dict) -> dict:\n",
    "    \"\"\"\n",
    "    'datasets' shape:\n",
    "        {\n",
    "          \"ep_000\": {\n",
    "             \"light\":   {\"episodes\": df, \"agents\": df, \"arrivals\": df, \"tasks\": df},\n",
    "             \"moderate\":{...},\n",
    "             \"heavy\":   {...}\n",
    "          },\n",
    "          \"ep_001\": {...}\n",
    "        }\n",
    "    \"\"\"\n",
    "    report = {\"datasets\": {}, \"episodes_consistency\": {}, \"topologies\": {}, \"pairs\": {}}\n",
    "\n",
    "    # 1) Validate each (episode, scenario)\n",
    "    for ep_name, ep_pack in datasets.items():\n",
    "        report[\"datasets\"][ep_name] = {}\n",
    "        for scenario, dpack in ep_pack.items():\n",
    "            key = f\"{ep_name}/{scenario}\"\n",
    "            errs = validate_one_dataset(key, dpack)\n",
    "            report[\"datasets\"][ep_name][scenario] = {\"ok\": len(errs) == 0, \"errors\": errs}\n",
    "\n",
    "    # 2) Episode-level Delta/T_slots consistency across scenarios\n",
    "    for ep_name, ep_pack in datasets.items():\n",
    "        errs = validate_episode_delta_consistency(ep_name, ep_pack)\n",
    "        report[\"episodes_consistency\"][ep_name] = {\"ok\": len(errs) == 0, \"errors\": errs}\n",
    "\n",
    "    # 3) Validate each topology\n",
    "    for tname, tpack in topologies.items():\n",
    "        errs = validate_one_topology(tname, tpack)\n",
    "        report[\"topologies\"][tname] = {\"ok\": len(errs) == 0, \"errors\": errs}\n",
    "\n",
    "    # 4) Pairwise validation for every valid (ep, scenario) × valid topology\n",
    "    for ep_name, ep_pack in datasets.items():\n",
    "        for scenario, dpack in ep_pack.items():\n",
    "            d_ok = report[\"datasets\"][ep_name][scenario][\"ok\"]\n",
    "            ep_ok = report[\"episodes_consistency\"][ep_name][\"ok\"]\n",
    "            for tname, tres in report[\"topologies\"].items():\n",
    "                key = f\"{ep_name}/{scenario}__{tname}\"\n",
    "                if d_ok and ep_ok and tres[\"ok\"]:\n",
    "                    errs = validate_dataset_topology_pair(ep_name, scenario, dpack, tname, topologies[tname])\n",
    "                    report[\"pairs\"][key] = {\"ok\": len(errs) == 0, \"errors\": errs}\n",
    "                else:\n",
    "                    report[\"pairs\"][key] = {\"ok\": False, \"errors\": [\"Skipped due to upstream invalid dataset/episode/topology.\"]}\n",
    "\n",
    "    return report\n",
    "\n",
    "# ---------- Pretty printer ----------\n",
    "def print_validation_report_episode_first(report: dict):\n",
    "    print(\"=== DATASETS (episode/scenario) ===\")\n",
    "    for ep_name, ep_res in report[\"datasets\"].items():\n",
    "        for scenario, info in ep_res.items():\n",
    "            status = \"OK\" if info[\"ok\"] else \"FAIL\"\n",
    "            print(f\"[{status}] {ep_name}/{scenario}\")\n",
    "            for e in info[\"errors\"]:\n",
    "                print(f\"  - {e}\")\n",
    "\n",
    "    print(\"\\n=== EPISODE-LEVEL CONSISTENCY (Delta & T_slots) ===\")\n",
    "    for ep_name, info in report[\"episodes_consistency\"].items():\n",
    "        status = \"OK\" if info[\"ok\"] else \"FAIL\"\n",
    "        print(f\"[{status}] {ep_name}\")\n",
    "        for e in info[\"errors\"]:\n",
    "            print(f\"  - {e}\")\n",
    "\n",
    "    print(\"\\n=== TOPOLOGIES ===\")\n",
    "    for name, info in report[\"topologies\"].items():\n",
    "        status = \"OK\" if info[\"ok\"] else \"FAIL\"\n",
    "        print(f\"[{status}] {name}\")\n",
    "        for e in info[\"errors\"]:\n",
    "            print(f\"  - {e}\")\n",
    "\n",
    "    print(\"\\n=== (EPISODE/SCENARIO) × TOPOLOGY PAIRS ===\")\n",
    "    for key, info in report[\"pairs\"].items():\n",
    "        status = \"OK\" if info[\"ok\"] else \"FAIL\"\n",
    "        print(f\"[{status}] {key}\")\n",
    "        for e in info[\"errors\"]:\n",
    "            print(f\"  - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASETS (episode/scenario) ===\n",
      "[OK] ep_000/heavy\n",
      "[OK] ep_000/light\n",
      "[OK] ep_000/moderate\n",
      "\n",
      "=== EPISODE-LEVEL CONSISTENCY (Delta & T_slots) ===\n",
      "[OK] ep_000\n",
      "\n",
      "=== TOPOLOGIES ===\n",
      "[OK] clustered\n",
      "[OK] full_mesh\n",
      "[OK] sparse_ring\n",
      "\n",
      "=== (EPISODE/SCENARIO) × TOPOLOGY PAIRS ===\n",
      "[OK] ep_000/heavy__clustered\n",
      "[OK] ep_000/heavy__full_mesh\n",
      "[OK] ep_000/heavy__sparse_ring\n",
      "[OK] ep_000/light__clustered\n",
      "[OK] ep_000/light__full_mesh\n",
      "[OK] ep_000/light__sparse_ring\n",
      "[OK] ep_000/moderate__clustered\n",
      "[OK] ep_000/moderate__full_mesh\n",
      "[OK] ep_000/moderate__sparse_ring\n"
     ]
    }
   ],
   "source": [
    "# ---- run the new validator ----\n",
    "report = validate_everything_episode_first(datasets, topologies)\n",
    "print_validation_report_episode_first(report)\n",
    "\n",
    "all_ok = (\n",
    "    all(info[\"ok\"] for ep in report[\"datasets\"].values() for info in ep.values())\n",
    "    and all(info[\"ok\"] for info in report[\"episodes_consistency\"].values())\n",
    "    and all(info[\"ok\"] for info in report[\"topologies\"].values())\n",
    "    and all(info[\"ok\"] for info in report[\"pairs\"].values())\n",
    ")\n",
    "if not all_ok:\n",
    "    raise RuntimeError(\"Validation failed. See printed report for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.3. Units Alignment </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we align units for all dataset episodes and scenarios\n",
    "and run consistency checks against all topologies.\n",
    "- Datasets: use Delta from episodes.csv; add per-slot helpers:\n",
    "    agents.f_local_slot (cycles/slot), tasks.deadline_slots (integer or NaN)\n",
    "    \n",
    "- Topologies: capacities are already per-slot (generator multiplied by Δ);\n",
    "    we only verify time_step == Delta and non-negative capacities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Helpers: safe getters =====\n",
    "def _get_delta(episodes_df: pd.DataFrame) -> float:\n",
    "    # Expect a single Delta value in episodes; take the first row\n",
    "    if \"Delta\" not in episodes_df.columns:\n",
    "        raise ValueError(\"episodes.csv must contain a 'Delta' column.\")\n",
    "    return float(episodes_df[\"Delta\"].iloc[0])\n",
    "\n",
    "def _ensure_numeric_positive(name: str, arr: np.ndarray):\n",
    "    # Basic sanity: finite and no negatives for capacities/links\n",
    "    if not np.isfinite(arr).all():\n",
    "        raise ValueError(f\"{name} contains non-finite values.\")\n",
    "    if (arr < 0).any():\n",
    "        raise ValueError(f\"{name} contains negative values.\")\n",
    "\n",
    "# ===== Alignment: per-dataset (one (episode, scenario) pack) =====\n",
    "def align_units_for_dataset(dataset: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Given one dataset dict {\"episodes\",\"agents\",\"arrivals\",\"tasks\"},\n",
    "    return a copy with aligned/derived columns (per-slot helpers).\n",
    "    \"\"\"\n",
    "    episodes = dataset[\"episodes\"].copy()\n",
    "    agents   = dataset[\"agents\"].copy()\n",
    "    arrivals = dataset[\"arrivals\"].copy()\n",
    "    tasks    = dataset[\"tasks\"].copy()\n",
    "\n",
    "    Delta = _get_delta(episodes)\n",
    "\n",
    "    # Agents: add per-slot compute capacity helper (cycles/slot)\n",
    "    if \"f_local\" not in agents.columns:\n",
    "        raise ValueError(\"agents.csv must contain 'f_local'.\")\n",
    "    agents[\"f_local\"] = agents[\"f_local\"].astype(float)\n",
    "    agents[\"f_local_slot\"] = agents[\"f_local\"] * Delta\n",
    "\n",
    "    # Memory is MB; keep as float\n",
    "    if \"m_local\" in agents.columns:\n",
    "        agents[\"m_local\"] = agents[\"m_local\"].astype(float)\n",
    "\n",
    "    # Tasks: ensure integer arrival slot\n",
    "    if \"t_arrival_slot\" not in tasks.columns:\n",
    "        raise ValueError(\"tasks.csv must contain 't_arrival_slot'.\")\n",
    "    tasks[\"t_arrival_slot\"] = tasks[\"t_arrival_slot\"].astype(int)\n",
    "\n",
    "    # Build deadline_slots = ceil(deadline_s / Delta) when has_deadline == 1, else NaN\n",
    "    if \"has_deadline\" in tasks.columns and \"deadline_s\" in tasks.columns:\n",
    "        def _to_deadline_slots(row):\n",
    "            if int(row[\"has_deadline\"]) == 1 and np.isfinite(row[\"deadline_s\"]):\n",
    "                return int(math.ceil(float(row[\"deadline_s\"]) / Delta))\n",
    "            return np.nan\n",
    "        tasks[\"deadline_slots\"] = tasks.apply(_to_deadline_slots, axis=1)\n",
    "        # Keep as nullable integer when possible\n",
    "        try:\n",
    "            tasks[\"deadline_slots\"] = tasks[\"deadline_slots\"].astype(\"Int64\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Ensure key numeric task fields are floats\n",
    "    for col in [\"b_mb\", \"rho_cyc_per_mb\", \"c_cycles\", \"mem_mb\"]:\n",
    "        if col in tasks.columns:\n",
    "            tasks[col] = tasks[col].astype(float)\n",
    "\n",
    "    return {\n",
    "        \"episodes\": episodes,\n",
    "        \"agents\":   agents,\n",
    "        \"arrivals\": arrivals,\n",
    "        \"tasks\":    tasks,\n",
    "    }\n",
    "\n",
    "# ===== Verification: per-topology against a target Delta =====\n",
    "def verify_topology_units(topology: Dict[str, Any], target_Delta: float) -> Tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Ensure topology capacities are per-slot and consistent with dataset Delta:\n",
    "    - time_step == target_Delta\n",
    "    - shapes are valid (K x (K+1))\n",
    "    - capacities non-negative\n",
    "    Returns (ok, message).\n",
    "    \"\"\"\n",
    "    # time_step check\n",
    "    ts = float(topology.get(\"time_step\", -1.0))\n",
    "    if not np.isclose(ts, target_Delta, atol=1e-9):\n",
    "        return (False, f\"time_step mismatch (topology={ts}, dataset Delta={target_Delta})\")\n",
    "\n",
    "    # K and lists\n",
    "    K = int(topology.get(\"number_of_servers\", -1))\n",
    "    priv = np.array(topology.get(\"private_cpu_capacities\", []), dtype=float)\n",
    "    pub  = np.array(topology.get(\"public_cpu_capacities\", []), dtype=float)\n",
    "    cloud = float(topology.get(\"cloud_computational_capacity\", -1.0))\n",
    "    M = np.array(topology.get(\"connection_matrix\", []), dtype=float)\n",
    "\n",
    "    if K <= 0:\n",
    "        return (False, \"Invalid 'number_of_servers' (K<=0).\")\n",
    "    if priv.shape[0] != K or pub.shape[0] != K:\n",
    "        return (False, \"private/public capacities must have length K.\")\n",
    "    if M.shape != (K, K+1):\n",
    "        return (False, f\"connection_matrix shape must be (K, K+1), got {M.shape}.\")\n",
    "\n",
    "    # Non-negative checks\n",
    "    _ensure_numeric_positive(\"private_cpu_capacities\", priv)\n",
    "    _ensure_numeric_positive(\"public_cpu_capacities\",  pub)\n",
    "    if not np.isfinite(cloud) or cloud < 0:\n",
    "        return (False, \"cloud_computational_capacity must be non-negative and finite.\")\n",
    "    _ensure_numeric_positive(\"connection_matrix\", M)\n",
    "\n",
    "    return (True, \"topology verified (per-slot, consistent).\")\n",
    "\n",
    "# ===== Batch alignment for ALL datasets (episode-first) & ALL topologies =====\n",
    "def align_all_units_episode_first(\n",
    "    datasets_ep_first: Dict[str, Dict[str, Dict[str, pd.DataFrame]]],\n",
    "    topologies_by_name: Dict[str, Dict[str, Any]]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Input 'datasets_ep_first' shape:\n",
    "        {\n",
    "          \"ep_000\": {\n",
    "             \"light\":   {\"episodes\": df, \"agents\": df, \"arrivals\": df, \"tasks\": df},\n",
    "             \"moderate\":{...},\n",
    "             \"heavy\":   {...}\n",
    "          },\n",
    "          \"ep_001\": {...}\n",
    "        }\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          \"datasets_aligned\": { ep_name: { scenario: aligned_pack, ... }, ... },\n",
    "          \"topology_checks\":  { topo_name: { ep_name: { scenario: {ok, message} } } }\n",
    "        }\n",
    "    \"\"\"\n",
    "    out = {\n",
    "        \"datasets_aligned\": {},\n",
    "        \"topology_checks\":  {}\n",
    "    }\n",
    "\n",
    "    # Align datasets (episode/scenario)\n",
    "    for ep_name, ep_pack in datasets_ep_first.items():\n",
    "        out[\"datasets_aligned\"][ep_name] = {}\n",
    "        for scenario, ds in ep_pack.items():\n",
    "            try:\n",
    "                out[\"datasets_aligned\"][ep_name][scenario] = align_units_for_dataset(ds)\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"[{ep_name}/{scenario}] dataset alignment failed: {e}\") from e\n",
    "\n",
    "    # Verify each topology against each (episode, scenario) Delta\n",
    "    for topo_name, topo_bundle in topologies_by_name.items():\n",
    "        topo_obj = topo_bundle.get(\"topology_data\", None)\n",
    "        if not isinstance(topo_obj, dict):\n",
    "            raise RuntimeError(f\"[{topo_name}] 'topology_data' missing or not a dict.\")\n",
    "        out[\"topology_checks\"][topo_name] = {}\n",
    "\n",
    "        for ep_name, ep_pack in out[\"datasets_aligned\"].items():\n",
    "            out[\"topology_checks\"][topo_name][ep_name] = {}\n",
    "            for scenario, aligned in ep_pack.items():\n",
    "                Delta = _get_delta(aligned[\"episodes\"])\n",
    "                ok, msg = verify_topology_units(topo_obj, Delta)\n",
    "                out[\"topology_checks\"][topo_name][ep_name][scenario] = {\"ok\": bool(ok), \"message\": msg}\n",
    "\n",
    "    return out\n",
    "\n",
    "# ===== Pretty printer (episode-first) =====\n",
    "def print_alignment_summary_episode_first(result: Dict[str, Any]):\n",
    "    # Datasets\n",
    "    print(\"=== DATASETS (aligned, episode/scenario) ===\")\n",
    "    for ep_name in sorted(result[\"datasets_aligned\"].keys()):\n",
    "        for scenario in sorted(result[\"datasets_aligned\"][ep_name].keys()):\n",
    "            ds = result[\"datasets_aligned\"][ep_name][scenario]\n",
    "            Delta = _get_delta(ds[\"episodes\"])\n",
    "            n_tasks = len(ds[\"tasks\"])\n",
    "            n_agents = len(ds[\"agents\"])\n",
    "            print(f\"[{ep_name}/{scenario}] Delta={Delta}  tasks={n_tasks}  agents={n_agents}\")\n",
    "\n",
    "    # Topologies\n",
    "    print(\"\\n=== TOPOLOGIES (checks vs each episode/scenario) ===\")\n",
    "    for topo_name, by_ep in result[\"topology_checks\"].items():\n",
    "        print(f\"Topology: {topo_name}\")\n",
    "        for ep_name in sorted(by_ep.keys()):\n",
    "            for scenario in sorted(by_ep[ep_name].keys()):\n",
    "                r = by_ep[ep_name][scenario]\n",
    "                flag = \"OK\" if r[\"ok\"] else \"FAIL\"\n",
    "                print(f\"  - {ep_name}/{scenario}: {flag}  -> {r['message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASETS (aligned, episode/scenario) ===\n",
      "[ep_000/heavy] Delta=1.0  tasks=30636  agents=18\n",
      "[ep_000/light] Delta=1.0  tasks=2113  agents=18\n",
      "[ep_000/moderate] Delta=1.0  tasks=8262  agents=18\n",
      "\n",
      "=== TOPOLOGIES (checks vs each episode/scenario) ===\n",
      "Topology: clustered\n",
      "  - ep_000/heavy: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/light: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/moderate: OK  -> topology verified (per-slot, consistent).\n",
      "Topology: full_mesh\n",
      "  - ep_000/heavy: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/light: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/moderate: OK  -> topology verified (per-slot, consistent).\n",
      "Topology: sparse_ring\n",
      "  - ep_000/heavy: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/light: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/moderate: OK  -> topology verified (per-slot, consistent).\n",
      "\n",
      " ===EXAMPLE===\n"
     ]
    }
   ],
   "source": [
    "# ==== Example driver (after your loading step) ====\n",
    "# datasets: episode-first dict\n",
    "# topologies: { \"full_mesh\": {...}, \"clustered\": {...}, \"sparse_ring\": {...} }\n",
    "\n",
    "result_align = align_all_units_episode_first(datasets_ep_first=datasets, topologies_by_name=topologies)\n",
    "print_alignment_summary_episode_first(result_align)\n",
    "\n",
    "# Access aligned data for a specific episode/scenario:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "aligned_light_ep0 = result_align[\"datasets_aligned\"][\"ep_000\"][\"light\"]\n",
    "agents_ep0_light  = aligned_light_ep0[\"agents\"]   # has f_local_slot\n",
    "tasks_ep0_light   = aligned_light_ep0[\"tasks\"]    # has deadline_slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.4. Build Scenario–Topology Pairs </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, all datasets are paired with all topologies (Cartesian product). Each pair is checked for matching time parameters, then a basic bundle is created for further enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _delta_from_episodes(episodes_df: pd.DataFrame) -> float:\n",
    "    \"\"\"Extract a single Delta value from episodes table.\"\"\"\n",
    "    if \"Delta\" not in episodes_df.columns:\n",
    "        raise ValueError(\"episodes.csv must contain 'Delta'.\")\n",
    "    return float(episodes_df[\"Delta\"].iloc[0])\n",
    "\n",
    "def _topology_time_step(topo_json: Dict[str, Any]) -> float:\n",
    "    \"\"\"Extract the topology time_step.\"\"\"\n",
    "    ts = topo_json.get(\"time_step\", None)\n",
    "    if ts is None:\n",
    "        raise ValueError(\"topology.json must contain 'time_step'.\")\n",
    "    return float(ts)\n",
    "\n",
    "def build_topology_episode_pairs(\n",
    "    datasets_ep_first: Dict[str, Dict[str, Dict[str, pd.DataFrame]]],\n",
    "    topologies: Dict[str, Dict[str, Any]],\n",
    "    strict_delta_match: bool = True\n",
    ") -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Build pairs between every topology and every (episode, scenario) dataset.\n",
    "    If strict_delta_match is True, any mismatch between dataset Delta and topology time_step raises an error.\n",
    "    \"\"\"\n",
    "    pairs_by_topology: Dict[str, Dict[str, Dict[str, Any]]] = {}\n",
    "\n",
    "    # Iterate topologies first (topology-centric)\n",
    "    for topo_name, topo_bundle in topologies.items():\n",
    "        topo_data = topo_bundle.get(\"topology_data\", None)\n",
    "        meta_data = topo_bundle.get(\"meta_data\", None)\n",
    "        cm_df     = topo_bundle.get(\"connection_matrix\", None)\n",
    "\n",
    "        if not isinstance(topo_data, dict):\n",
    "            raise ValueError(f\"[{topo_name}] topology_data missing or not a dict.\")\n",
    "        if cm_df is None:\n",
    "            raise ValueError(f\"[{topo_name}] connection_matrix DataFrame is missing.\")\n",
    "\n",
    "        # Validate K and connection matrix shape\n",
    "        K = int(topo_data.get(\"number_of_servers\", -1))\n",
    "        if K <= 0:\n",
    "            raise ValueError(f\"[{topo_name}] invalid 'number_of_servers' in topology.json\")\n",
    "        if not (cm_df.shape[0] == K and cm_df.shape[1] == K + 1):\n",
    "            raise ValueError(\n",
    "                f\"[{topo_name}] connection_matrix shape must be (K, K+1); got {cm_df.shape}\"\n",
    "            )\n",
    "\n",
    "        topo_ts = _topology_time_step(topo_data)\n",
    "\n",
    "        # Prepare container for this topology\n",
    "        if topo_name not in pairs_by_topology:\n",
    "            pairs_by_topology[topo_name] = {}\n",
    "\n",
    "        # Compare with every (episode, scenario)\n",
    "        for ep_name, scenarios in datasets_ep_first.items():\n",
    "            if ep_name not in pairs_by_topology[topo_name]:\n",
    "                pairs_by_topology[topo_name][ep_name] = {}\n",
    "\n",
    "            for scen_name, ds in scenarios.items():\n",
    "                ds_Delta = _delta_from_episodes(ds[\"episodes\"])\n",
    "                delta_ok = bool(np.isclose(ds_Delta, topo_ts, atol=1e-12))\n",
    "                msg = \"OK\" if delta_ok else (\n",
    "                    f\"time_step mismatch (dataset Delta={ds_Delta}, topology time_step={topo_ts})\"\n",
    "                )\n",
    "                if (not delta_ok) and strict_delta_match:\n",
    "                    raise ValueError(f\"[{topo_name} × {ep_name}/{scen_name}] {msg}\")\n",
    "\n",
    "                # Store bundle\n",
    "                pairs_by_topology[topo_name][ep_name][scen_name] = {\n",
    "                    \"scenario\": scen_name,\n",
    "                    \"episode\": ep_name,\n",
    "                    \"topology\": topo_name,\n",
    "                    \"Delta\": ds_Delta,\n",
    "                    \"K\": K,\n",
    "                    \"dataset\": ds,\n",
    "                    \"topology_data\": topo_data,\n",
    "                    \"topology_meta_data\": meta_data,\n",
    "                    \"connection_matrix_df\": cm_df,\n",
    "                    \"checks\": {\"delta_match\": delta_ok, \"message\": msg}\n",
    "                }\n",
    "\n",
    "    return pairs_by_topology\n",
    "\n",
    "def print_pairs_summary_topology_first_ep(\n",
    "    pairs_by_topology: Dict[str, Dict[str, Dict[str, Any]]]\n",
    ") -> None:\n",
    "    \"\"\"Pretty-print summary as topology → episode → scenario.\"\"\"\n",
    "    print(\"=== TOPOLOGY × EPISODE × SCENARIO ===\")\n",
    "    for topo_name, by_ep in pairs_by_topology.items():\n",
    "        print(f\"[TOPOLOGY] {topo_name}\")\n",
    "        for ep_name in sorted(by_ep.keys()):\n",
    "            print(f\"  ├─ Episode: {ep_name}\")\n",
    "            scen_map = by_ep[ep_name]\n",
    "            for scen_name in sorted(scen_map.keys()):\n",
    "                bundle = scen_map[scen_name]\n",
    "                flag  = \"OK\" if bundle[\"checks\"][\"delta_match\"] else \"FAIL\"\n",
    "                K     = bundle[\"K\"]\n",
    "                Delta = bundle[\"Delta\"]\n",
    "                msg   = bundle[\"checks\"][\"message\"]\n",
    "                print(f\"  │    - [{flag}] {scen_name:9s} | K={K:2d}  Δ={Delta:g}  -> {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOPOLOGY × EPISODE × SCENARIO ===\n",
      "[TOPOLOGY] clustered\n",
      "  ├─ Episode: ep_000\n",
      "  │    - [OK] heavy     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] light     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] moderate  | K=18  Δ=1  -> OK\n",
      "[TOPOLOGY] full_mesh\n",
      "  ├─ Episode: ep_000\n",
      "  │    - [OK] heavy     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] light     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] moderate  | K=18  Δ=1  -> OK\n",
      "[TOPOLOGY] sparse_ring\n",
      "  ├─ Episode: ep_000\n",
      "  │    - [OK] heavy     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] light     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] moderate  | K=18  Δ=1  -> OK\n",
      "\n",
      " ===EXAMPLE===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mec_0</th>\n",
       "      <th>mec_1</th>\n",
       "      <th>mec_2</th>\n",
       "      <th>mec_3</th>\n",
       "      <th>mec_4</th>\n",
       "      <th>mec_5</th>\n",
       "      <th>mec_6</th>\n",
       "      <th>mec_7</th>\n",
       "      <th>mec_8</th>\n",
       "      <th>mec_9</th>\n",
       "      <th>mec_10</th>\n",
       "      <th>mec_11</th>\n",
       "      <th>mec_12</th>\n",
       "      <th>mec_13</th>\n",
       "      <th>mec_14</th>\n",
       "      <th>mec_15</th>\n",
       "      <th>mec_16</th>\n",
       "      <th>mec_17</th>\n",
       "      <th>cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mec_0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.798801</td>\n",
       "      <td>11.958295</td>\n",
       "      <td>11.470404</td>\n",
       "      <td>9.980195</td>\n",
       "      <td>8.814050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.912800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_1</th>\n",
       "      <td>9.798801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.375143</td>\n",
       "      <td>11.535600</td>\n",
       "      <td>10.702584</td>\n",
       "      <td>9.136893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.609202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_2</th>\n",
       "      <td>11.958295</td>\n",
       "      <td>8.375143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.814632</td>\n",
       "      <td>9.637714</td>\n",
       "      <td>9.170700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.055348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_3</th>\n",
       "      <td>11.470404</td>\n",
       "      <td>11.535600</td>\n",
       "      <td>8.814632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.377054</td>\n",
       "      <td>11.920252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.851664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_4</th>\n",
       "      <td>9.980195</td>\n",
       "      <td>10.702584</td>\n",
       "      <td>9.637714</td>\n",
       "      <td>10.377054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.105383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.076301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_5</th>\n",
       "      <td>8.814050</td>\n",
       "      <td>9.136893</td>\n",
       "      <td>9.170700</td>\n",
       "      <td>11.920252</td>\n",
       "      <td>8.105383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.079279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.844690</td>\n",
       "      <td>9.566568</td>\n",
       "      <td>11.011583</td>\n",
       "      <td>10.132206</td>\n",
       "      <td>11.731761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.876371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.844690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.172655</td>\n",
       "      <td>11.317250</td>\n",
       "      <td>9.944330</td>\n",
       "      <td>11.698995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.497305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.566568</td>\n",
       "      <td>8.172655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.919272</td>\n",
       "      <td>9.162932</td>\n",
       "      <td>11.220747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.131110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.011583</td>\n",
       "      <td>11.317250</td>\n",
       "      <td>11.919272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.868000</td>\n",
       "      <td>11.393785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.205323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.132206</td>\n",
       "      <td>9.944330</td>\n",
       "      <td>9.162932</td>\n",
       "      <td>11.868000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.548735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.893806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.731761</td>\n",
       "      <td>11.698995</td>\n",
       "      <td>11.220747</td>\n",
       "      <td>11.393785</td>\n",
       "      <td>9.548735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.162429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.573090</td>\n",
       "      <td>10.155633</td>\n",
       "      <td>11.202596</td>\n",
       "      <td>10.691233</td>\n",
       "      <td>11.439129</td>\n",
       "      <td>94.683387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.573090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.795540</td>\n",
       "      <td>9.382486</td>\n",
       "      <td>8.156515</td>\n",
       "      <td>10.108954</td>\n",
       "      <td>86.214881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.155633</td>\n",
       "      <td>10.795540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.183423</td>\n",
       "      <td>9.055461</td>\n",
       "      <td>8.857866</td>\n",
       "      <td>100.518021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.202596</td>\n",
       "      <td>9.382486</td>\n",
       "      <td>8.183423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.922031</td>\n",
       "      <td>8.777507</td>\n",
       "      <td>85.563298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.691233</td>\n",
       "      <td>8.156515</td>\n",
       "      <td>9.055461</td>\n",
       "      <td>10.922031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.488045</td>\n",
       "      <td>109.449028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.439129</td>\n",
       "      <td>10.108954</td>\n",
       "      <td>8.857866</td>\n",
       "      <td>8.777507</td>\n",
       "      <td>11.488045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119.214192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mec_0      mec_1      mec_2      mec_3      mec_4      mec_5  \\\n",
       "mec_0    0.000000   9.798801  11.958295  11.470404   9.980195   8.814050   \n",
       "mec_1    9.798801   0.000000   8.375143  11.535600  10.702584   9.136893   \n",
       "mec_2   11.958295   8.375143   0.000000   8.814632   9.637714   9.170700   \n",
       "mec_3   11.470404  11.535600   8.814632   0.000000  10.377054  11.920252   \n",
       "mec_4    9.980195  10.702584   9.637714  10.377054   0.000000   8.105383   \n",
       "mec_5    8.814050   9.136893   9.170700  11.920252   8.105383   0.000000   \n",
       "mec_6    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_7    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_8    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_9    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_10   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_11   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_12   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_13   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_14   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_15   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_16   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_17   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "            mec_6      mec_7      mec_8      mec_9     mec_10     mec_11  \\\n",
       "mec_0    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_1    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_2    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_3    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_4    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_5    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_6    0.000000   9.844690   9.566568  11.011583  10.132206  11.731761   \n",
       "mec_7    9.844690   0.000000   8.172655  11.317250   9.944330  11.698995   \n",
       "mec_8    9.566568   8.172655   0.000000  11.919272   9.162932  11.220747   \n",
       "mec_9   11.011583  11.317250  11.919272   0.000000  11.868000  11.393785   \n",
       "mec_10  10.132206   9.944330   9.162932  11.868000   0.000000   9.548735   \n",
       "mec_11  11.731761  11.698995  11.220747  11.393785   9.548735   0.000000   \n",
       "mec_12   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_13   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_14   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_15   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_16   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_17   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "           mec_12     mec_13     mec_14     mec_15     mec_16     mec_17  \\\n",
       "mec_0    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_1    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_2    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_3    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_4    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_5    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_6    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_7    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_8    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_9    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_10   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_11   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "mec_12   0.000000   8.573090  10.155633  11.202596  10.691233  11.439129   \n",
       "mec_13   8.573090   0.000000  10.795540   9.382486   8.156515  10.108954   \n",
       "mec_14  10.155633  10.795540   0.000000   8.183423   9.055461   8.857866   \n",
       "mec_15  11.202596   9.382486   8.183423   0.000000  10.922031   8.777507   \n",
       "mec_16  10.691233   8.156515   9.055461  10.922031   0.000000  11.488045   \n",
       "mec_17  11.439129  10.108954   8.857866   8.777507  11.488045   0.000000   \n",
       "\n",
       "             cloud  \n",
       "mec_0    98.912800  \n",
       "mec_1   104.609202  \n",
       "mec_2    92.055348  \n",
       "mec_3    84.851664  \n",
       "mec_4    99.076301  \n",
       "mec_5   115.079279  \n",
       "mec_6   115.876371  \n",
       "mec_7    85.497305  \n",
       "mec_8   104.131110  \n",
       "mec_9    87.205323  \n",
       "mec_10   98.893806  \n",
       "mec_11  100.162429  \n",
       "mec_12   94.683387  \n",
       "mec_13   86.214881  \n",
       "mec_14  100.518021  \n",
       "mec_15   85.563298  \n",
       "mec_16  109.449028  \n",
       "mec_17  119.214192  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Example driver (with your current variables) ---\n",
    "pairs_by_topology = build_topology_episode_pairs(\n",
    "    datasets_ep_first=datasets,   # episode-first dict you already built\n",
    "    topologies=topologies,\n",
    "    strict_delta_match=True\n",
    ")\n",
    "\n",
    "print_pairs_summary_topology_first_ep(pairs_by_topology)\n",
    "\n",
    "# Access examples:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "pairs_by_topology[\"full_mesh\"][\"ep_000\"][\"light\"][\"dataset\"][\"tasks\"]\n",
    "pairs_by_topology[\"clustered\"][\"ep_000\"][\"heavy\"][\"connection_matrix_df\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.5. Agent→MEC mapping (for all pairs) </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent → MEC Mapping assigns each agent to a specific MEC server.\n",
    "This creates a fixed mec_id for every agent (e.g., agent_id % K), which determines where its tasks are initially queued and processed in the MDP environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_agents_to_mecs(pairs_by_topology):\n",
    "    \"\"\"\n",
    "    Adds agent→MEC mapping to each (topology / ep / scenario) bundle.\n",
    "    - Rule: mec_id = agent_id % K\n",
    "    - Writes:\n",
    "        bundle[\"agent_to_mec\"]                  (pd.Series, index=agent_id)\n",
    "        bundle[\"dataset\"][\"agents\"][\"mec_id\"]   (added column)\n",
    "    \"\"\"\n",
    "    for topo_name, by_ep in pairs_by_topology.items():\n",
    "        for ep_name, by_scen in by_ep.items():\n",
    "            for scen_name, bundle in by_scen.items():\n",
    "\n",
    "                ds = bundle[\"dataset\"]\n",
    "                agents = ds[\"agents\"].copy()\n",
    "                K = int(bundle[\"K\"])\n",
    "\n",
    "                if \"agent_id\" not in agents.columns:\n",
    "                    raise ValueError(f\"[{topo_name}/{ep_name}/{scen_name}] agents.csv missing 'agent_id'.\")\n",
    "\n",
    "                # Ensure agent_id is contiguous & sorted (0..N_agents-1)\n",
    "                agents = agents.sort_values(\"agent_id\").reset_index(drop=True)\n",
    "                expected_n = int(bundle[\"dataset\"][\"episodes\"][\"N_agents\"].iloc[0])\n",
    "                if agents[\"agent_id\"].min() != 0 or agents[\"agent_id\"].max() != expected_n - 1:\n",
    "                    raise ValueError(f\"[{topo_name}/{ep_name}/{scen_name}] agent_id range not 0..N_agents-1.\")\n",
    "\n",
    "                # Mapping\n",
    "                mec_ids = (agents[\"agent_id\"].astype(int) % K).astype(int)\n",
    "                agents[\"mec_id\"] = mec_ids\n",
    "\n",
    "                # Store: dataset copy + Series with index=agent_id\n",
    "                ds[\"agents\"] = agents\n",
    "                bundle[\"agent_to_mec\"] = pd.Series(\n",
    "                    data=mec_ids.values,\n",
    "                    index=agents[\"agent_id\"].values,\n",
    "                    name=\"mec_id\"\n",
    "                )\n",
    "\n",
    "    return pairs_by_topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===EXAMPLE===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>f_local</th>\n",
       "      <th>m_local</th>\n",
       "      <th>lam_sec</th>\n",
       "      <th>mec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>0.708673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>0.234989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>0.228174</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>0.310369</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>0.548990</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id       f_local      m_local   lam_sec  mec_id\n",
       "0         0  1.741183e+09  5713.849721  0.708673       0\n",
       "1         1  1.352326e+09  4566.428755  0.234989       1\n",
       "2         2  1.726668e+09  5815.120004  0.228174       2\n",
       "3         3  1.543616e+09  3539.850245  0.310369       3\n",
       "4         4  1.130883e+09  4161.367769  0.548990       4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply mapping\n",
    "pairs_by_topology = assign_agents_to_mecs(pairs_by_topology)\n",
    "\n",
    "# Quick sanity peek\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "pairs_by_topology[\"clustered\"][\"ep_000\"][\"heavy\"][\"dataset\"][\"agents\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.6. Environment Configuration </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we build a unified env_config for each scenario–topology pair.\n",
    "It bundles all required information for the MDP/RL environment—such as compute capacities, the Agent→MEC mapping, connection matrix, initial queue states, and action/state specifications—into a single consistent configuration used by the RL training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_core_from_bundle(bundle: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    required = [\"dataset\", \"topology_data\", \"connection_matrix_df\", \"Delta\", \"K\"]\n",
    "    for k in required:\n",
    "        if k not in bundle:\n",
    "            raise ValueError(f\"Bundle missing required key: '{k}'\")\n",
    "\n",
    "    ds   = bundle[\"dataset\"]\n",
    "    topo = bundle[\"topology_data\"]\n",
    "    Mdf  = bundle[\"connection_matrix_df\"]\n",
    "\n",
    "    private_cpu = np.asarray(topo[\"private_cpu_capacities\"], dtype=float)\n",
    "    public_cpu  = np.asarray(topo[\"public_cpu_capacities\"],  dtype=float)\n",
    "    cloud_cpu   = float(topo[\"cloud_computational_capacity\"])\n",
    "    M           = Mdf.to_numpy(dtype=float)  # (K, K+1), last col MEC→Cloud (MB/slot)\n",
    "\n",
    "    return dict(\n",
    "        Delta=float(bundle[\"Delta\"]),\n",
    "        K=int(bundle[\"K\"]),\n",
    "        episodes=ds[\"episodes\"],\n",
    "        agents=ds[\"agents\"],\n",
    "        arrivals=ds[\"arrivals\"],\n",
    "        tasks=ds[\"tasks\"],\n",
    "        private_cpu=private_cpu,\n",
    "        public_cpu=public_cpu,\n",
    "        cloud_cpu=cloud_cpu,\n",
    "        connection_matrix=M,\n",
    "        topology_type=topo.get(\"topology_type\", \"unknown\"),\n",
    "    )\n",
    "\n",
    "def _build_default_queues(K: int) -> Dict[str, np.ndarray]:\n",
    "    return {\n",
    "        \"mec_local_cycles\":   np.zeros(K, dtype=float),\n",
    "        \"mec_public_cycles\":  np.zeros(K, dtype=float),\n",
    "        \"mec_bytes_in_transit\": np.zeros(K, dtype=float),\n",
    "        \"cloud_cycles\":       np.array([0.0], dtype=float),\n",
    "    }\n",
    "\n",
    "def _derive_action_space() -> Dict[str, Any]:\n",
    "    return {\"type\": \"discrete\", \"n\": 3, \"labels\": {0: \"LOCAL\", 1: \"MEC\", 2: \"CLOUD\"}}\n",
    "\n",
    "def _derive_state_spec(K: int) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"components\": {\n",
    "            \"queues\": {\n",
    "                \"mec_local_cycles\":  {\"shape\": (K,),   \"dtype\": \"float\"},\n",
    "                \"mec_public_cycles\": {\"shape\": (K,),   \"dtype\": \"float\"},\n",
    "                \"cloud_cycles\":      {\"shape\": (1,),   \"dtype\": \"float\"},\n",
    "            },\n",
    "            \"links\": {\n",
    "                \"connection_matrix\": {\"shape\": (K, K+1), \"dtype\": \"float\"},\n",
    "            },\n",
    "            \"capacities\": {\n",
    "                \"private_cpu\": {\"shape\": (K,), \"dtype\": \"float\"},\n",
    "                \"public_cpu\":  {\"shape\": (K,), \"dtype\": \"float\"},\n",
    "                \"cloud_cpu\":   {\"shape\": (1,), \"dtype\": \"float\"},\n",
    "            }\n",
    "        },\n",
    "        \"note\": \"Declarative spec; tensor assembly happens in the Env at each step.\"\n",
    "    }\n",
    "\n",
    "def build_env_config_for_bundle(bundle: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    core = _extract_core_from_bundle(bundle)\n",
    "\n",
    "    if \"agent_to_mec\" not in bundle:\n",
    "        raise ValueError(\"Bundle has no 'agent_to_mec' mapping. Run Stage 5 first.\")\n",
    "\n",
    "    agent_to_mec = bundle[\"agent_to_mec\"]\n",
    "    if isinstance(agent_to_mec, pd.Series):\n",
    "        # reorder by agent_id if needed\n",
    "        if agent_to_mec.index.name != \"agent_id\":\n",
    "            agent_to_mec.index.name = \"agent_id\"\n",
    "        idx = core[\"agents\"].sort_values(\"agent_id\")[\"agent_id\"].to_numpy()\n",
    "        agent_to_mec = agent_to_mec.reindex(idx)\n",
    "        agent_to_mec_arr = agent_to_mec.to_numpy(dtype=int)\n",
    "    else:\n",
    "        agent_to_mec_arr = np.asarray(agent_to_mec, dtype=int)\n",
    "\n",
    "    N_agents = int(core[\"episodes\"][\"N_agents\"].iloc[0])\n",
    "    if len(agent_to_mec_arr) != N_agents:\n",
    "        raise ValueError(f\"agent_to_mec length ({len(agent_to_mec_arr)}) != N_agents ({N_agents}).\")\n",
    "\n",
    "    queues_init  = _build_default_queues(core[\"K\"])\n",
    "    action_space = _derive_action_space()\n",
    "    state_spec   = _derive_state_spec(core[\"K\"])\n",
    "\n",
    "    env_config = {\n",
    "        \"Delta\": core[\"Delta\"],\n",
    "        \"K\": core[\"K\"],\n",
    "        \"topology_type\": core[\"topology_type\"],\n",
    "        \"connection_matrix\": core[\"connection_matrix\"],\n",
    "\n",
    "        \"private_cpu\": core[\"private_cpu\"],\n",
    "        \"public_cpu\":  core[\"public_cpu\"],\n",
    "        \"cloud_cpu\":   core[\"cloud_cpu\"],\n",
    "\n",
    "        \"N_agents\": N_agents,\n",
    "        \"agent_to_mec\": agent_to_mec_arr,\n",
    "\n",
    "        # aligned dataframes\n",
    "        \"episodes\": core[\"episodes\"],\n",
    "        \"agents\":   core[\"agents\"],\n",
    "        \"arrivals\": core[\"arrivals\"],\n",
    "        \"tasks\":    core[\"tasks\"],\n",
    "\n",
    "        \"queues_initial\": queues_init,\n",
    "        \"action_space\": action_space,\n",
    "        \"state_spec\": state_spec,\n",
    "\n",
    "        \"checks\": bundle.get(\"checks\", {\"delta_match\": True, \"message\": \"n/a\"}),\n",
    "    }\n",
    "    return env_config\n",
    "\n",
    "def build_all_env_configs(\n",
    "    pairs_by_topology: Dict[str, Dict[str, Dict[str, Any]]]\n",
    ") -> Dict[str, Dict[str, Dict[str, Dict[str, Any]]]]:\n",
    "    \"\"\"\n",
    "    Build env_config for every (topology / episode / scenario) bundle.\n",
    "\n",
    "    Desired output shape (EPISODE-first):\n",
    "        env_configs[episode][topology][scenario] = env_config\n",
    "\n",
    "    So you can access:\n",
    "        env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"agent_to_mec\"]\n",
    "    \"\"\"\n",
    "    out: Dict[str, Dict[str, Dict[str, Dict[str, Any]]]] = {}\n",
    "    # pairs_by_topology: topo -> ep -> scen -> bundle\n",
    "    for topo_name, by_ep in pairs_by_topology.items():\n",
    "        for ep_name, by_scen in by_ep.items():\n",
    "            # ensure episode level exists\n",
    "            if ep_name not in out:\n",
    "                out[ep_name] = {}\n",
    "            # ensure topology level under this episode exists\n",
    "            if topo_name not in out[ep_name]:\n",
    "                out[ep_name][topo_name] = {}\n",
    "            for scen_name, bundle in by_scen.items():\n",
    "                if \"agent_to_mec\" not in bundle:\n",
    "                    raise RuntimeError(\n",
    "                        f\"[{topo_name}/{ep_name}/{scen_name}] missing 'agent_to_mec'. Run Stage 5 first.\"\n",
    "                    )\n",
    "                env_cfg = build_env_config_for_bundle(bundle)\n",
    "                out[ep_name][topo_name][scen_name] = env_cfg\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===EXAMPLE===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build\n",
    "env_configs = build_all_env_configs(pairs_by_topology)\n",
    "\n",
    "# Example access:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"agent_to_mec\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.7. Sanity Checks </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we verify that each env_config is internally consistent (queue shapes, capacities, agent→MEC mapping, and connection matrix are valid and ready for simulation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_env_config(env_config):\n",
    "    errors = []\n",
    "\n",
    "    # 1) Agent → MEC alignment\n",
    "    N_agents = env_config[\"N_agents\"]\n",
    "    if len(env_config[\"agent_to_mec\"]) != N_agents:\n",
    "        errors.append(\"Length of agent_to_mec does not match N_agents.\")\n",
    "\n",
    "    # 2) Queue initial state shapes\n",
    "    K = env_config[\"K\"]\n",
    "    q = env_config[\"queues_initial\"]\n",
    "    if q[\"mec_local_cycles\"].shape != (K,):\n",
    "        errors.append(\"mec_local_cycles queue shape mismatch.\")\n",
    "    if q[\"mec_public_cycles\"].shape != (K,):\n",
    "        errors.append(\"mec_public_cycles queue shape mismatch.\")\n",
    "    if q[\"mec_bytes_in_transit\"].shape != (K,):\n",
    "        errors.append(\"mec_bytes_in_transit queue shape mismatch.\")\n",
    "    if q[\"cloud_cycles\"].shape != (1,):\n",
    "        errors.append(\"cloud_cycles shape mismatch (should be (1,)).\")\n",
    "\n",
    "    # 3) Non-negative compute capacities\n",
    "    if (env_config[\"private_cpu\"] < 0).any():\n",
    "        errors.append(\"private_cpu has negative values.\")\n",
    "    if (env_config[\"public_cpu\"] < 0).any():\n",
    "        errors.append(\"public_cpu has negative values.\")\n",
    "    if env_config[\"cloud_cpu\"] < 0:\n",
    "        errors.append(\"cloud_cpu is negative.\")\n",
    "\n",
    "    # 4) Connection matrix dimension (K x K+1)\n",
    "    M = env_config[\"connection_matrix\"]\n",
    "    if M.shape != (K, K+1):\n",
    "        errors.append(\"connection_matrix shape mismatch.\")\n",
    "\n",
    "    # 5) Action space correctness\n",
    "    if env_config[\"action_space\"][\"type\"] != \"discrete\":\n",
    "        errors.append(\"Action space must be discrete (LOCAL/MEC/CLOUD).\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "def sanity_check_all(env_configs):\n",
    "    for topo_name, by_ep in env_configs.items():\n",
    "        for ep_name, by_scen in by_ep.items():\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                errs = sanity_check_env_config(env_cfg)\n",
    "                if errs:\n",
    "                    print(f\"[FAIL] {topo_name}/{ep_name}/{scen_name}:\")\n",
    "                    for e in errs:\n",
    "                        print(\"   -\", e)\n",
    "                else:\n",
    "                    print(f\"[OK]   {topo_name}/{ep_name}/{scen_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]   ep_000/clustered/heavy\n",
      "[OK]   ep_000/clustered/light\n",
      "[OK]   ep_000/clustered/moderate\n",
      "[OK]   ep_000/full_mesh/heavy\n",
      "[OK]   ep_000/full_mesh/light\n",
      "[OK]   ep_000/full_mesh/moderate\n",
      "[OK]   ep_000/sparse_ring/heavy\n",
      "[OK]   ep_000/sparse_ring/light\n",
      "[OK]   ep_000/sparse_ring/moderate\n",
      "env_configs: \n",
      " {'ep_000': {'clustered': {'heavy': {'Delta': 1.0, 'K': 18, 'topology_type': 'clustered', 'connection_matrix': array([[  0.        ,   9.79880061,  11.95829539,  11.47040438,\n",
      "          9.98019544,   8.81405007,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  98.91279982],\n",
      "       [  9.79880061,   0.        ,   8.37514324,  11.53560011,\n",
      "         10.70258438,   9.13689312,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 104.60920208],\n",
      "       [ 11.95829539,   8.37514324,   0.        ,   8.81463191,\n",
      "          9.63771407,   9.17070042,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  92.05534806],\n",
      "       [ 11.47040438,  11.53560011,   8.81463191,   0.        ,\n",
      "         10.37705391,  11.92025208,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  84.85166372],\n",
      "       [  9.98019544,  10.70258438,   9.63771407,  10.37705391,\n",
      "          0.        ,   8.10538324,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  99.07630097],\n",
      "       [  8.81405007,   9.13689312,   9.17070042,  11.92025208,\n",
      "          8.10538324,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 115.07927911],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   9.84469022,\n",
      "          9.56656784,  11.01158338,  10.13220601,  11.73176121,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 115.8763706 ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   9.84469022,   0.        ,\n",
      "          8.17265482,  11.31725016,   9.94433007,  11.69899488,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  85.49730491],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   9.56656784,   8.17265482,\n",
      "          0.        ,  11.9192718 ,   9.16293193,  11.22074688,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 104.13111015],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  11.01158338,  11.31725016,\n",
      "         11.9192718 ,   0.        ,  11.8680001 ,  11.39378515,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  87.20532265],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  10.13220601,   9.94433007,\n",
      "          9.16293193,  11.8680001 ,   0.        ,   9.54873479,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  98.89380626],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  11.73176121,  11.69899488,\n",
      "         11.22074688,  11.39378515,   9.54873479,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 100.16242881],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   8.57308973,  10.15563321,  11.20259578,\n",
      "         10.69123291,  11.43912945,  94.68338717],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          8.57308973,   0.        ,  10.79553972,   9.38248576,\n",
      "          8.15651517,  10.10895365,  86.2148807 ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         10.15563321,  10.79553972,   0.        ,   8.18342325,\n",
      "          9.05546058,   8.85786558, 100.51802149],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         11.20259578,   9.38248576,   8.18342325,   0.        ,\n",
      "         10.92203111,   8.7775075 ,  85.56329834],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         10.69123291,   8.15651517,   9.05546058,  10.92203111,\n",
      "          0.        ,  11.48804542, 109.44902762],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         11.43912945,  10.10895365,   8.85786558,   8.7775075 ,\n",
      "         11.48804542,   0.        , 119.21419244]]), 'private_cpu': array([1.41702651e+09, 1.46583552e+09, 1.40029615e+09, 1.21986312e+09,\n",
      "       1.27037663e+09, 1.34801953e+09, 1.78616129e+09, 1.38093201e+09,\n",
      "       1.73968038e+09, 1.60615170e+09, 1.72279202e+09, 1.45211969e+09,\n",
      "       1.57532372e+09, 1.67517605e+09, 1.46526924e+09, 1.56574374e+09,\n",
      "       1.71525983e+09, 1.22583243e+09]), 'public_cpu': array([7.68946447e+08, 7.53418541e+08, 7.02715948e+08, 5.45197669e+08,\n",
      "       6.70994513e+08, 6.80525152e+08, 8.11159072e+08, 7.82943570e+08,\n",
      "       5.01997672e+08, 6.85198792e+08, 8.22519853e+08, 7.16138691e+08,\n",
      "       8.22355072e+08, 5.56428866e+08, 8.05978940e+08, 7.90274918e+08,\n",
      "       6.02437544e+08, 7.09495765e+08]), 'cloud_cpu': 30000000000.0, 'N_agents': 18, 'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), 'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
      "0    heavy           0    1.0     3600    1.0        18   345, 'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
      "0          0  1.741183e+09  5713.849721  0.708673       0\n",
      "1          1  1.352326e+09  4566.428755  0.234989       1\n",
      "2          2  1.726668e+09  5815.120004  0.228174       2\n",
      "3          3  1.543616e+09  3539.850245  0.310369       3\n",
      "4          4  1.130883e+09  4161.367769  0.548990       4\n",
      "5          5  1.761336e+09  7349.509397  0.427498       5\n",
      "6          6  1.093196e+09  6389.821853  0.733849       6\n",
      "7          7  1.022066e+09  5354.805771  0.492160       7\n",
      "8          8  1.280853e+09  3931.170813  0.647444       8\n",
      "9          9  1.260889e+09  5133.304392  0.434945       9\n",
      "10        10  8.077840e+08  6774.364061  0.696332      10\n",
      "11        11  1.252718e+09  5907.761753  0.250139      11\n",
      "12        12  1.849537e+09  4251.816941  0.275633      12\n",
      "13        13  2.013685e+09  3452.486291  0.387815      13\n",
      "14        14  1.566043e+09  6514.168780  0.410745      14\n",
      "15        15  1.573528e+09  7018.517023  0.746995      15\n",
      "16        16  1.386095e+09  6122.347442  0.414992      16\n",
      "17        17  1.604826e+09  3449.292167  0.516951      17, 'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
      "0        heavy           0       0     0.0         0        0\n",
      "1        heavy           0       0     0.0         1        1\n",
      "2        heavy           0       0     0.0         4        2\n",
      "3        heavy           0       0     0.0         7        3\n",
      "4        heavy           0       0     0.0        10        4\n",
      "...        ...         ...     ...     ...       ...      ...\n",
      "30631    heavy           0    3599  3599.0         5    30631\n",
      "30632    heavy           0    3599  3599.0         6    30632\n",
      "30633    heavy           0    3599  3599.0         6    30633\n",
      "30634    heavy           0    3599  3599.0         7    30634\n",
      "30635    heavy           0    3599  3599.0         7    30635\n",
      "\n",
      "[30636 rows x 6 columns], 'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
      "0        heavy           0        0         0               0             0.0   \n",
      "1        heavy           0        1         1               0             0.0   \n",
      "2        heavy           0        2         4               0             0.0   \n",
      "3        heavy           0        3         7               0             0.0   \n",
      "4        heavy           0        4        10               0             0.0   \n",
      "...        ...         ...      ...       ...             ...             ...   \n",
      "30631    heavy           0    30631         5            3599          3599.0   \n",
      "30632    heavy           0    30632         6            3599          3599.0   \n",
      "30633    heavy           0    30633         6            3599          3599.0   \n",
      "30634    heavy           0    30634         7            3599          3599.0   \n",
      "30635    heavy           0    30635         7            3599          3599.0   \n",
      "\n",
      "            b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
      "0       7.202096    9.727147e+08  7.005585e+09   66.611010   sensor   \n",
      "1       5.479984    1.314973e+09  7.206031e+09   77.928800    image   \n",
      "2       8.421977    2.500222e+09  2.105681e+10   72.966446     text   \n",
      "3       6.324986    1.779582e+09  1.125583e+10   56.492900   sensor   \n",
      "4      11.473269    1.087572e+09  1.247800e+10   73.389854   sensor   \n",
      "...          ...             ...           ...         ...      ...   \n",
      "30631   6.238504    1.090296e+09  6.801814e+09   69.218260    video   \n",
      "30632   3.289880    1.599958e+09  5.263669e+09   39.210260   sensor   \n",
      "30633   6.192005    8.322764e+08  5.153459e+09   73.052900   sensor   \n",
      "30634   3.244716    1.627807e+09  5.281771e+09  103.576775    image   \n",
      "30635   1.736996    2.141823e+09  3.720338e+09   92.836210     text   \n",
      "\n",
      "       has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
      "0                 1    0.800726       0.800726           0     0.000000   \n",
      "1                 1    0.615113       0.615113           0     0.000000   \n",
      "2                 1    0.323007       0.323007           1     0.539704   \n",
      "3                 1    0.481587       0.481587           0     0.000000   \n",
      "4                 1    0.594564       0.594564           0     0.000000   \n",
      "...             ...         ...            ...         ...          ...   \n",
      "30631             1    0.525271    3599.525400           1     0.605597   \n",
      "30632             0         NaN            NaN           0     0.000000   \n",
      "30633             0         NaN            NaN           1     0.566783   \n",
      "30634             0         NaN            NaN           1     0.706580   \n",
      "30635             1    0.763454    3599.763400           0     0.000000   \n",
      "\n",
      "      action_space_hint  \n",
      "0              discrete  \n",
      "1              discrete  \n",
      "2            continuous  \n",
      "3              discrete  \n",
      "4              discrete  \n",
      "...                 ...  \n",
      "30631        continuous  \n",
      "30632          discrete  \n",
      "30633        continuous  \n",
      "30634        continuous  \n",
      "30635          discrete  \n",
      "\n",
      "[30636 rows x 17 columns], 'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'cloud_cycles': array([0.])}, 'action_space': {'type': 'discrete', 'n': 3, 'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}}, 'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,), 'dtype': 'float'}, 'mec_public_cycles': {'shape': (18,), 'dtype': 'float'}, 'cloud_cycles': {'shape': (1,), 'dtype': 'float'}}, 'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}}, 'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'}, 'public_cpu': {'shape': (18,), 'dtype': 'float'}, 'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}}, 'note': 'Declarative spec; tensor assembly happens in the Env at each step.'}, 'checks': {'delta_match': True, 'message': 'OK'}}, 'light': {'Delta': 1.0, 'K': 18, 'topology_type': 'clustered', 'connection_matrix': array([[  0.        ,   9.79880061,  11.95829539,  11.47040438,\n",
      "          9.98019544,   8.81405007,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  98.91279982],\n",
      "       [  9.79880061,   0.        ,   8.37514324,  11.53560011,\n",
      "         10.70258438,   9.13689312,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 104.60920208],\n",
      "       [ 11.95829539,   8.37514324,   0.        ,   8.81463191,\n",
      "          9.63771407,   9.17070042,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  92.05534806],\n",
      "       [ 11.47040438,  11.53560011,   8.81463191,   0.        ,\n",
      "         10.37705391,  11.92025208,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  84.85166372],\n",
      "       [  9.98019544,  10.70258438,   9.63771407,  10.37705391,\n",
      "          0.        ,   8.10538324,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  99.07630097],\n",
      "       [  8.81405007,   9.13689312,   9.17070042,  11.92025208,\n",
      "          8.10538324,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 115.07927911],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   9.84469022,\n",
      "          9.56656784,  11.01158338,  10.13220601,  11.73176121,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 115.8763706 ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   9.84469022,   0.        ,\n",
      "          8.17265482,  11.31725016,   9.94433007,  11.69899488,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  85.49730491],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   9.56656784,   8.17265482,\n",
      "          0.        ,  11.9192718 ,   9.16293193,  11.22074688,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 104.13111015],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  11.01158338,  11.31725016,\n",
      "         11.9192718 ,   0.        ,  11.8680001 ,  11.39378515,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  87.20532265],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  10.13220601,   9.94433007,\n",
      "          9.16293193,  11.8680001 ,   0.        ,   9.54873479,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  98.89380626],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  11.73176121,  11.69899488,\n",
      "         11.22074688,  11.39378515,   9.54873479,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 100.16242881],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   8.57308973,  10.15563321,  11.20259578,\n",
      "         10.69123291,  11.43912945,  94.68338717],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          8.57308973,   0.        ,  10.79553972,   9.38248576,\n",
      "          8.15651517,  10.10895365,  86.2148807 ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         10.15563321,  10.79553972,   0.        ,   8.18342325,\n",
      "          9.05546058,   8.85786558, 100.51802149],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         11.20259578,   9.38248576,   8.18342325,   0.        ,\n",
      "         10.92203111,   8.7775075 ,  85.56329834],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         10.69123291,   8.15651517,   9.05546058,  10.92203111,\n",
      "          0.        ,  11.48804542, 109.44902762],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         11.43912945,  10.10895365,   8.85786558,   8.7775075 ,\n",
      "         11.48804542,   0.        , 119.21419244]]), 'private_cpu': array([1.41702651e+09, 1.46583552e+09, 1.40029615e+09, 1.21986312e+09,\n",
      "       1.27037663e+09, 1.34801953e+09, 1.78616129e+09, 1.38093201e+09,\n",
      "       1.73968038e+09, 1.60615170e+09, 1.72279202e+09, 1.45211969e+09,\n",
      "       1.57532372e+09, 1.67517605e+09, 1.46526924e+09, 1.56574374e+09,\n",
      "       1.71525983e+09, 1.22583243e+09]), 'public_cpu': array([7.68946447e+08, 7.53418541e+08, 7.02715948e+08, 5.45197669e+08,\n",
      "       6.70994513e+08, 6.80525152e+08, 8.11159072e+08, 7.82943570e+08,\n",
      "       5.01997672e+08, 6.85198792e+08, 8.22519853e+08, 7.16138691e+08,\n",
      "       8.22355072e+08, 5.56428866e+08, 8.05978940e+08, 7.90274918e+08,\n",
      "       6.02437544e+08, 7.09495765e+08]), 'cloud_cpu': 30000000000.0, 'N_agents': 18, 'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), 'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
      "0    light           0    1.0     3600    1.0        18   143, 'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
      "0          0  9.214683e+08  5152.146294  0.021214       0\n",
      "1          1  1.988512e+09  4208.470915  0.030254       1\n",
      "2          2  1.361339e+09  4466.022492  0.028701       2\n",
      "3          3  2.155303e+09  7570.283244  0.038873       3\n",
      "4          4  8.727403e+08  6918.455560  0.037506       4\n",
      "5          5  2.350478e+09  7997.219317  0.013920       5\n",
      "6          6  1.080474e+09  3611.664818  0.031591       6\n",
      "7          7  1.483437e+09  5690.301814  0.026184       7\n",
      "8          8  1.782616e+09  5312.418573  0.040268       8\n",
      "9          9  2.164538e+09  6264.107462  0.048391       9\n",
      "10        10  2.381892e+09  5233.485875  0.039955      10\n",
      "11        11  1.698112e+09  5619.134661  0.037599      11\n",
      "12        12  1.170523e+09  5302.008006  0.034852      12\n",
      "13        13  1.004000e+09  6356.746540  0.027640      13\n",
      "14        14  1.206141e+09  4332.462100  0.038611      14\n",
      "15        15  2.062918e+09  5181.575792  0.042660      15\n",
      "16        16  1.493700e+09  6776.846182  0.026377      16\n",
      "17        17  1.302068e+09  6167.829828  0.025928      17, 'arrivals':      scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
      "0       light           0       0     0.0         1        0\n",
      "1       light           0       0     0.0        17        1\n",
      "2       light           0       7     7.0        17        2\n",
      "3       light           0       9     9.0         3        3\n",
      "4       light           0      13    13.0        15        4\n",
      "...       ...         ...     ...     ...       ...      ...\n",
      "2108    light           0    3594  3594.0        14     2108\n",
      "2109    light           0    3597  3597.0        11     2109\n",
      "2110    light           0    3597  3597.0        16     2110\n",
      "2111    light           0    3598  3598.0        14     2111\n",
      "2112    light           0    3599  3599.0        17     2112\n",
      "\n",
      "[2113 rows x 6 columns], 'tasks':      scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
      "0       light           0        0         1               0             0.0   \n",
      "1       light           0        1        17               0             0.0   \n",
      "2       light           0        2        17               7             7.0   \n",
      "3       light           0        3         3               9             9.0   \n",
      "4       light           0        4        15              13            13.0   \n",
      "...       ...         ...      ...       ...             ...             ...   \n",
      "2108    light           0     2108        14            3594          3594.0   \n",
      "2109    light           0     2109        11            3597          3597.0   \n",
      "2110    light           0     2110        16            3597          3597.0   \n",
      "2111    light           0     2111        14            3598          3598.0   \n",
      "2112    light           0     2112        17            3599          3599.0   \n",
      "\n",
      "          b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
      "0     2.484967    5.525261e+08  1.373009e+09   62.412148    video   \n",
      "1     2.509962    1.082130e+09  2.716106e+09   74.606000     text   \n",
      "2     1.509317    1.757732e+09  2.652974e+09   30.173971     text   \n",
      "3     2.114311    4.582521e+08  9.688874e+08   52.914295    image   \n",
      "4     1.707707    6.574788e+08  1.122781e+09   95.441150    image   \n",
      "...        ...             ...           ...         ...      ...   \n",
      "2108  2.306310    1.006178e+09  2.320560e+09   64.688480     text   \n",
      "2109  3.687047    1.297120e+09  4.782541e+09  106.002625   sensor   \n",
      "2110  2.407504    9.582727e+08  2.307045e+09   65.863180    image   \n",
      "2111  1.205960    1.482103e+09  1.787356e+09   65.631966    image   \n",
      "2112  1.339075    4.337156e+08  5.807776e+08   81.440796    video   \n",
      "\n",
      "      has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
      "0                1    1.339893       1.339893           1     0.424900   \n",
      "1                0         NaN            NaN           0     0.000000   \n",
      "2                0         NaN            NaN           1     0.358162   \n",
      "3                0         NaN            NaN           0     0.000000   \n",
      "4                0         NaN            NaN           0     0.000000   \n",
      "...            ...         ...            ...         ...          ...   \n",
      "2108             0         NaN            NaN           0     0.000000   \n",
      "2109             0         NaN            NaN           0     0.000000   \n",
      "2110             0         NaN            NaN           1     0.393362   \n",
      "2111             0         NaN            NaN           0     0.000000   \n",
      "2112             0         NaN            NaN           0     0.000000   \n",
      "\n",
      "     action_space_hint  \n",
      "0           continuous  \n",
      "1             discrete  \n",
      "2           continuous  \n",
      "3             discrete  \n",
      "4             discrete  \n",
      "...                ...  \n",
      "2108          discrete  \n",
      "2109          discrete  \n",
      "2110        continuous  \n",
      "2111          discrete  \n",
      "2112          discrete  \n",
      "\n",
      "[2113 rows x 17 columns], 'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'cloud_cycles': array([0.])}, 'action_space': {'type': 'discrete', 'n': 3, 'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}}, 'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,), 'dtype': 'float'}, 'mec_public_cycles': {'shape': (18,), 'dtype': 'float'}, 'cloud_cycles': {'shape': (1,), 'dtype': 'float'}}, 'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}}, 'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'}, 'public_cpu': {'shape': (18,), 'dtype': 'float'}, 'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}}, 'note': 'Declarative spec; tensor assembly happens in the Env at each step.'}, 'checks': {'delta_match': True, 'message': 'OK'}}, 'moderate': {'Delta': 1.0, 'K': 18, 'topology_type': 'clustered', 'connection_matrix': array([[  0.        ,   9.79880061,  11.95829539,  11.47040438,\n",
      "          9.98019544,   8.81405007,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  98.91279982],\n",
      "       [  9.79880061,   0.        ,   8.37514324,  11.53560011,\n",
      "         10.70258438,   9.13689312,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 104.60920208],\n",
      "       [ 11.95829539,   8.37514324,   0.        ,   8.81463191,\n",
      "          9.63771407,   9.17070042,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  92.05534806],\n",
      "       [ 11.47040438,  11.53560011,   8.81463191,   0.        ,\n",
      "         10.37705391,  11.92025208,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  84.85166372],\n",
      "       [  9.98019544,  10.70258438,   9.63771407,  10.37705391,\n",
      "          0.        ,   8.10538324,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  99.07630097],\n",
      "       [  8.81405007,   9.13689312,   9.17070042,  11.92025208,\n",
      "          8.10538324,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 115.07927911],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   9.84469022,\n",
      "          9.56656784,  11.01158338,  10.13220601,  11.73176121,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 115.8763706 ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   9.84469022,   0.        ,\n",
      "          8.17265482,  11.31725016,   9.94433007,  11.69899488,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  85.49730491],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   9.56656784,   8.17265482,\n",
      "          0.        ,  11.9192718 ,   9.16293193,  11.22074688,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 104.13111015],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  11.01158338,  11.31725016,\n",
      "         11.9192718 ,   0.        ,  11.8680001 ,  11.39378515,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  87.20532265],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  10.13220601,   9.94433007,\n",
      "          9.16293193,  11.8680001 ,   0.        ,   9.54873479,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  98.89380626],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  11.73176121,  11.69899488,\n",
      "         11.22074688,  11.39378515,   9.54873479,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 100.16242881],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   8.57308973,  10.15563321,  11.20259578,\n",
      "         10.69123291,  11.43912945,  94.68338717],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          8.57308973,   0.        ,  10.79553972,   9.38248576,\n",
      "          8.15651517,  10.10895365,  86.2148807 ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         10.15563321,  10.79553972,   0.        ,   8.18342325,\n",
      "          9.05546058,   8.85786558, 100.51802149],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         11.20259578,   9.38248576,   8.18342325,   0.        ,\n",
      "         10.92203111,   8.7775075 ,  85.56329834],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         10.69123291,   8.15651517,   9.05546058,  10.92203111,\n",
      "          0.        ,  11.48804542, 109.44902762],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         11.43912945,  10.10895365,   8.85786558,   8.7775075 ,\n",
      "         11.48804542,   0.        , 119.21419244]]), 'private_cpu': array([1.41702651e+09, 1.46583552e+09, 1.40029615e+09, 1.21986312e+09,\n",
      "       1.27037663e+09, 1.34801953e+09, 1.78616129e+09, 1.38093201e+09,\n",
      "       1.73968038e+09, 1.60615170e+09, 1.72279202e+09, 1.45211969e+09,\n",
      "       1.57532372e+09, 1.67517605e+09, 1.46526924e+09, 1.56574374e+09,\n",
      "       1.71525983e+09, 1.22583243e+09]), 'public_cpu': array([7.68946447e+08, 7.53418541e+08, 7.02715948e+08, 5.45197669e+08,\n",
      "       6.70994513e+08, 6.80525152e+08, 8.11159072e+08, 7.82943570e+08,\n",
      "       5.01997672e+08, 6.85198792e+08, 8.22519853e+08, 7.16138691e+08,\n",
      "       8.22355072e+08, 5.56428866e+08, 8.05978940e+08, 7.90274918e+08,\n",
      "       6.02437544e+08, 7.09495765e+08]), 'cloud_cpu': 30000000000.0, 'N_agents': 18, 'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), 'episodes':    scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
      "0  moderate           0    1.0     3600    1.0        18   244, 'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
      "0          0  2.075234e+09  4177.077472  0.083588       0\n",
      "1          1  1.845675e+09  4444.750864  0.117454       1\n",
      "2          2  1.422351e+09  3116.790674  0.190249       2\n",
      "3          3  8.627662e+08  3819.530831  0.180022       3\n",
      "4          4  1.576391e+09  4456.416731  0.124874       4\n",
      "5          5  1.361574e+09  6518.273845  0.093241       5\n",
      "6          6  1.146421e+09  4031.095267  0.197552       6\n",
      "7          7  1.093930e+09  5125.594407  0.160180       7\n",
      "8          8  8.213925e+08  5099.239983  0.089347       8\n",
      "9          9  1.378500e+09  3320.898803  0.115078       9\n",
      "10        10  1.967238e+09  3878.558132  0.066943      10\n",
      "11        11  1.937473e+09  5303.971140  0.051492      11\n",
      "12        12  1.973373e+09  4718.837422  0.187653      12\n",
      "13        13  2.334762e+09  4156.023984  0.171413      13\n",
      "14        14  1.989451e+09  5301.096958  0.169348      14\n",
      "15        15  2.245627e+09  3973.902321  0.114526      15\n",
      "16        16  9.699633e+08  5954.812618  0.109306      16\n",
      "17        17  1.298186e+09  6890.123320  0.106591      17, 'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
      "0     moderate           0       1     1.0         3        0\n",
      "1     moderate           0       1     1.0        12        1\n",
      "2     moderate           0       1     1.0        13        2\n",
      "3     moderate           0       1     1.0        13        3\n",
      "4     moderate           0       3     3.0         5        4\n",
      "...        ...         ...     ...     ...       ...      ...\n",
      "8257  moderate           0    3597  3597.0        13     8257\n",
      "8258  moderate           0    3597  3597.0        13     8258\n",
      "8259  moderate           0    3597  3597.0        14     8259\n",
      "8260  moderate           0    3598  3598.0        13     8260\n",
      "8261  moderate           0    3599  3599.0         6     8261\n",
      "\n",
      "[8262 rows x 6 columns], 'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
      "0     moderate           0        0         3               1             1.0   \n",
      "1     moderate           0        1        12               1             1.0   \n",
      "2     moderate           0        2        13               1             1.0   \n",
      "3     moderate           0        3        13               1             1.0   \n",
      "4     moderate           0        4         5               3             3.0   \n",
      "...        ...         ...      ...       ...             ...             ...   \n",
      "8257  moderate           0     8257        13            3597          3597.0   \n",
      "8258  moderate           0     8258        13            3597          3597.0   \n",
      "8259  moderate           0     8259        14            3597          3597.0   \n",
      "8260  moderate           0     8260        13            3598          3598.0   \n",
      "8261  moderate           0     8261         6            3599          3599.0   \n",
      "\n",
      "          b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
      "0     4.463301    1.368071e+09  6.106115e+09   59.895400    video   \n",
      "1     2.032145    1.310597e+09  2.663323e+09   39.163837     text   \n",
      "2     2.471461    1.423734e+09  3.518704e+09   71.265870    image   \n",
      "3     2.097559    7.160129e+08  1.501879e+09   73.560420     text   \n",
      "4     2.683642    9.887779e+08  2.653526e+09  114.356410    video   \n",
      "...        ...             ...           ...         ...      ...   \n",
      "8257  2.391213    5.808735e+08  1.388992e+09   56.940155    video   \n",
      "8258  2.583749    1.690439e+09  4.367671e+09   67.638040    video   \n",
      "8259  2.405940    1.218846e+09  2.932471e+09   66.223816   sensor   \n",
      "8260  2.014641    9.512537e+08  1.916434e+09   36.491844     text   \n",
      "8261  4.927452    2.140466e+09  1.054704e+10   47.556170    image   \n",
      "\n",
      "      has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
      "0                0         NaN            NaN           0     0.000000   \n",
      "1                0         NaN            NaN           1     0.619935   \n",
      "2                0         NaN            NaN           0     0.000000   \n",
      "3                0         NaN            NaN           1     0.667023   \n",
      "4                1    0.868840       3.868839           0     0.000000   \n",
      "...            ...         ...            ...         ...          ...   \n",
      "8257             0         NaN            NaN           0     0.000000   \n",
      "8258             0         NaN            NaN           0     0.000000   \n",
      "8259             1    1.438337    3598.438200           0     0.000000   \n",
      "8260             0         NaN            NaN           1     0.493939   \n",
      "8261             0         NaN            NaN           0     0.000000   \n",
      "\n",
      "     action_space_hint  \n",
      "0             discrete  \n",
      "1           continuous  \n",
      "2             discrete  \n",
      "3           continuous  \n",
      "4             discrete  \n",
      "...                ...  \n",
      "8257          discrete  \n",
      "8258          discrete  \n",
      "8259          discrete  \n",
      "8260        continuous  \n",
      "8261          discrete  \n",
      "\n",
      "[8262 rows x 17 columns], 'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'cloud_cycles': array([0.])}, 'action_space': {'type': 'discrete', 'n': 3, 'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}}, 'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,), 'dtype': 'float'}, 'mec_public_cycles': {'shape': (18,), 'dtype': 'float'}, 'cloud_cycles': {'shape': (1,), 'dtype': 'float'}}, 'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}}, 'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'}, 'public_cpu': {'shape': (18,), 'dtype': 'float'}, 'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}}, 'note': 'Declarative spec; tensor assembly happens in the Env at each step.'}, 'checks': {'delta_match': True, 'message': 'OK'}}}, 'full_mesh': {'heavy': {'Delta': 1.0, 'K': 18, 'topology_type': 'fully_connected', 'connection_matrix': array([[  0.        ,  11.92281432,  10.47890811,  11.62756381,\n",
      "          9.72588091,   9.91325978,   8.60450808,   9.50115837,\n",
      "         10.91615142,  11.81350974,   8.9852223 ,  10.80194249,\n",
      "          9.73499996,   9.19422365,   8.12723414,  10.69973564,\n",
      "          8.60534515,  11.55299163,  92.53424509],\n",
      "       [ 11.92281432,   0.        ,  11.08031243,  10.34304631,\n",
      "         11.49029507,  10.65127018,   8.33860734,   8.88809786,\n",
      "         11.86786775,   9.25818495,  11.68602726,  10.73935883,\n",
      "          8.71533211,  10.60486084,  11.70825125,   8.60692948,\n",
      "         11.47275338,  10.84320426, 102.77092651],\n",
      "       [ 10.47890811,  11.08031243,   0.        ,  10.64649505,\n",
      "         11.53438988,   8.09132603,   8.86977281,  11.27540672,\n",
      "          9.44013753,  10.61901002,  10.63050405,   8.62482374,\n",
      "         11.93621388,   8.57698697,  11.36443595,   8.97319535,\n",
      "          9.8559768 ,  10.59985665,  90.21900011],\n",
      "       [ 11.62756381,  10.34304631,  10.64649505,   0.        ,\n",
      "         11.20948852,  11.42185288,   8.19203445,  10.17525597,\n",
      "         11.95613397,  11.56506179,   9.13060445,   9.29187176,\n",
      "          8.15166136,   8.23006506,   8.84915373,   8.30343023,\n",
      "         11.2237641 ,  10.82287993, 116.69177743],\n",
      "       [  9.72588091,  11.49029507,  11.53438988,  11.20948852,\n",
      "          0.        ,  11.57957036,  11.22306739,   9.13859261,\n",
      "          8.00416714,   8.11347903,  10.76178584,  11.79952273,\n",
      "          8.36313817,   8.94473855,  11.01157505,  11.20524851,\n",
      "          9.6610549 ,  11.47970717, 113.53515991],\n",
      "       [  9.91325978,  10.65127018,   8.09132603,  11.42185288,\n",
      "         11.57957036,   0.        ,  10.19076132,  11.14913457,\n",
      "          8.01497904,  10.22662375,  11.8880429 ,   8.83572162,\n",
      "          9.62774888,  10.17125276,   8.68627754,   8.58986201,\n",
      "         11.02055036,   8.20195936, 103.1242896 ],\n",
      "       [  8.60450808,   8.33860734,   8.86977281,   8.19203445,\n",
      "         11.22306739,  10.19076132,   0.        ,   9.25823308,\n",
      "          8.59949341,  11.6955161 ,   8.22286692,  11.05960807,\n",
      "          9.26773023,  11.83977492,  10.63031311,  11.21776576,\n",
      "          8.10131787,   9.22655274,  80.31803431],\n",
      "       [  9.50115837,   8.88809786,  11.27540672,  10.17525597,\n",
      "          9.13859261,  11.14913457,   9.25823308,   0.        ,\n",
      "         11.02345357,   8.71314753,  10.66198773,   9.95449414,\n",
      "          8.29711708,   9.56968893,  11.47314045,  11.04922624,\n",
      "         11.36644903,   8.69355859,  84.27804082],\n",
      "       [ 10.91615142,  11.86786775,   9.44013753,  11.95613397,\n",
      "          8.00416714,   8.01497904,   8.59949341,  11.02345357,\n",
      "          0.        ,  10.36649366,   9.01459539,   8.50196981,\n",
      "         10.24199153,   9.01413545,  10.8651746 ,   8.73945359,\n",
      "          9.49328392,  10.95063845, 105.06297613],\n",
      "       [ 11.81350974,   9.25818495,  10.61901002,  11.56506179,\n",
      "          8.11347903,  10.22662375,  11.6955161 ,   8.71314753,\n",
      "         10.36649366,   0.        ,   9.27746018,  11.92108069,\n",
      "          8.63413464,  10.20054372,  11.94518796,   8.47182754,\n",
      "         10.58547852,  10.32572754,  90.45659317],\n",
      "       [  8.9852223 ,  11.68602726,  10.63050405,   9.13060445,\n",
      "         10.76178584,  11.8880429 ,   8.22286692,  10.66198773,\n",
      "          9.01459539,   9.27746018,   0.        ,   8.05666516,\n",
      "         11.04409073,  10.99370358,  11.64886694,  11.83759545,\n",
      "         11.46201003,  10.55497495,  90.49497857],\n",
      "       [ 10.80194249,  10.73935883,   8.62482374,   9.29187176,\n",
      "         11.79952273,   8.83572162,  11.05960807,   9.95449414,\n",
      "          8.50196981,  11.92108069,   8.05666516,   0.        ,\n",
      "          9.58238503,   9.85598834,   8.99850643,  11.94521517,\n",
      "          9.28969472,  10.38872064, 114.97360564],\n",
      "       [  9.73499996,   8.71533211,  11.93621388,   8.15166136,\n",
      "          8.36313817,   9.62774888,   9.26773023,   8.29711708,\n",
      "         10.24199153,   8.63413464,  11.04409073,   9.58238503,\n",
      "          0.        ,  11.27384325,  11.28665671,   8.90522964,\n",
      "         10.41042621,  10.61255726, 106.22071351],\n",
      "       [  9.19422365,  10.60486084,   8.57698697,   8.23006506,\n",
      "          8.94473855,  10.17125276,  11.83977492,   9.56968893,\n",
      "          9.01413545,  10.20054372,  10.99370358,   9.85598834,\n",
      "         11.27384325,   0.        ,   9.54211704,  11.54586854,\n",
      "          8.92633187,  10.4308838 , 114.1328218 ],\n",
      "       [  8.12723414,  11.70825125,  11.36443595,   8.84915373,\n",
      "         11.01157505,   8.68627754,  10.63031311,  11.47314045,\n",
      "         10.8651746 ,  11.94518796,  11.64886694,   8.99850643,\n",
      "         11.28665671,   9.54211704,   0.        ,   9.42280233,\n",
      "         11.65808696,  10.24933329, 100.32308979],\n",
      "       [ 10.69973564,   8.60692948,   8.97319535,   8.30343023,\n",
      "         11.20524851,   8.58986201,  11.21776576,  11.04922624,\n",
      "          8.73945359,   8.47182754,  11.83759545,  11.94521517,\n",
      "          8.90522964,  11.54586854,   9.42280233,   0.        ,\n",
      "         11.44854903,   8.67962924, 101.35876193],\n",
      "       [  8.60534515,  11.47275338,   9.8559768 ,  11.2237641 ,\n",
      "          9.6610549 ,  11.02055036,   8.10131787,  11.36644903,\n",
      "          9.49328392,  10.58547852,  11.46201003,   9.28969472,\n",
      "         10.41042621,   8.92633187,  11.65808696,  11.44854903,\n",
      "          0.        ,  10.51361586,  96.80376159],\n",
      "       [ 11.55299163,  10.84320426,  10.59985665,  10.82287993,\n",
      "         11.47970717,   8.20195936,   9.22655274,   8.69355859,\n",
      "         10.95063845,  10.32572754,  10.55497495,  10.38872064,\n",
      "         10.61255726,  10.4308838 ,  10.24933329,   8.67962924,\n",
      "         10.51361586,   0.        ,  91.90437345]]), 'private_cpu': array([1.52424030e+09, 1.36612999e+09, 1.32985713e+09, 1.75903750e+09,\n",
      "       1.78521529e+09, 1.58565730e+09, 1.36855507e+09, 1.56036396e+09,\n",
      "       1.23146379e+09, 1.28074522e+09, 1.54077462e+09, 1.70275186e+09,\n",
      "       1.42938204e+09, 1.77064224e+09, 1.54900140e+09, 1.34500170e+09,\n",
      "       1.28934975e+09, 1.34111888e+09]), 'public_cpu': array([5.41968088e+08, 7.71454134e+08, 8.41493012e+08, 8.07566257e+08,\n",
      "       8.21473667e+08, 7.11004312e+08, 7.49406606e+08, 5.29752691e+08,\n",
      "       6.66159079e+08, 5.18725393e+08, 8.65619117e+08, 7.79462658e+08,\n",
      "       5.91542663e+08, 8.11924367e+08, 7.42569242e+08, 8.35342189e+08,\n",
      "       7.18293796e+08, 5.95744952e+08]), 'cloud_cpu': 30000000000.0, 'N_agents': 18, 'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), 'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
      "0    heavy           0    1.0     3600    1.0        18   345, 'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
      "0          0  1.741183e+09  5713.849721  0.708673       0\n",
      "1          1  1.352326e+09  4566.428755  0.234989       1\n",
      "2          2  1.726668e+09  5815.120004  0.228174       2\n",
      "3          3  1.543616e+09  3539.850245  0.310369       3\n",
      "4          4  1.130883e+09  4161.367769  0.548990       4\n",
      "5          5  1.761336e+09  7349.509397  0.427498       5\n",
      "6          6  1.093196e+09  6389.821853  0.733849       6\n",
      "7          7  1.022066e+09  5354.805771  0.492160       7\n",
      "8          8  1.280853e+09  3931.170813  0.647444       8\n",
      "9          9  1.260889e+09  5133.304392  0.434945       9\n",
      "10        10  8.077840e+08  6774.364061  0.696332      10\n",
      "11        11  1.252718e+09  5907.761753  0.250139      11\n",
      "12        12  1.849537e+09  4251.816941  0.275633      12\n",
      "13        13  2.013685e+09  3452.486291  0.387815      13\n",
      "14        14  1.566043e+09  6514.168780  0.410745      14\n",
      "15        15  1.573528e+09  7018.517023  0.746995      15\n",
      "16        16  1.386095e+09  6122.347442  0.414992      16\n",
      "17        17  1.604826e+09  3449.292167  0.516951      17, 'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
      "0        heavy           0       0     0.0         0        0\n",
      "1        heavy           0       0     0.0         1        1\n",
      "2        heavy           0       0     0.0         4        2\n",
      "3        heavy           0       0     0.0         7        3\n",
      "4        heavy           0       0     0.0        10        4\n",
      "...        ...         ...     ...     ...       ...      ...\n",
      "30631    heavy           0    3599  3599.0         5    30631\n",
      "30632    heavy           0    3599  3599.0         6    30632\n",
      "30633    heavy           0    3599  3599.0         6    30633\n",
      "30634    heavy           0    3599  3599.0         7    30634\n",
      "30635    heavy           0    3599  3599.0         7    30635\n",
      "\n",
      "[30636 rows x 6 columns], 'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
      "0        heavy           0        0         0               0             0.0   \n",
      "1        heavy           0        1         1               0             0.0   \n",
      "2        heavy           0        2         4               0             0.0   \n",
      "3        heavy           0        3         7               0             0.0   \n",
      "4        heavy           0        4        10               0             0.0   \n",
      "...        ...         ...      ...       ...             ...             ...   \n",
      "30631    heavy           0    30631         5            3599          3599.0   \n",
      "30632    heavy           0    30632         6            3599          3599.0   \n",
      "30633    heavy           0    30633         6            3599          3599.0   \n",
      "30634    heavy           0    30634         7            3599          3599.0   \n",
      "30635    heavy           0    30635         7            3599          3599.0   \n",
      "\n",
      "            b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
      "0       7.202096    9.727147e+08  7.005585e+09   66.611010   sensor   \n",
      "1       5.479984    1.314973e+09  7.206031e+09   77.928800    image   \n",
      "2       8.421977    2.500222e+09  2.105681e+10   72.966446     text   \n",
      "3       6.324986    1.779582e+09  1.125583e+10   56.492900   sensor   \n",
      "4      11.473269    1.087572e+09  1.247800e+10   73.389854   sensor   \n",
      "...          ...             ...           ...         ...      ...   \n",
      "30631   6.238504    1.090296e+09  6.801814e+09   69.218260    video   \n",
      "30632   3.289880    1.599958e+09  5.263669e+09   39.210260   sensor   \n",
      "30633   6.192005    8.322764e+08  5.153459e+09   73.052900   sensor   \n",
      "30634   3.244716    1.627807e+09  5.281771e+09  103.576775    image   \n",
      "30635   1.736996    2.141823e+09  3.720338e+09   92.836210     text   \n",
      "\n",
      "       has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
      "0                 1    0.800726       0.800726           0     0.000000   \n",
      "1                 1    0.615113       0.615113           0     0.000000   \n",
      "2                 1    0.323007       0.323007           1     0.539704   \n",
      "3                 1    0.481587       0.481587           0     0.000000   \n",
      "4                 1    0.594564       0.594564           0     0.000000   \n",
      "...             ...         ...            ...         ...          ...   \n",
      "30631             1    0.525271    3599.525400           1     0.605597   \n",
      "30632             0         NaN            NaN           0     0.000000   \n",
      "30633             0         NaN            NaN           1     0.566783   \n",
      "30634             0         NaN            NaN           1     0.706580   \n",
      "30635             1    0.763454    3599.763400           0     0.000000   \n",
      "\n",
      "      action_space_hint  \n",
      "0              discrete  \n",
      "1              discrete  \n",
      "2            continuous  \n",
      "3              discrete  \n",
      "4              discrete  \n",
      "...                 ...  \n",
      "30631        continuous  \n",
      "30632          discrete  \n",
      "30633        continuous  \n",
      "30634        continuous  \n",
      "30635          discrete  \n",
      "\n",
      "[30636 rows x 17 columns], 'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'cloud_cycles': array([0.])}, 'action_space': {'type': 'discrete', 'n': 3, 'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}}, 'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,), 'dtype': 'float'}, 'mec_public_cycles': {'shape': (18,), 'dtype': 'float'}, 'cloud_cycles': {'shape': (1,), 'dtype': 'float'}}, 'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}}, 'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'}, 'public_cpu': {'shape': (18,), 'dtype': 'float'}, 'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}}, 'note': 'Declarative spec; tensor assembly happens in the Env at each step.'}, 'checks': {'delta_match': True, 'message': 'OK'}}, 'light': {'Delta': 1.0, 'K': 18, 'topology_type': 'fully_connected', 'connection_matrix': array([[  0.        ,  11.92281432,  10.47890811,  11.62756381,\n",
      "          9.72588091,   9.91325978,   8.60450808,   9.50115837,\n",
      "         10.91615142,  11.81350974,   8.9852223 ,  10.80194249,\n",
      "          9.73499996,   9.19422365,   8.12723414,  10.69973564,\n",
      "          8.60534515,  11.55299163,  92.53424509],\n",
      "       [ 11.92281432,   0.        ,  11.08031243,  10.34304631,\n",
      "         11.49029507,  10.65127018,   8.33860734,   8.88809786,\n",
      "         11.86786775,   9.25818495,  11.68602726,  10.73935883,\n",
      "          8.71533211,  10.60486084,  11.70825125,   8.60692948,\n",
      "         11.47275338,  10.84320426, 102.77092651],\n",
      "       [ 10.47890811,  11.08031243,   0.        ,  10.64649505,\n",
      "         11.53438988,   8.09132603,   8.86977281,  11.27540672,\n",
      "          9.44013753,  10.61901002,  10.63050405,   8.62482374,\n",
      "         11.93621388,   8.57698697,  11.36443595,   8.97319535,\n",
      "          9.8559768 ,  10.59985665,  90.21900011],\n",
      "       [ 11.62756381,  10.34304631,  10.64649505,   0.        ,\n",
      "         11.20948852,  11.42185288,   8.19203445,  10.17525597,\n",
      "         11.95613397,  11.56506179,   9.13060445,   9.29187176,\n",
      "          8.15166136,   8.23006506,   8.84915373,   8.30343023,\n",
      "         11.2237641 ,  10.82287993, 116.69177743],\n",
      "       [  9.72588091,  11.49029507,  11.53438988,  11.20948852,\n",
      "          0.        ,  11.57957036,  11.22306739,   9.13859261,\n",
      "          8.00416714,   8.11347903,  10.76178584,  11.79952273,\n",
      "          8.36313817,   8.94473855,  11.01157505,  11.20524851,\n",
      "          9.6610549 ,  11.47970717, 113.53515991],\n",
      "       [  9.91325978,  10.65127018,   8.09132603,  11.42185288,\n",
      "         11.57957036,   0.        ,  10.19076132,  11.14913457,\n",
      "          8.01497904,  10.22662375,  11.8880429 ,   8.83572162,\n",
      "          9.62774888,  10.17125276,   8.68627754,   8.58986201,\n",
      "         11.02055036,   8.20195936, 103.1242896 ],\n",
      "       [  8.60450808,   8.33860734,   8.86977281,   8.19203445,\n",
      "         11.22306739,  10.19076132,   0.        ,   9.25823308,\n",
      "          8.59949341,  11.6955161 ,   8.22286692,  11.05960807,\n",
      "          9.26773023,  11.83977492,  10.63031311,  11.21776576,\n",
      "          8.10131787,   9.22655274,  80.31803431],\n",
      "       [  9.50115837,   8.88809786,  11.27540672,  10.17525597,\n",
      "          9.13859261,  11.14913457,   9.25823308,   0.        ,\n",
      "         11.02345357,   8.71314753,  10.66198773,   9.95449414,\n",
      "          8.29711708,   9.56968893,  11.47314045,  11.04922624,\n",
      "         11.36644903,   8.69355859,  84.27804082],\n",
      "       [ 10.91615142,  11.86786775,   9.44013753,  11.95613397,\n",
      "          8.00416714,   8.01497904,   8.59949341,  11.02345357,\n",
      "          0.        ,  10.36649366,   9.01459539,   8.50196981,\n",
      "         10.24199153,   9.01413545,  10.8651746 ,   8.73945359,\n",
      "          9.49328392,  10.95063845, 105.06297613],\n",
      "       [ 11.81350974,   9.25818495,  10.61901002,  11.56506179,\n",
      "          8.11347903,  10.22662375,  11.6955161 ,   8.71314753,\n",
      "         10.36649366,   0.        ,   9.27746018,  11.92108069,\n",
      "          8.63413464,  10.20054372,  11.94518796,   8.47182754,\n",
      "         10.58547852,  10.32572754,  90.45659317],\n",
      "       [  8.9852223 ,  11.68602726,  10.63050405,   9.13060445,\n",
      "         10.76178584,  11.8880429 ,   8.22286692,  10.66198773,\n",
      "          9.01459539,   9.27746018,   0.        ,   8.05666516,\n",
      "         11.04409073,  10.99370358,  11.64886694,  11.83759545,\n",
      "         11.46201003,  10.55497495,  90.49497857],\n",
      "       [ 10.80194249,  10.73935883,   8.62482374,   9.29187176,\n",
      "         11.79952273,   8.83572162,  11.05960807,   9.95449414,\n",
      "          8.50196981,  11.92108069,   8.05666516,   0.        ,\n",
      "          9.58238503,   9.85598834,   8.99850643,  11.94521517,\n",
      "          9.28969472,  10.38872064, 114.97360564],\n",
      "       [  9.73499996,   8.71533211,  11.93621388,   8.15166136,\n",
      "          8.36313817,   9.62774888,   9.26773023,   8.29711708,\n",
      "         10.24199153,   8.63413464,  11.04409073,   9.58238503,\n",
      "          0.        ,  11.27384325,  11.28665671,   8.90522964,\n",
      "         10.41042621,  10.61255726, 106.22071351],\n",
      "       [  9.19422365,  10.60486084,   8.57698697,   8.23006506,\n",
      "          8.94473855,  10.17125276,  11.83977492,   9.56968893,\n",
      "          9.01413545,  10.20054372,  10.99370358,   9.85598834,\n",
      "         11.27384325,   0.        ,   9.54211704,  11.54586854,\n",
      "          8.92633187,  10.4308838 , 114.1328218 ],\n",
      "       [  8.12723414,  11.70825125,  11.36443595,   8.84915373,\n",
      "         11.01157505,   8.68627754,  10.63031311,  11.47314045,\n",
      "         10.8651746 ,  11.94518796,  11.64886694,   8.99850643,\n",
      "         11.28665671,   9.54211704,   0.        ,   9.42280233,\n",
      "         11.65808696,  10.24933329, 100.32308979],\n",
      "       [ 10.69973564,   8.60692948,   8.97319535,   8.30343023,\n",
      "         11.20524851,   8.58986201,  11.21776576,  11.04922624,\n",
      "          8.73945359,   8.47182754,  11.83759545,  11.94521517,\n",
      "          8.90522964,  11.54586854,   9.42280233,   0.        ,\n",
      "         11.44854903,   8.67962924, 101.35876193],\n",
      "       [  8.60534515,  11.47275338,   9.8559768 ,  11.2237641 ,\n",
      "          9.6610549 ,  11.02055036,   8.10131787,  11.36644903,\n",
      "          9.49328392,  10.58547852,  11.46201003,   9.28969472,\n",
      "         10.41042621,   8.92633187,  11.65808696,  11.44854903,\n",
      "          0.        ,  10.51361586,  96.80376159],\n",
      "       [ 11.55299163,  10.84320426,  10.59985665,  10.82287993,\n",
      "         11.47970717,   8.20195936,   9.22655274,   8.69355859,\n",
      "         10.95063845,  10.32572754,  10.55497495,  10.38872064,\n",
      "         10.61255726,  10.4308838 ,  10.24933329,   8.67962924,\n",
      "         10.51361586,   0.        ,  91.90437345]]), 'private_cpu': array([1.52424030e+09, 1.36612999e+09, 1.32985713e+09, 1.75903750e+09,\n",
      "       1.78521529e+09, 1.58565730e+09, 1.36855507e+09, 1.56036396e+09,\n",
      "       1.23146379e+09, 1.28074522e+09, 1.54077462e+09, 1.70275186e+09,\n",
      "       1.42938204e+09, 1.77064224e+09, 1.54900140e+09, 1.34500170e+09,\n",
      "       1.28934975e+09, 1.34111888e+09]), 'public_cpu': array([5.41968088e+08, 7.71454134e+08, 8.41493012e+08, 8.07566257e+08,\n",
      "       8.21473667e+08, 7.11004312e+08, 7.49406606e+08, 5.29752691e+08,\n",
      "       6.66159079e+08, 5.18725393e+08, 8.65619117e+08, 7.79462658e+08,\n",
      "       5.91542663e+08, 8.11924367e+08, 7.42569242e+08, 8.35342189e+08,\n",
      "       7.18293796e+08, 5.95744952e+08]), 'cloud_cpu': 30000000000.0, 'N_agents': 18, 'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), 'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
      "0    light           0    1.0     3600    1.0        18   143, 'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
      "0          0  9.214683e+08  5152.146294  0.021214       0\n",
      "1          1  1.988512e+09  4208.470915  0.030254       1\n",
      "2          2  1.361339e+09  4466.022492  0.028701       2\n",
      "3          3  2.155303e+09  7570.283244  0.038873       3\n",
      "4          4  8.727403e+08  6918.455560  0.037506       4\n",
      "5          5  2.350478e+09  7997.219317  0.013920       5\n",
      "6          6  1.080474e+09  3611.664818  0.031591       6\n",
      "7          7  1.483437e+09  5690.301814  0.026184       7\n",
      "8          8  1.782616e+09  5312.418573  0.040268       8\n",
      "9          9  2.164538e+09  6264.107462  0.048391       9\n",
      "10        10  2.381892e+09  5233.485875  0.039955      10\n",
      "11        11  1.698112e+09  5619.134661  0.037599      11\n",
      "12        12  1.170523e+09  5302.008006  0.034852      12\n",
      "13        13  1.004000e+09  6356.746540  0.027640      13\n",
      "14        14  1.206141e+09  4332.462100  0.038611      14\n",
      "15        15  2.062918e+09  5181.575792  0.042660      15\n",
      "16        16  1.493700e+09  6776.846182  0.026377      16\n",
      "17        17  1.302068e+09  6167.829828  0.025928      17, 'arrivals':      scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
      "0       light           0       0     0.0         1        0\n",
      "1       light           0       0     0.0        17        1\n",
      "2       light           0       7     7.0        17        2\n",
      "3       light           0       9     9.0         3        3\n",
      "4       light           0      13    13.0        15        4\n",
      "...       ...         ...     ...     ...       ...      ...\n",
      "2108    light           0    3594  3594.0        14     2108\n",
      "2109    light           0    3597  3597.0        11     2109\n",
      "2110    light           0    3597  3597.0        16     2110\n",
      "2111    light           0    3598  3598.0        14     2111\n",
      "2112    light           0    3599  3599.0        17     2112\n",
      "\n",
      "[2113 rows x 6 columns], 'tasks':      scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
      "0       light           0        0         1               0             0.0   \n",
      "1       light           0        1        17               0             0.0   \n",
      "2       light           0        2        17               7             7.0   \n",
      "3       light           0        3         3               9             9.0   \n",
      "4       light           0        4        15              13            13.0   \n",
      "...       ...         ...      ...       ...             ...             ...   \n",
      "2108    light           0     2108        14            3594          3594.0   \n",
      "2109    light           0     2109        11            3597          3597.0   \n",
      "2110    light           0     2110        16            3597          3597.0   \n",
      "2111    light           0     2111        14            3598          3598.0   \n",
      "2112    light           0     2112        17            3599          3599.0   \n",
      "\n",
      "          b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
      "0     2.484967    5.525261e+08  1.373009e+09   62.412148    video   \n",
      "1     2.509962    1.082130e+09  2.716106e+09   74.606000     text   \n",
      "2     1.509317    1.757732e+09  2.652974e+09   30.173971     text   \n",
      "3     2.114311    4.582521e+08  9.688874e+08   52.914295    image   \n",
      "4     1.707707    6.574788e+08  1.122781e+09   95.441150    image   \n",
      "...        ...             ...           ...         ...      ...   \n",
      "2108  2.306310    1.006178e+09  2.320560e+09   64.688480     text   \n",
      "2109  3.687047    1.297120e+09  4.782541e+09  106.002625   sensor   \n",
      "2110  2.407504    9.582727e+08  2.307045e+09   65.863180    image   \n",
      "2111  1.205960    1.482103e+09  1.787356e+09   65.631966    image   \n",
      "2112  1.339075    4.337156e+08  5.807776e+08   81.440796    video   \n",
      "\n",
      "      has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
      "0                1    1.339893       1.339893           1     0.424900   \n",
      "1                0         NaN            NaN           0     0.000000   \n",
      "2                0         NaN            NaN           1     0.358162   \n",
      "3                0         NaN            NaN           0     0.000000   \n",
      "4                0         NaN            NaN           0     0.000000   \n",
      "...            ...         ...            ...         ...          ...   \n",
      "2108             0         NaN            NaN           0     0.000000   \n",
      "2109             0         NaN            NaN           0     0.000000   \n",
      "2110             0         NaN            NaN           1     0.393362   \n",
      "2111             0         NaN            NaN           0     0.000000   \n",
      "2112             0         NaN            NaN           0     0.000000   \n",
      "\n",
      "     action_space_hint  \n",
      "0           continuous  \n",
      "1             discrete  \n",
      "2           continuous  \n",
      "3             discrete  \n",
      "4             discrete  \n",
      "...                ...  \n",
      "2108          discrete  \n",
      "2109          discrete  \n",
      "2110        continuous  \n",
      "2111          discrete  \n",
      "2112          discrete  \n",
      "\n",
      "[2113 rows x 17 columns], 'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'cloud_cycles': array([0.])}, 'action_space': {'type': 'discrete', 'n': 3, 'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}}, 'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,), 'dtype': 'float'}, 'mec_public_cycles': {'shape': (18,), 'dtype': 'float'}, 'cloud_cycles': {'shape': (1,), 'dtype': 'float'}}, 'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}}, 'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'}, 'public_cpu': {'shape': (18,), 'dtype': 'float'}, 'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}}, 'note': 'Declarative spec; tensor assembly happens in the Env at each step.'}, 'checks': {'delta_match': True, 'message': 'OK'}}, 'moderate': {'Delta': 1.0, 'K': 18, 'topology_type': 'fully_connected', 'connection_matrix': array([[  0.        ,  11.92281432,  10.47890811,  11.62756381,\n",
      "          9.72588091,   9.91325978,   8.60450808,   9.50115837,\n",
      "         10.91615142,  11.81350974,   8.9852223 ,  10.80194249,\n",
      "          9.73499996,   9.19422365,   8.12723414,  10.69973564,\n",
      "          8.60534515,  11.55299163,  92.53424509],\n",
      "       [ 11.92281432,   0.        ,  11.08031243,  10.34304631,\n",
      "         11.49029507,  10.65127018,   8.33860734,   8.88809786,\n",
      "         11.86786775,   9.25818495,  11.68602726,  10.73935883,\n",
      "          8.71533211,  10.60486084,  11.70825125,   8.60692948,\n",
      "         11.47275338,  10.84320426, 102.77092651],\n",
      "       [ 10.47890811,  11.08031243,   0.        ,  10.64649505,\n",
      "         11.53438988,   8.09132603,   8.86977281,  11.27540672,\n",
      "          9.44013753,  10.61901002,  10.63050405,   8.62482374,\n",
      "         11.93621388,   8.57698697,  11.36443595,   8.97319535,\n",
      "          9.8559768 ,  10.59985665,  90.21900011],\n",
      "       [ 11.62756381,  10.34304631,  10.64649505,   0.        ,\n",
      "         11.20948852,  11.42185288,   8.19203445,  10.17525597,\n",
      "         11.95613397,  11.56506179,   9.13060445,   9.29187176,\n",
      "          8.15166136,   8.23006506,   8.84915373,   8.30343023,\n",
      "         11.2237641 ,  10.82287993, 116.69177743],\n",
      "       [  9.72588091,  11.49029507,  11.53438988,  11.20948852,\n",
      "          0.        ,  11.57957036,  11.22306739,   9.13859261,\n",
      "          8.00416714,   8.11347903,  10.76178584,  11.79952273,\n",
      "          8.36313817,   8.94473855,  11.01157505,  11.20524851,\n",
      "          9.6610549 ,  11.47970717, 113.53515991],\n",
      "       [  9.91325978,  10.65127018,   8.09132603,  11.42185288,\n",
      "         11.57957036,   0.        ,  10.19076132,  11.14913457,\n",
      "          8.01497904,  10.22662375,  11.8880429 ,   8.83572162,\n",
      "          9.62774888,  10.17125276,   8.68627754,   8.58986201,\n",
      "         11.02055036,   8.20195936, 103.1242896 ],\n",
      "       [  8.60450808,   8.33860734,   8.86977281,   8.19203445,\n",
      "         11.22306739,  10.19076132,   0.        ,   9.25823308,\n",
      "          8.59949341,  11.6955161 ,   8.22286692,  11.05960807,\n",
      "          9.26773023,  11.83977492,  10.63031311,  11.21776576,\n",
      "          8.10131787,   9.22655274,  80.31803431],\n",
      "       [  9.50115837,   8.88809786,  11.27540672,  10.17525597,\n",
      "          9.13859261,  11.14913457,   9.25823308,   0.        ,\n",
      "         11.02345357,   8.71314753,  10.66198773,   9.95449414,\n",
      "          8.29711708,   9.56968893,  11.47314045,  11.04922624,\n",
      "         11.36644903,   8.69355859,  84.27804082],\n",
      "       [ 10.91615142,  11.86786775,   9.44013753,  11.95613397,\n",
      "          8.00416714,   8.01497904,   8.59949341,  11.02345357,\n",
      "          0.        ,  10.36649366,   9.01459539,   8.50196981,\n",
      "         10.24199153,   9.01413545,  10.8651746 ,   8.73945359,\n",
      "          9.49328392,  10.95063845, 105.06297613],\n",
      "       [ 11.81350974,   9.25818495,  10.61901002,  11.56506179,\n",
      "          8.11347903,  10.22662375,  11.6955161 ,   8.71314753,\n",
      "         10.36649366,   0.        ,   9.27746018,  11.92108069,\n",
      "          8.63413464,  10.20054372,  11.94518796,   8.47182754,\n",
      "         10.58547852,  10.32572754,  90.45659317],\n",
      "       [  8.9852223 ,  11.68602726,  10.63050405,   9.13060445,\n",
      "         10.76178584,  11.8880429 ,   8.22286692,  10.66198773,\n",
      "          9.01459539,   9.27746018,   0.        ,   8.05666516,\n",
      "         11.04409073,  10.99370358,  11.64886694,  11.83759545,\n",
      "         11.46201003,  10.55497495,  90.49497857],\n",
      "       [ 10.80194249,  10.73935883,   8.62482374,   9.29187176,\n",
      "         11.79952273,   8.83572162,  11.05960807,   9.95449414,\n",
      "          8.50196981,  11.92108069,   8.05666516,   0.        ,\n",
      "          9.58238503,   9.85598834,   8.99850643,  11.94521517,\n",
      "          9.28969472,  10.38872064, 114.97360564],\n",
      "       [  9.73499996,   8.71533211,  11.93621388,   8.15166136,\n",
      "          8.36313817,   9.62774888,   9.26773023,   8.29711708,\n",
      "         10.24199153,   8.63413464,  11.04409073,   9.58238503,\n",
      "          0.        ,  11.27384325,  11.28665671,   8.90522964,\n",
      "         10.41042621,  10.61255726, 106.22071351],\n",
      "       [  9.19422365,  10.60486084,   8.57698697,   8.23006506,\n",
      "          8.94473855,  10.17125276,  11.83977492,   9.56968893,\n",
      "          9.01413545,  10.20054372,  10.99370358,   9.85598834,\n",
      "         11.27384325,   0.        ,   9.54211704,  11.54586854,\n",
      "          8.92633187,  10.4308838 , 114.1328218 ],\n",
      "       [  8.12723414,  11.70825125,  11.36443595,   8.84915373,\n",
      "         11.01157505,   8.68627754,  10.63031311,  11.47314045,\n",
      "         10.8651746 ,  11.94518796,  11.64886694,   8.99850643,\n",
      "         11.28665671,   9.54211704,   0.        ,   9.42280233,\n",
      "         11.65808696,  10.24933329, 100.32308979],\n",
      "       [ 10.69973564,   8.60692948,   8.97319535,   8.30343023,\n",
      "         11.20524851,   8.58986201,  11.21776576,  11.04922624,\n",
      "          8.73945359,   8.47182754,  11.83759545,  11.94521517,\n",
      "          8.90522964,  11.54586854,   9.42280233,   0.        ,\n",
      "         11.44854903,   8.67962924, 101.35876193],\n",
      "       [  8.60534515,  11.47275338,   9.8559768 ,  11.2237641 ,\n",
      "          9.6610549 ,  11.02055036,   8.10131787,  11.36644903,\n",
      "          9.49328392,  10.58547852,  11.46201003,   9.28969472,\n",
      "         10.41042621,   8.92633187,  11.65808696,  11.44854903,\n",
      "          0.        ,  10.51361586,  96.80376159],\n",
      "       [ 11.55299163,  10.84320426,  10.59985665,  10.82287993,\n",
      "         11.47970717,   8.20195936,   9.22655274,   8.69355859,\n",
      "         10.95063845,  10.32572754,  10.55497495,  10.38872064,\n",
      "         10.61255726,  10.4308838 ,  10.24933329,   8.67962924,\n",
      "         10.51361586,   0.        ,  91.90437345]]), 'private_cpu': array([1.52424030e+09, 1.36612999e+09, 1.32985713e+09, 1.75903750e+09,\n",
      "       1.78521529e+09, 1.58565730e+09, 1.36855507e+09, 1.56036396e+09,\n",
      "       1.23146379e+09, 1.28074522e+09, 1.54077462e+09, 1.70275186e+09,\n",
      "       1.42938204e+09, 1.77064224e+09, 1.54900140e+09, 1.34500170e+09,\n",
      "       1.28934975e+09, 1.34111888e+09]), 'public_cpu': array([5.41968088e+08, 7.71454134e+08, 8.41493012e+08, 8.07566257e+08,\n",
      "       8.21473667e+08, 7.11004312e+08, 7.49406606e+08, 5.29752691e+08,\n",
      "       6.66159079e+08, 5.18725393e+08, 8.65619117e+08, 7.79462658e+08,\n",
      "       5.91542663e+08, 8.11924367e+08, 7.42569242e+08, 8.35342189e+08,\n",
      "       7.18293796e+08, 5.95744952e+08]), 'cloud_cpu': 30000000000.0, 'N_agents': 18, 'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), 'episodes':    scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
      "0  moderate           0    1.0     3600    1.0        18   244, 'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
      "0          0  2.075234e+09  4177.077472  0.083588       0\n",
      "1          1  1.845675e+09  4444.750864  0.117454       1\n",
      "2          2  1.422351e+09  3116.790674  0.190249       2\n",
      "3          3  8.627662e+08  3819.530831  0.180022       3\n",
      "4          4  1.576391e+09  4456.416731  0.124874       4\n",
      "5          5  1.361574e+09  6518.273845  0.093241       5\n",
      "6          6  1.146421e+09  4031.095267  0.197552       6\n",
      "7          7  1.093930e+09  5125.594407  0.160180       7\n",
      "8          8  8.213925e+08  5099.239983  0.089347       8\n",
      "9          9  1.378500e+09  3320.898803  0.115078       9\n",
      "10        10  1.967238e+09  3878.558132  0.066943      10\n",
      "11        11  1.937473e+09  5303.971140  0.051492      11\n",
      "12        12  1.973373e+09  4718.837422  0.187653      12\n",
      "13        13  2.334762e+09  4156.023984  0.171413      13\n",
      "14        14  1.989451e+09  5301.096958  0.169348      14\n",
      "15        15  2.245627e+09  3973.902321  0.114526      15\n",
      "16        16  9.699633e+08  5954.812618  0.109306      16\n",
      "17        17  1.298186e+09  6890.123320  0.106591      17, 'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
      "0     moderate           0       1     1.0         3        0\n",
      "1     moderate           0       1     1.0        12        1\n",
      "2     moderate           0       1     1.0        13        2\n",
      "3     moderate           0       1     1.0        13        3\n",
      "4     moderate           0       3     3.0         5        4\n",
      "...        ...         ...     ...     ...       ...      ...\n",
      "8257  moderate           0    3597  3597.0        13     8257\n",
      "8258  moderate           0    3597  3597.0        13     8258\n",
      "8259  moderate           0    3597  3597.0        14     8259\n",
      "8260  moderate           0    3598  3598.0        13     8260\n",
      "8261  moderate           0    3599  3599.0         6     8261\n",
      "\n",
      "[8262 rows x 6 columns], 'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
      "0     moderate           0        0         3               1             1.0   \n",
      "1     moderate           0        1        12               1             1.0   \n",
      "2     moderate           0        2        13               1             1.0   \n",
      "3     moderate           0        3        13               1             1.0   \n",
      "4     moderate           0        4         5               3             3.0   \n",
      "...        ...         ...      ...       ...             ...             ...   \n",
      "8257  moderate           0     8257        13            3597          3597.0   \n",
      "8258  moderate           0     8258        13            3597          3597.0   \n",
      "8259  moderate           0     8259        14            3597          3597.0   \n",
      "8260  moderate           0     8260        13            3598          3598.0   \n",
      "8261  moderate           0     8261         6            3599          3599.0   \n",
      "\n",
      "          b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
      "0     4.463301    1.368071e+09  6.106115e+09   59.895400    video   \n",
      "1     2.032145    1.310597e+09  2.663323e+09   39.163837     text   \n",
      "2     2.471461    1.423734e+09  3.518704e+09   71.265870    image   \n",
      "3     2.097559    7.160129e+08  1.501879e+09   73.560420     text   \n",
      "4     2.683642    9.887779e+08  2.653526e+09  114.356410    video   \n",
      "...        ...             ...           ...         ...      ...   \n",
      "8257  2.391213    5.808735e+08  1.388992e+09   56.940155    video   \n",
      "8258  2.583749    1.690439e+09  4.367671e+09   67.638040    video   \n",
      "8259  2.405940    1.218846e+09  2.932471e+09   66.223816   sensor   \n",
      "8260  2.014641    9.512537e+08  1.916434e+09   36.491844     text   \n",
      "8261  4.927452    2.140466e+09  1.054704e+10   47.556170    image   \n",
      "\n",
      "      has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
      "0                0         NaN            NaN           0     0.000000   \n",
      "1                0         NaN            NaN           1     0.619935   \n",
      "2                0         NaN            NaN           0     0.000000   \n",
      "3                0         NaN            NaN           1     0.667023   \n",
      "4                1    0.868840       3.868839           0     0.000000   \n",
      "...            ...         ...            ...         ...          ...   \n",
      "8257             0         NaN            NaN           0     0.000000   \n",
      "8258             0         NaN            NaN           0     0.000000   \n",
      "8259             1    1.438337    3598.438200           0     0.000000   \n",
      "8260             0         NaN            NaN           1     0.493939   \n",
      "8261             0         NaN            NaN           0     0.000000   \n",
      "\n",
      "     action_space_hint  \n",
      "0             discrete  \n",
      "1           continuous  \n",
      "2             discrete  \n",
      "3           continuous  \n",
      "4             discrete  \n",
      "...                ...  \n",
      "8257          discrete  \n",
      "8258          discrete  \n",
      "8259          discrete  \n",
      "8260        continuous  \n",
      "8261          discrete  \n",
      "\n",
      "[8262 rows x 17 columns], 'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'cloud_cycles': array([0.])}, 'action_space': {'type': 'discrete', 'n': 3, 'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}}, 'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,), 'dtype': 'float'}, 'mec_public_cycles': {'shape': (18,), 'dtype': 'float'}, 'cloud_cycles': {'shape': (1,), 'dtype': 'float'}}, 'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}}, 'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'}, 'public_cpu': {'shape': (18,), 'dtype': 'float'}, 'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}}, 'note': 'Declarative spec; tensor assembly happens in the Env at each step.'}, 'checks': {'delta_match': True, 'message': 'OK'}}}, 'sparse_ring': {'heavy': {'Delta': 1.0, 'K': 18, 'topology_type': 'skip_connections', 'connection_matrix': array([[  0.        ,   8.84365721,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   9.998233  , 110.67630067],\n",
      "       [  8.84365721,   0.        ,   9.97505999,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  92.76931356],\n",
      "       [  0.        ,   9.97505999,   0.        ,  11.95310224,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  96.02627731],\n",
      "       [  0.        ,   0.        ,  11.95310224,   0.        ,\n",
      "          9.13794468,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 119.09298037],\n",
      "       [  0.        ,   0.        ,   0.        ,   9.13794468,\n",
      "          0.        ,   8.87531982,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 116.41878804],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          8.87531982,   0.        ,   8.11860408,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 114.89278573],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   8.11860408,   0.        ,  11.80494832,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  84.22860842],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  11.80494832,   0.        ,\n",
      "         11.88844246,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  83.35489123],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,  11.88844246,\n",
      "          0.        ,  10.68030026,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 113.406384  ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         10.68030026,   0.        ,   8.33085549,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 102.93150158],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   8.33085549,   0.        ,   9.0219371 ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 117.12846943],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   9.0219371 ,   0.        ,\n",
      "          8.72814871,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  81.9905366 ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   8.72814871,\n",
      "          0.        ,   9.92346512,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  89.09483645],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          9.92346512,   0.        ,   9.77172384,   0.        ,\n",
      "          0.        ,   0.        ,  86.80566083],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   9.77172384,   0.        ,  10.16870053,\n",
      "          0.        ,   0.        ,  86.54990281],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  10.16870053,   0.        ,\n",
      "          9.18678203,   0.        , 119.58805212],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   9.18678203,\n",
      "          0.        ,  11.135163  ,  83.69352674],\n",
      "       [  9.998233  ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         11.135163  ,   0.        , 117.90994977]]), 'private_cpu': array([1.33775622e+09, 1.49393054e+09, 1.43997791e+09, 1.21062439e+09,\n",
      "       1.76267552e+09, 1.31132161e+09, 1.38049135e+09, 1.44709927e+09,\n",
      "       1.42518832e+09, 1.49771021e+09, 1.22897323e+09, 1.55137334e+09,\n",
      "       1.68413918e+09, 1.34491629e+09, 1.32974180e+09, 1.25644994e+09,\n",
      "       1.39636453e+09, 1.24796862e+09]), 'public_cpu': array([6.34923798e+08, 8.09092790e+08, 7.02435778e+08, 7.93630196e+08,\n",
      "       8.95631390e+08, 8.85066767e+08, 8.47527275e+08, 6.08503977e+08,\n",
      "       8.50440640e+08, 5.84627600e+08, 7.79588586e+08, 6.35569109e+08,\n",
      "       8.83065611e+08, 6.63393658e+08, 8.79030498e+08, 6.69585169e+08,\n",
      "       6.25279054e+08, 6.38664453e+08]), 'cloud_cpu': 30000000000.0, 'N_agents': 18, 'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), 'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
      "0    heavy           0    1.0     3600    1.0        18   345, 'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
      "0          0  1.741183e+09  5713.849721  0.708673       0\n",
      "1          1  1.352326e+09  4566.428755  0.234989       1\n",
      "2          2  1.726668e+09  5815.120004  0.228174       2\n",
      "3          3  1.543616e+09  3539.850245  0.310369       3\n",
      "4          4  1.130883e+09  4161.367769  0.548990       4\n",
      "5          5  1.761336e+09  7349.509397  0.427498       5\n",
      "6          6  1.093196e+09  6389.821853  0.733849       6\n",
      "7          7  1.022066e+09  5354.805771  0.492160       7\n",
      "8          8  1.280853e+09  3931.170813  0.647444       8\n",
      "9          9  1.260889e+09  5133.304392  0.434945       9\n",
      "10        10  8.077840e+08  6774.364061  0.696332      10\n",
      "11        11  1.252718e+09  5907.761753  0.250139      11\n",
      "12        12  1.849537e+09  4251.816941  0.275633      12\n",
      "13        13  2.013685e+09  3452.486291  0.387815      13\n",
      "14        14  1.566043e+09  6514.168780  0.410745      14\n",
      "15        15  1.573528e+09  7018.517023  0.746995      15\n",
      "16        16  1.386095e+09  6122.347442  0.414992      16\n",
      "17        17  1.604826e+09  3449.292167  0.516951      17, 'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
      "0        heavy           0       0     0.0         0        0\n",
      "1        heavy           0       0     0.0         1        1\n",
      "2        heavy           0       0     0.0         4        2\n",
      "3        heavy           0       0     0.0         7        3\n",
      "4        heavy           0       0     0.0        10        4\n",
      "...        ...         ...     ...     ...       ...      ...\n",
      "30631    heavy           0    3599  3599.0         5    30631\n",
      "30632    heavy           0    3599  3599.0         6    30632\n",
      "30633    heavy           0    3599  3599.0         6    30633\n",
      "30634    heavy           0    3599  3599.0         7    30634\n",
      "30635    heavy           0    3599  3599.0         7    30635\n",
      "\n",
      "[30636 rows x 6 columns], 'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
      "0        heavy           0        0         0               0             0.0   \n",
      "1        heavy           0        1         1               0             0.0   \n",
      "2        heavy           0        2         4               0             0.0   \n",
      "3        heavy           0        3         7               0             0.0   \n",
      "4        heavy           0        4        10               0             0.0   \n",
      "...        ...         ...      ...       ...             ...             ...   \n",
      "30631    heavy           0    30631         5            3599          3599.0   \n",
      "30632    heavy           0    30632         6            3599          3599.0   \n",
      "30633    heavy           0    30633         6            3599          3599.0   \n",
      "30634    heavy           0    30634         7            3599          3599.0   \n",
      "30635    heavy           0    30635         7            3599          3599.0   \n",
      "\n",
      "            b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
      "0       7.202096    9.727147e+08  7.005585e+09   66.611010   sensor   \n",
      "1       5.479984    1.314973e+09  7.206031e+09   77.928800    image   \n",
      "2       8.421977    2.500222e+09  2.105681e+10   72.966446     text   \n",
      "3       6.324986    1.779582e+09  1.125583e+10   56.492900   sensor   \n",
      "4      11.473269    1.087572e+09  1.247800e+10   73.389854   sensor   \n",
      "...          ...             ...           ...         ...      ...   \n",
      "30631   6.238504    1.090296e+09  6.801814e+09   69.218260    video   \n",
      "30632   3.289880    1.599958e+09  5.263669e+09   39.210260   sensor   \n",
      "30633   6.192005    8.322764e+08  5.153459e+09   73.052900   sensor   \n",
      "30634   3.244716    1.627807e+09  5.281771e+09  103.576775    image   \n",
      "30635   1.736996    2.141823e+09  3.720338e+09   92.836210     text   \n",
      "\n",
      "       has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
      "0                 1    0.800726       0.800726           0     0.000000   \n",
      "1                 1    0.615113       0.615113           0     0.000000   \n",
      "2                 1    0.323007       0.323007           1     0.539704   \n",
      "3                 1    0.481587       0.481587           0     0.000000   \n",
      "4                 1    0.594564       0.594564           0     0.000000   \n",
      "...             ...         ...            ...         ...          ...   \n",
      "30631             1    0.525271    3599.525400           1     0.605597   \n",
      "30632             0         NaN            NaN           0     0.000000   \n",
      "30633             0         NaN            NaN           1     0.566783   \n",
      "30634             0         NaN            NaN           1     0.706580   \n",
      "30635             1    0.763454    3599.763400           0     0.000000   \n",
      "\n",
      "      action_space_hint  \n",
      "0              discrete  \n",
      "1              discrete  \n",
      "2            continuous  \n",
      "3              discrete  \n",
      "4              discrete  \n",
      "...                 ...  \n",
      "30631        continuous  \n",
      "30632          discrete  \n",
      "30633        continuous  \n",
      "30634        continuous  \n",
      "30635          discrete  \n",
      "\n",
      "[30636 rows x 17 columns], 'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'cloud_cycles': array([0.])}, 'action_space': {'type': 'discrete', 'n': 3, 'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}}, 'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,), 'dtype': 'float'}, 'mec_public_cycles': {'shape': (18,), 'dtype': 'float'}, 'cloud_cycles': {'shape': (1,), 'dtype': 'float'}}, 'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}}, 'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'}, 'public_cpu': {'shape': (18,), 'dtype': 'float'}, 'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}}, 'note': 'Declarative spec; tensor assembly happens in the Env at each step.'}, 'checks': {'delta_match': True, 'message': 'OK'}}, 'light': {'Delta': 1.0, 'K': 18, 'topology_type': 'skip_connections', 'connection_matrix': array([[  0.        ,   8.84365721,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   9.998233  , 110.67630067],\n",
      "       [  8.84365721,   0.        ,   9.97505999,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  92.76931356],\n",
      "       [  0.        ,   9.97505999,   0.        ,  11.95310224,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  96.02627731],\n",
      "       [  0.        ,   0.        ,  11.95310224,   0.        ,\n",
      "          9.13794468,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 119.09298037],\n",
      "       [  0.        ,   0.        ,   0.        ,   9.13794468,\n",
      "          0.        ,   8.87531982,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 116.41878804],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          8.87531982,   0.        ,   8.11860408,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 114.89278573],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   8.11860408,   0.        ,  11.80494832,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  84.22860842],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  11.80494832,   0.        ,\n",
      "         11.88844246,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  83.35489123],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,  11.88844246,\n",
      "          0.        ,  10.68030026,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 113.406384  ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         10.68030026,   0.        ,   8.33085549,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 102.93150158],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   8.33085549,   0.        ,   9.0219371 ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 117.12846943],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   9.0219371 ,   0.        ,\n",
      "          8.72814871,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  81.9905366 ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   8.72814871,\n",
      "          0.        ,   9.92346512,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  89.09483645],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          9.92346512,   0.        ,   9.77172384,   0.        ,\n",
      "          0.        ,   0.        ,  86.80566083],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   9.77172384,   0.        ,  10.16870053,\n",
      "          0.        ,   0.        ,  86.54990281],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  10.16870053,   0.        ,\n",
      "          9.18678203,   0.        , 119.58805212],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   9.18678203,\n",
      "          0.        ,  11.135163  ,  83.69352674],\n",
      "       [  9.998233  ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         11.135163  ,   0.        , 117.90994977]]), 'private_cpu': array([1.33775622e+09, 1.49393054e+09, 1.43997791e+09, 1.21062439e+09,\n",
      "       1.76267552e+09, 1.31132161e+09, 1.38049135e+09, 1.44709927e+09,\n",
      "       1.42518832e+09, 1.49771021e+09, 1.22897323e+09, 1.55137334e+09,\n",
      "       1.68413918e+09, 1.34491629e+09, 1.32974180e+09, 1.25644994e+09,\n",
      "       1.39636453e+09, 1.24796862e+09]), 'public_cpu': array([6.34923798e+08, 8.09092790e+08, 7.02435778e+08, 7.93630196e+08,\n",
      "       8.95631390e+08, 8.85066767e+08, 8.47527275e+08, 6.08503977e+08,\n",
      "       8.50440640e+08, 5.84627600e+08, 7.79588586e+08, 6.35569109e+08,\n",
      "       8.83065611e+08, 6.63393658e+08, 8.79030498e+08, 6.69585169e+08,\n",
      "       6.25279054e+08, 6.38664453e+08]), 'cloud_cpu': 30000000000.0, 'N_agents': 18, 'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), 'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
      "0    light           0    1.0     3600    1.0        18   143, 'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
      "0          0  9.214683e+08  5152.146294  0.021214       0\n",
      "1          1  1.988512e+09  4208.470915  0.030254       1\n",
      "2          2  1.361339e+09  4466.022492  0.028701       2\n",
      "3          3  2.155303e+09  7570.283244  0.038873       3\n",
      "4          4  8.727403e+08  6918.455560  0.037506       4\n",
      "5          5  2.350478e+09  7997.219317  0.013920       5\n",
      "6          6  1.080474e+09  3611.664818  0.031591       6\n",
      "7          7  1.483437e+09  5690.301814  0.026184       7\n",
      "8          8  1.782616e+09  5312.418573  0.040268       8\n",
      "9          9  2.164538e+09  6264.107462  0.048391       9\n",
      "10        10  2.381892e+09  5233.485875  0.039955      10\n",
      "11        11  1.698112e+09  5619.134661  0.037599      11\n",
      "12        12  1.170523e+09  5302.008006  0.034852      12\n",
      "13        13  1.004000e+09  6356.746540  0.027640      13\n",
      "14        14  1.206141e+09  4332.462100  0.038611      14\n",
      "15        15  2.062918e+09  5181.575792  0.042660      15\n",
      "16        16  1.493700e+09  6776.846182  0.026377      16\n",
      "17        17  1.302068e+09  6167.829828  0.025928      17, 'arrivals':      scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
      "0       light           0       0     0.0         1        0\n",
      "1       light           0       0     0.0        17        1\n",
      "2       light           0       7     7.0        17        2\n",
      "3       light           0       9     9.0         3        3\n",
      "4       light           0      13    13.0        15        4\n",
      "...       ...         ...     ...     ...       ...      ...\n",
      "2108    light           0    3594  3594.0        14     2108\n",
      "2109    light           0    3597  3597.0        11     2109\n",
      "2110    light           0    3597  3597.0        16     2110\n",
      "2111    light           0    3598  3598.0        14     2111\n",
      "2112    light           0    3599  3599.0        17     2112\n",
      "\n",
      "[2113 rows x 6 columns], 'tasks':      scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
      "0       light           0        0         1               0             0.0   \n",
      "1       light           0        1        17               0             0.0   \n",
      "2       light           0        2        17               7             7.0   \n",
      "3       light           0        3         3               9             9.0   \n",
      "4       light           0        4        15              13            13.0   \n",
      "...       ...         ...      ...       ...             ...             ...   \n",
      "2108    light           0     2108        14            3594          3594.0   \n",
      "2109    light           0     2109        11            3597          3597.0   \n",
      "2110    light           0     2110        16            3597          3597.0   \n",
      "2111    light           0     2111        14            3598          3598.0   \n",
      "2112    light           0     2112        17            3599          3599.0   \n",
      "\n",
      "          b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
      "0     2.484967    5.525261e+08  1.373009e+09   62.412148    video   \n",
      "1     2.509962    1.082130e+09  2.716106e+09   74.606000     text   \n",
      "2     1.509317    1.757732e+09  2.652974e+09   30.173971     text   \n",
      "3     2.114311    4.582521e+08  9.688874e+08   52.914295    image   \n",
      "4     1.707707    6.574788e+08  1.122781e+09   95.441150    image   \n",
      "...        ...             ...           ...         ...      ...   \n",
      "2108  2.306310    1.006178e+09  2.320560e+09   64.688480     text   \n",
      "2109  3.687047    1.297120e+09  4.782541e+09  106.002625   sensor   \n",
      "2110  2.407504    9.582727e+08  2.307045e+09   65.863180    image   \n",
      "2111  1.205960    1.482103e+09  1.787356e+09   65.631966    image   \n",
      "2112  1.339075    4.337156e+08  5.807776e+08   81.440796    video   \n",
      "\n",
      "      has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
      "0                1    1.339893       1.339893           1     0.424900   \n",
      "1                0         NaN            NaN           0     0.000000   \n",
      "2                0         NaN            NaN           1     0.358162   \n",
      "3                0         NaN            NaN           0     0.000000   \n",
      "4                0         NaN            NaN           0     0.000000   \n",
      "...            ...         ...            ...         ...          ...   \n",
      "2108             0         NaN            NaN           0     0.000000   \n",
      "2109             0         NaN            NaN           0     0.000000   \n",
      "2110             0         NaN            NaN           1     0.393362   \n",
      "2111             0         NaN            NaN           0     0.000000   \n",
      "2112             0         NaN            NaN           0     0.000000   \n",
      "\n",
      "     action_space_hint  \n",
      "0           continuous  \n",
      "1             discrete  \n",
      "2           continuous  \n",
      "3             discrete  \n",
      "4             discrete  \n",
      "...                ...  \n",
      "2108          discrete  \n",
      "2109          discrete  \n",
      "2110        continuous  \n",
      "2111          discrete  \n",
      "2112          discrete  \n",
      "\n",
      "[2113 rows x 17 columns], 'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'cloud_cycles': array([0.])}, 'action_space': {'type': 'discrete', 'n': 3, 'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}}, 'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,), 'dtype': 'float'}, 'mec_public_cycles': {'shape': (18,), 'dtype': 'float'}, 'cloud_cycles': {'shape': (1,), 'dtype': 'float'}}, 'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}}, 'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'}, 'public_cpu': {'shape': (18,), 'dtype': 'float'}, 'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}}, 'note': 'Declarative spec; tensor assembly happens in the Env at each step.'}, 'checks': {'delta_match': True, 'message': 'OK'}}, 'moderate': {'Delta': 1.0, 'K': 18, 'topology_type': 'skip_connections', 'connection_matrix': array([[  0.        ,   8.84365721,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   9.998233  , 110.67630067],\n",
      "       [  8.84365721,   0.        ,   9.97505999,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  92.76931356],\n",
      "       [  0.        ,   9.97505999,   0.        ,  11.95310224,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  96.02627731],\n",
      "       [  0.        ,   0.        ,  11.95310224,   0.        ,\n",
      "          9.13794468,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 119.09298037],\n",
      "       [  0.        ,   0.        ,   0.        ,   9.13794468,\n",
      "          0.        ,   8.87531982,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 116.41878804],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          8.87531982,   0.        ,   8.11860408,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 114.89278573],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   8.11860408,   0.        ,  11.80494832,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  84.22860842],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  11.80494832,   0.        ,\n",
      "         11.88844246,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  83.35489123],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,  11.88844246,\n",
      "          0.        ,  10.68030026,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 113.406384  ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         10.68030026,   0.        ,   8.33085549,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 102.93150158],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   8.33085549,   0.        ,   9.0219371 ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        , 117.12846943],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   9.0219371 ,   0.        ,\n",
      "          8.72814871,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  81.9905366 ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   8.72814871,\n",
      "          0.        ,   9.92346512,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  89.09483645],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          9.92346512,   0.        ,   9.77172384,   0.        ,\n",
      "          0.        ,   0.        ,  86.80566083],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   9.77172384,   0.        ,  10.16870053,\n",
      "          0.        ,   0.        ,  86.54990281],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  10.16870053,   0.        ,\n",
      "          9.18678203,   0.        , 119.58805212],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   9.18678203,\n",
      "          0.        ,  11.135163  ,  83.69352674],\n",
      "       [  9.998233  ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         11.135163  ,   0.        , 117.90994977]]), 'private_cpu': array([1.33775622e+09, 1.49393054e+09, 1.43997791e+09, 1.21062439e+09,\n",
      "       1.76267552e+09, 1.31132161e+09, 1.38049135e+09, 1.44709927e+09,\n",
      "       1.42518832e+09, 1.49771021e+09, 1.22897323e+09, 1.55137334e+09,\n",
      "       1.68413918e+09, 1.34491629e+09, 1.32974180e+09, 1.25644994e+09,\n",
      "       1.39636453e+09, 1.24796862e+09]), 'public_cpu': array([6.34923798e+08, 8.09092790e+08, 7.02435778e+08, 7.93630196e+08,\n",
      "       8.95631390e+08, 8.85066767e+08, 8.47527275e+08, 6.08503977e+08,\n",
      "       8.50440640e+08, 5.84627600e+08, 7.79588586e+08, 6.35569109e+08,\n",
      "       8.83065611e+08, 6.63393658e+08, 8.79030498e+08, 6.69585169e+08,\n",
      "       6.25279054e+08, 6.38664453e+08]), 'cloud_cpu': 30000000000.0, 'N_agents': 18, 'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), 'episodes':    scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
      "0  moderate           0    1.0     3600    1.0        18   244, 'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
      "0          0  2.075234e+09  4177.077472  0.083588       0\n",
      "1          1  1.845675e+09  4444.750864  0.117454       1\n",
      "2          2  1.422351e+09  3116.790674  0.190249       2\n",
      "3          3  8.627662e+08  3819.530831  0.180022       3\n",
      "4          4  1.576391e+09  4456.416731  0.124874       4\n",
      "5          5  1.361574e+09  6518.273845  0.093241       5\n",
      "6          6  1.146421e+09  4031.095267  0.197552       6\n",
      "7          7  1.093930e+09  5125.594407  0.160180       7\n",
      "8          8  8.213925e+08  5099.239983  0.089347       8\n",
      "9          9  1.378500e+09  3320.898803  0.115078       9\n",
      "10        10  1.967238e+09  3878.558132  0.066943      10\n",
      "11        11  1.937473e+09  5303.971140  0.051492      11\n",
      "12        12  1.973373e+09  4718.837422  0.187653      12\n",
      "13        13  2.334762e+09  4156.023984  0.171413      13\n",
      "14        14  1.989451e+09  5301.096958  0.169348      14\n",
      "15        15  2.245627e+09  3973.902321  0.114526      15\n",
      "16        16  9.699633e+08  5954.812618  0.109306      16\n",
      "17        17  1.298186e+09  6890.123320  0.106591      17, 'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
      "0     moderate           0       1     1.0         3        0\n",
      "1     moderate           0       1     1.0        12        1\n",
      "2     moderate           0       1     1.0        13        2\n",
      "3     moderate           0       1     1.0        13        3\n",
      "4     moderate           0       3     3.0         5        4\n",
      "...        ...         ...     ...     ...       ...      ...\n",
      "8257  moderate           0    3597  3597.0        13     8257\n",
      "8258  moderate           0    3597  3597.0        13     8258\n",
      "8259  moderate           0    3597  3597.0        14     8259\n",
      "8260  moderate           0    3598  3598.0        13     8260\n",
      "8261  moderate           0    3599  3599.0         6     8261\n",
      "\n",
      "[8262 rows x 6 columns], 'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
      "0     moderate           0        0         3               1             1.0   \n",
      "1     moderate           0        1        12               1             1.0   \n",
      "2     moderate           0        2        13               1             1.0   \n",
      "3     moderate           0        3        13               1             1.0   \n",
      "4     moderate           0        4         5               3             3.0   \n",
      "...        ...         ...      ...       ...             ...             ...   \n",
      "8257  moderate           0     8257        13            3597          3597.0   \n",
      "8258  moderate           0     8258        13            3597          3597.0   \n",
      "8259  moderate           0     8259        14            3597          3597.0   \n",
      "8260  moderate           0     8260        13            3598          3598.0   \n",
      "8261  moderate           0     8261         6            3599          3599.0   \n",
      "\n",
      "          b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
      "0     4.463301    1.368071e+09  6.106115e+09   59.895400    video   \n",
      "1     2.032145    1.310597e+09  2.663323e+09   39.163837     text   \n",
      "2     2.471461    1.423734e+09  3.518704e+09   71.265870    image   \n",
      "3     2.097559    7.160129e+08  1.501879e+09   73.560420     text   \n",
      "4     2.683642    9.887779e+08  2.653526e+09  114.356410    video   \n",
      "...        ...             ...           ...         ...      ...   \n",
      "8257  2.391213    5.808735e+08  1.388992e+09   56.940155    video   \n",
      "8258  2.583749    1.690439e+09  4.367671e+09   67.638040    video   \n",
      "8259  2.405940    1.218846e+09  2.932471e+09   66.223816   sensor   \n",
      "8260  2.014641    9.512537e+08  1.916434e+09   36.491844     text   \n",
      "8261  4.927452    2.140466e+09  1.054704e+10   47.556170    image   \n",
      "\n",
      "      has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
      "0                0         NaN            NaN           0     0.000000   \n",
      "1                0         NaN            NaN           1     0.619935   \n",
      "2                0         NaN            NaN           0     0.000000   \n",
      "3                0         NaN            NaN           1     0.667023   \n",
      "4                1    0.868840       3.868839           0     0.000000   \n",
      "...            ...         ...            ...         ...          ...   \n",
      "8257             0         NaN            NaN           0     0.000000   \n",
      "8258             0         NaN            NaN           0     0.000000   \n",
      "8259             1    1.438337    3598.438200           0     0.000000   \n",
      "8260             0         NaN            NaN           1     0.493939   \n",
      "8261             0         NaN            NaN           0     0.000000   \n",
      "\n",
      "     action_space_hint  \n",
      "0             discrete  \n",
      "1           continuous  \n",
      "2             discrete  \n",
      "3           continuous  \n",
      "4             discrete  \n",
      "...                ...  \n",
      "8257          discrete  \n",
      "8258          discrete  \n",
      "8259          discrete  \n",
      "8260        continuous  \n",
      "8261          discrete  \n",
      "\n",
      "[8262 rows x 17 columns], 'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.]), 'cloud_cycles': array([0.])}, 'action_space': {'type': 'discrete', 'n': 3, 'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}}, 'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,), 'dtype': 'float'}, 'mec_public_cycles': {'shape': (18,), 'dtype': 'float'}, 'cloud_cycles': {'shape': (1,), 'dtype': 'float'}}, 'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}}, 'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'}, 'public_cpu': {'shape': (18,), 'dtype': 'float'}, 'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}}, 'note': 'Declarative spec; tensor assembly happens in the Env at each step.'}, 'checks': {'delta_match': True, 'message': 'OK'}}}}}\n",
      "\n",
      " ===EXAMPLE===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>t_arrival_slot</th>\n",
       "      <th>t_arrival_time</th>\n",
       "      <th>b_mb</th>\n",
       "      <th>rho_cyc_per_mb</th>\n",
       "      <th>c_cycles</th>\n",
       "      <th>mem_mb</th>\n",
       "      <th>modality</th>\n",
       "      <th>has_deadline</th>\n",
       "      <th>deadline_s</th>\n",
       "      <th>deadline_time</th>\n",
       "      <th>non_atomic</th>\n",
       "      <th>split_ratio</th>\n",
       "      <th>action_space_hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.202096</td>\n",
       "      <td>9.727147e+08</td>\n",
       "      <td>7.005585e+09</td>\n",
       "      <td>66.611010</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800726</td>\n",
       "      <td>0.800726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.479984</td>\n",
       "      <td>1.314973e+09</td>\n",
       "      <td>7.206031e+09</td>\n",
       "      <td>77.928800</td>\n",
       "      <td>image</td>\n",
       "      <td>1</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.421977</td>\n",
       "      <td>2.500222e+09</td>\n",
       "      <td>2.105681e+10</td>\n",
       "      <td>72.966446</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323007</td>\n",
       "      <td>0.323007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539704</td>\n",
       "      <td>continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.324986</td>\n",
       "      <td>1.779582e+09</td>\n",
       "      <td>1.125583e+10</td>\n",
       "      <td>56.492900</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481587</td>\n",
       "      <td>0.481587</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.473269</td>\n",
       "      <td>1.087572e+09</td>\n",
       "      <td>1.247800e+10</td>\n",
       "      <td>73.389854</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594564</td>\n",
       "      <td>0.594564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30631</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>30631</td>\n",
       "      <td>5</td>\n",
       "      <td>3599</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>6.238504</td>\n",
       "      <td>1.090296e+09</td>\n",
       "      <td>6.801814e+09</td>\n",
       "      <td>69.218260</td>\n",
       "      <td>video</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525271</td>\n",
       "      <td>3599.525400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605597</td>\n",
       "      <td>continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30632</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>30632</td>\n",
       "      <td>6</td>\n",
       "      <td>3599</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>3.289880</td>\n",
       "      <td>1.599958e+09</td>\n",
       "      <td>5.263669e+09</td>\n",
       "      <td>39.210260</td>\n",
       "      <td>sensor</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30633</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>30633</td>\n",
       "      <td>6</td>\n",
       "      <td>3599</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>6.192005</td>\n",
       "      <td>8.322764e+08</td>\n",
       "      <td>5.153459e+09</td>\n",
       "      <td>73.052900</td>\n",
       "      <td>sensor</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566783</td>\n",
       "      <td>continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30634</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>30634</td>\n",
       "      <td>7</td>\n",
       "      <td>3599</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>3.244716</td>\n",
       "      <td>1.627807e+09</td>\n",
       "      <td>5.281771e+09</td>\n",
       "      <td>103.576775</td>\n",
       "      <td>image</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706580</td>\n",
       "      <td>continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30635</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>30635</td>\n",
       "      <td>7</td>\n",
       "      <td>3599</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>1.736996</td>\n",
       "      <td>2.141823e+09</td>\n",
       "      <td>3.720338e+09</td>\n",
       "      <td>92.836210</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>0.763454</td>\n",
       "      <td>3599.763400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30636 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "0        heavy           0        0         0               0             0.0   \n",
       "1        heavy           0        1         1               0             0.0   \n",
       "2        heavy           0        2         4               0             0.0   \n",
       "3        heavy           0        3         7               0             0.0   \n",
       "4        heavy           0        4        10               0             0.0   \n",
       "...        ...         ...      ...       ...             ...             ...   \n",
       "30631    heavy           0    30631         5            3599          3599.0   \n",
       "30632    heavy           0    30632         6            3599          3599.0   \n",
       "30633    heavy           0    30633         6            3599          3599.0   \n",
       "30634    heavy           0    30634         7            3599          3599.0   \n",
       "30635    heavy           0    30635         7            3599          3599.0   \n",
       "\n",
       "            b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "0       7.202096    9.727147e+08  7.005585e+09   66.611010   sensor   \n",
       "1       5.479984    1.314973e+09  7.206031e+09   77.928800    image   \n",
       "2       8.421977    2.500222e+09  2.105681e+10   72.966446     text   \n",
       "3       6.324986    1.779582e+09  1.125583e+10   56.492900   sensor   \n",
       "4      11.473269    1.087572e+09  1.247800e+10   73.389854   sensor   \n",
       "...          ...             ...           ...         ...      ...   \n",
       "30631   6.238504    1.090296e+09  6.801814e+09   69.218260    video   \n",
       "30632   3.289880    1.599958e+09  5.263669e+09   39.210260   sensor   \n",
       "30633   6.192005    8.322764e+08  5.153459e+09   73.052900   sensor   \n",
       "30634   3.244716    1.627807e+09  5.281771e+09  103.576775    image   \n",
       "30635   1.736996    2.141823e+09  3.720338e+09   92.836210     text   \n",
       "\n",
       "       has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "0                 1    0.800726       0.800726           0     0.000000   \n",
       "1                 1    0.615113       0.615113           0     0.000000   \n",
       "2                 1    0.323007       0.323007           1     0.539704   \n",
       "3                 1    0.481587       0.481587           0     0.000000   \n",
       "4                 1    0.594564       0.594564           0     0.000000   \n",
       "...             ...         ...            ...         ...          ...   \n",
       "30631             1    0.525271    3599.525400           1     0.605597   \n",
       "30632             0         NaN            NaN           0     0.000000   \n",
       "30633             0         NaN            NaN           1     0.566783   \n",
       "30634             0         NaN            NaN           1     0.706580   \n",
       "30635             1    0.763454    3599.763400           0     0.000000   \n",
       "\n",
       "      action_space_hint  \n",
       "0              discrete  \n",
       "1              discrete  \n",
       "2            continuous  \n",
       "3              discrete  \n",
       "4              discrete  \n",
       "...                 ...  \n",
       "30631        continuous  \n",
       "30632          discrete  \n",
       "30633        continuous  \n",
       "30634        continuous  \n",
       "30635          discrete  \n",
       "\n",
       "[30636 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run all sanity checks\n",
    "sanity_check_all(env_configs)\n",
    "\n",
    "print(\"env_configs: \\n\", env_configs)\n",
    "\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "display(env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] env_configs summary → ./artifacts/env_configs_summary.txt\n"
     ]
    }
   ],
   "source": [
    "def _summarize_array(arr, max_items=6):\n",
    "    \"\"\"Return a short, readable summary string for numpy arrays.\"\"\"\n",
    "    try:\n",
    "        arr = np.asarray(arr)\n",
    "        base = f\"ndarray shape={arr.shape}, dtype={arr.dtype}\"\n",
    "        if arr.size == 0:\n",
    "            return base + \" | empty\"\n",
    "        # Show a few values only if it's 1D or small\n",
    "        if arr.ndim == 1 and arr.size <= max_items:\n",
    "            return base + f\" | values={arr.tolist()}\"\n",
    "        # Stats if numeric\n",
    "        if np.issubdtype(arr.dtype, np.number):\n",
    "            return base + f\" | min={np.nanmin(arr):.4g}, max={np.nanmax(arr):.4g}, mean={np.nanmean(arr):.4g}\"\n",
    "        return base\n",
    "    except Exception as e:\n",
    "        return f\"(array summary failed: {e})\"\n",
    "\n",
    "def _summarize_df(df: pd.DataFrame, max_cols=10):\n",
    "    \"\"\"Return a short summary string for DataFrames.\"\"\"\n",
    "    try:\n",
    "        cols = df.columns.tolist()\n",
    "        cols_show = cols[:max_cols] + ([\"...\"] if len(cols) > max_cols else [])\n",
    "        return f\"DataFrame shape={df.shape}, columns={cols_show}\"\n",
    "    except Exception as e:\n",
    "        return f\"(dataframe summary failed: {e})\"\n",
    "\n",
    "def _summarize_any(name, obj, indent=\"    \"):\n",
    "    \"\"\"Create a few readable lines summarizing an object by type.\"\"\"\n",
    "    lines = []\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        lines.append(f\"{indent}{name}: {_summarize_df(obj)}\")\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        lines.append(f\"{indent}{name}: {_summarize_array(obj)}\")\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        preview = obj[:6] if len(obj) > 6 else obj\n",
    "        lines.append(f\"{indent}{name}: list len={len(obj)}, preview={preview}\")\n",
    "    elif isinstance(obj, dict):\n",
    "        lines.append(f\"{indent}{name}: dict keys={list(obj.keys())}\")\n",
    "        # If it's the queues dict or small dict, briefly dive one level\n",
    "        if name == \"queues_initial\" or len(obj) <= 6:\n",
    "            for k, v in obj.items():\n",
    "                sub = _summarize_any(k, v, indent=indent + \"  \")\n",
    "                lines.extend(sub if isinstance(sub, list) else [sub])\n",
    "    elif isinstance(obj, (int, float, str, bool, type(None))):\n",
    "        lines.append(f\"{indent}{name}: {repr(obj)}\")\n",
    "    else:\n",
    "        # Try numpy conversion\n",
    "        try:\n",
    "            arr = np.asarray(obj)\n",
    "            lines.append(f\"{indent}{name}: {_summarize_array(arr)}\")\n",
    "        except Exception:\n",
    "            lines.append(f\"{indent}{name}: ({type(obj).__name__})\")\n",
    "    return lines\n",
    "\n",
    "def save_env_configs_text(env_configs, out_path=\"./artifacts/env_configs_summary.txt\"):\n",
    "    \"\"\"\n",
    "    Save a human-readable summary of env_configs (episode → topology → scenario) to a text file.\n",
    "    Includes shapes of DataFrames, key columns, array shapes/stats, and key scalar parameters.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    lines = []\n",
    "    lines.append(\"=== ENV CONFIGS SUMMARY (episode → topology → scenario) ===\\n\")\n",
    "\n",
    "    # Iterate deterministic order for reproducibility\n",
    "    for ep_name in sorted(env_configs.keys()):\n",
    "        lines.append(f\"[EPISODE] {ep_name}\")\n",
    "        by_topo = env_configs[ep_name]\n",
    "        for topo_name in sorted(by_topo.keys()):\n",
    "            lines.append(f\"  [TOPOLOGY] {topo_name}\")\n",
    "            by_scen = by_topo[topo_name]\n",
    "            for scen_name in sorted(by_scen.keys()):\n",
    "                env_cfg = by_scen[scen_name]\n",
    "                lines.append(f\"    [SCENARIO] {scen_name}\")\n",
    "\n",
    "                # Highlight most relevant scalars first if present\n",
    "                for key in [\"Delta\", \"K\", \"N_agents\", \"topology_type\"]:\n",
    "                    if key in env_cfg:\n",
    "                        lines.extend(_summarize_any(key, env_cfg[key], indent=\"      \"))\n",
    "\n",
    "                # Then summarize major tensors/arrays\n",
    "                for key in [\"connection_matrix\", \"private_cpu\", \"public_cpu\", \"cloud_cpu\", \"agent_to_mec\"]:\n",
    "                    if key in env_cfg:\n",
    "                        lines.extend(_summarize_any(key, env_cfg[key], indent=\"      \"))\n",
    "\n",
    "                # Then summarize DataFrames (episodes, agents, arrivals, tasks)\n",
    "                for key in [\"episodes\", \"agents\", \"arrivals\", \"tasks\"]:\n",
    "                    if key in env_cfg:\n",
    "                        lines.extend(_summarize_any(key, env_cfg[key], indent=\"      \"))\n",
    "\n",
    "                # Queues + RL descriptors (optional)\n",
    "                for key in [\"queues_initial\", \"action_space\", \"state_spec\", \"checks\"]:\n",
    "                    if key in env_cfg:\n",
    "                        lines.extend(_summarize_any(key, env_cfg[key], indent=\"      \"))\n",
    "\n",
    "                lines.append(\"\")  # blank line between scenarios\n",
    "\n",
    "            lines.append(\"\")  # blank line between topologies\n",
    "        lines.append(\"\")      # blank line between episodes\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(f\"[saved] env_configs summary → {out_path}\")\n",
    "\n",
    "# ---- usage ----\n",
    "save_env_configs_text(env_configs, out_path=\"./artifacts/env_configs_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Step 1, we have loaded the data, aligned the units, assigned agents to MECs, and prepared the environment configuration. Finally, we have performed consistency checks to ensure the data is correct. Next, we can move on to task labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Step 2: Task Labeling </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.1. Basic Task Labeling (buckets, urgency, atomicity, ...) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- helpers: quantile-based cut points ----------\n",
    "def _quantile_cutpoints(s: pd.Series, q_low=0.33, q_high=0.66) -> Tuple[float, float]:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "    if len(s) == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    return (float(s.quantile(q_low)), float(s.quantile(q_high)))\n",
    "\n",
    "def _bucketize(value: float, q1: float, q2: float) -> str:\n",
    "    # Returns 'S', 'M', 'L' based on two cut points (q1<=q2)\n",
    "    if not np.isfinite(value) or not np.isfinite(q1) or not np.isfinite(q2):\n",
    "        return \"U\"  # Unknown\n",
    "    if value <= q1: return \"S\"\n",
    "    if value <= q2: return \"M\"\n",
    "    return \"L\"\n",
    "\n",
    "# ---------- threshold builder (adaptive to each tasks DF) ----------\n",
    "def build_task_label_thresholds(tasks_df: pd.DataFrame,\n",
    "                                q_low=0.33, q_high=0.66,\n",
    "                                urgent_slots_cap: int = 2) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build adaptive thresholds from the data itself (per-episode/senario),\n",
    "    so 'light/moderate/heavy' are handled robustly.\n",
    "    \"\"\"\n",
    "    q_b_mb   = _quantile_cutpoints(tasks_df[\"b_mb\"], q_low, q_high) if \"b_mb\" in tasks_df else (np.nan, np.nan)\n",
    "    q_rho    = _quantile_cutpoints(tasks_df[\"rho_cyc_per_mb\"], q_low, q_high) if \"rho_cyc_per_mb\" in tasks_df else (np.nan, np.nan)\n",
    "    q_mem    = _quantile_cutpoints(tasks_df[\"mem_mb\"], q_low, q_high) if \"mem_mb\" in tasks_df else (np.nan, np.nan)\n",
    "    q_split  = _quantile_cutpoints(tasks_df.loc[tasks_df.get(\"non_atomic\", 0)==1, \"split_ratio\"], q_low, q_high) \\\n",
    "               if \"split_ratio\" in tasks_df else (np.nan, np.nan)\n",
    "\n",
    "    return {\n",
    "        \"b_mb\":   {\"q1\": q_b_mb[0],  \"q2\": q_b_mb[1]},\n",
    "        \"rho\":    {\"q1\": q_rho[0],   \"q2\": q_rho[1]},\n",
    "        \"mem\":    {\"q1\": q_mem[0],   \"q2\": q_mem[1]},\n",
    "        \"split\":  {\"q1\": q_split[0], \"q2\": q_split[1]},\n",
    "        # If deadline_slots ≤ urgent_slots_cap → 'hard' (latency sensitive)\n",
    "        \"urgent_slots_cap\": int(urgent_slots_cap),\n",
    "    }\n",
    "\n",
    "# ---------- main labeling for a single tasks DF ----------\n",
    "def label_tasks_df(tasks_df: pd.DataFrame, Delta: float, thresholds: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add label columns to tasks_df (returns a COPY).\n",
    "    Columns added:\n",
    "      - size_bucket, compute_bucket, mem_bucket\n",
    "      - deadline_slots (if missing), urgency (none/soft/hard)\n",
    "      - atomicity, split_bucket\n",
    "      - latency_sensitive, compute_heavy, io_heavy, memory_heavy (bools)\n",
    "      - routing_hint (LOCAL/MEC/CLOUD)\n",
    "    \"\"\"\n",
    "    df = tasks_df.copy()\n",
    "\n",
    "    # --- ensure numeric types\n",
    "    for col in [\"b_mb\", \"rho_cyc_per_mb\", \"c_cycles\", \"mem_mb\", \"deadline_s\", \"split_ratio\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # --- deadline_slots (if not precomputed in Units Alignment)\n",
    "    if \"deadline_slots\" not in df.columns:\n",
    "        if \"has_deadline\" in df.columns and \"deadline_s\" in df.columns:\n",
    "            df[\"deadline_slots\"] = np.where(\n",
    "                (df[\"has_deadline\"] == 1) & np.isfinite(df[\"deadline_s\"]),\n",
    "                np.ceil(df[\"deadline_s\"] / float(Delta)).astype(\"float\"),\n",
    "                np.nan\n",
    "            )\n",
    "        else:\n",
    "            df[\"deadline_slots\"] = np.nan\n",
    "\n",
    "    # --- bucketize size/compute/memory\n",
    "    b_q1, b_q2   = thresholds[\"b_mb\"][\"q1\"], thresholds[\"b_mb\"][\"q2\"]\n",
    "    rho_q1, rho_q2 = thresholds[\"rho\"][\"q1\"], thresholds[\"rho\"][\"q2\"]\n",
    "    mem_q1, mem_q2 = thresholds[\"mem\"][\"q1\"], thresholds[\"mem\"][\"q2\"]\n",
    "\n",
    "    df[\"size_bucket\"]    = df[\"b_mb\"].apply(lambda x: _bucketize(x, b_q1, b_q2)) if \"b_mb\" in df else \"U\"\n",
    "    df[\"compute_bucket\"] = df[\"rho_cyc_per_mb\"].apply(lambda x: _bucketize(x, rho_q1, rho_q2)) if \"rho_cyc_per_mb\" in df else \"U\"\n",
    "    df[\"mem_bucket\"]     = df[\"mem_mb\"].apply(lambda x: _bucketize(x, mem_q1, mem_q2)) if \"mem_mb\" in df else \"U\"\n",
    "\n",
    "    # --- atomicity & split buckets\n",
    "    if \"non_atomic\" in df.columns:\n",
    "        df[\"atomicity\"] = np.where(df[\"non_atomic\"] == 1, \"splittable\", \"atomic\")\n",
    "    else:\n",
    "        df[\"atomicity\"] = \"atomic\"\n",
    "\n",
    "    if \"split_ratio\" in df.columns:\n",
    "        sp_q1, sp_q2 = thresholds[\"split\"][\"q1\"], thresholds[\"split\"][\"q2\"]\n",
    "        df[\"split_bucket\"] = np.where(\n",
    "            df[\"atomicity\"] == \"splittable\",\n",
    "            df[\"split_ratio\"].apply(lambda v: _bucketize(v, sp_q1, sp_q2)),\n",
    "            \"NA\"\n",
    "        )\n",
    "    else:\n",
    "        df[\"split_bucket\"] = \"NA\"\n",
    "\n",
    "    # --- urgency levels\n",
    "    urgent_cap = int(thresholds.get(\"urgent_slots_cap\", 2))\n",
    "    def _urg(row):\n",
    "        if int(row.get(\"has_deadline\", 0)) != 1 or not np.isfinite(row.get(\"deadline_slots\", np.nan)):\n",
    "            return \"none\"\n",
    "        slots = int(row[\"deadline_slots\"])\n",
    "        if slots <= urgent_cap:  # very tight deadline\n",
    "            return \"hard\"\n",
    "        return \"soft\"\n",
    "    df[\"urgency\"] = df.apply(_urg, axis=1)\n",
    "\n",
    "    # --- boolean convenience labels\n",
    "    df[\"latency_sensitive\"] = (df[\"urgency\"] == \"hard\")\n",
    "    df[\"compute_heavy\"]     = (df[\"compute_bucket\"] == \"L\")\n",
    "    df[\"io_heavy\"]          = (df[\"size_bucket\"] == \"L\")\n",
    "    df[\"memory_heavy\"]      = (df[\"mem_bucket\"] == \"L\")\n",
    "\n",
    "    # --- a very simple routing hint (only for debugging/EDA; not used by the RL policy)\n",
    "    def _hint(row):\n",
    "        if row[\"compute_heavy\"] or row[\"memory_heavy\"]:\n",
    "            return \"CLOUD\"\n",
    "        if row[\"latency_sensitive\"]:\n",
    "            return \"MEC\"\n",
    "        return \"LOCAL\"\n",
    "    df[\"routing_hint\"] = df.apply(_hint, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- batch apply to env_configs (topology → episode → scenario) ----------\n",
    "def label_all_tasks_in_env_configs(env_configs: Dict[str, Dict[str, Dict[str, Any]]],\n",
    "                                   q_low=0.33, q_high=0.66, urgent_slots_cap=2,\n",
    "                                   verbose=True) -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    For each env_config:\n",
    "      - build thresholds from its own tasks DF\n",
    "      - label tasks\n",
    "      - put labeled DF back into env_config[\"tasks\"]\n",
    "      - return a concise summary per bundle\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "\n",
    "    for topo_name, by_ep in env_configs.items():\n",
    "        summary[topo_name] = {}\n",
    "        for ep_name, by_scen in by_ep.items():\n",
    "            summary[topo_name][ep_name] = {}\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                tasks = env_cfg[\"tasks\"]\n",
    "                Delta = float(env_cfg[\"Delta\"])\n",
    "\n",
    "                # thresholds adaptive to this bundle\n",
    "                th = build_task_label_thresholds(tasks, q_low=q_low, q_high=q_high,\n",
    "                                                 urgent_slots_cap=urgent_slots_cap)\n",
    "                labeled = label_tasks_df(tasks, Delta=Delta, thresholds=th)\n",
    "                env_cfg[\"tasks\"] = labeled  # write back\n",
    "\n",
    "                # tiny summary\n",
    "                cnt = {\n",
    "                    \"n\": len(labeled),\n",
    "                    \"urg_hard\": int((labeled[\"urgency\"] == \"hard\").sum()),\n",
    "                    \"splittable\": int((labeled[\"atomicity\"] == \"splittable\").sum()),\n",
    "                    \"size_L\": int((labeled[\"size_bucket\"] == \"L\").sum()),\n",
    "                    \"compute_L\": int((labeled[\"compute_bucket\"] == \"L\").sum()),\n",
    "                    \"mem_L\": int((labeled[\"mem_bucket\"] == \"L\").sum()),\n",
    "                }\n",
    "                summary[topo_name][ep_name][scen_name] = cnt\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"[label] {topo_name}/{ep_name}/{scen_name} -> \"\n",
    "                          f\"n={cnt['n']}, hard={cnt['urg_hard']}, split={cnt['splittable']}, \"\n",
    "                          f\"sizeL={cnt['size_L']}, compL={cnt['compute_L']}, memL={cnt['mem_L']}\")\n",
    "\n",
    "    return env_configs, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[label] ep_000/clustered/heavy -> n=30636, hard=10673, split=13766, sizeL=10416, compL=10416, memL=10416\n",
      "[label] ep_000/clustered/light -> n=2113, hard=322, split=539, sizeL=719, compL=719, memL=719\n",
      "[label] ep_000/clustered/moderate -> n=8262, hard=2117, split=2890, sizeL=2809, compL=2809, memL=2809\n",
      "[label] ep_000/full_mesh/heavy -> n=30636, hard=10673, split=13766, sizeL=10416, compL=10416, memL=10416\n",
      "[label] ep_000/full_mesh/light -> n=2113, hard=322, split=539, sizeL=719, compL=719, memL=719\n",
      "[label] ep_000/full_mesh/moderate -> n=8262, hard=2117, split=2890, sizeL=2809, compL=2809, memL=2809\n",
      "[label] ep_000/sparse_ring/heavy -> n=30636, hard=10673, split=13766, sizeL=10416, compL=10416, memL=10416\n",
      "[label] ep_000/sparse_ring/light -> n=2113, hard=322, split=539, sizeL=719, compL=719, memL=719\n",
      "[label] ep_000/sparse_ring/moderate -> n=8262, hard=2117, split=2890, sizeL=2809, compL=2809, memL=2809\n",
      "\n",
      " ===EXAMPLE===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>t_arrival_slot</th>\n",
       "      <th>t_arrival_time</th>\n",
       "      <th>b_mb</th>\n",
       "      <th>rho_cyc_per_mb</th>\n",
       "      <th>c_cycles</th>\n",
       "      <th>mem_mb</th>\n",
       "      <th>...</th>\n",
       "      <th>compute_bucket</th>\n",
       "      <th>mem_bucket</th>\n",
       "      <th>atomicity</th>\n",
       "      <th>split_bucket</th>\n",
       "      <th>urgency</th>\n",
       "      <th>latency_sensitive</th>\n",
       "      <th>compute_heavy</th>\n",
       "      <th>io_heavy</th>\n",
       "      <th>memory_heavy</th>\n",
       "      <th>routing_hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.202096</td>\n",
       "      <td>9.727147e+08</td>\n",
       "      <td>7.005585e+09</td>\n",
       "      <td>66.611010</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>atomic</td>\n",
       "      <td>NA</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.479984</td>\n",
       "      <td>1.314973e+09</td>\n",
       "      <td>7.206031e+09</td>\n",
       "      <td>77.928800</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>atomic</td>\n",
       "      <td>NA</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>CLOUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.421977</td>\n",
       "      <td>2.500222e+09</td>\n",
       "      <td>2.105681e+10</td>\n",
       "      <td>72.966446</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>M</td>\n",
       "      <td>splittable</td>\n",
       "      <td>S</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CLOUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.324986</td>\n",
       "      <td>1.779582e+09</td>\n",
       "      <td>1.125583e+10</td>\n",
       "      <td>56.492900</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>atomic</td>\n",
       "      <td>NA</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.473269</td>\n",
       "      <td>1.087572e+09</td>\n",
       "      <td>1.247800e+10</td>\n",
       "      <td>73.389854</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>atomic</td>\n",
       "      <td>NA</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "0    heavy           0        0         0               0             0.0   \n",
       "1    heavy           0        1         1               0             0.0   \n",
       "2    heavy           0        2         4               0             0.0   \n",
       "3    heavy           0        3         7               0             0.0   \n",
       "4    heavy           0        4        10               0             0.0   \n",
       "\n",
       "        b_mb  rho_cyc_per_mb      c_cycles     mem_mb  ... compute_bucket  \\\n",
       "0   7.202096    9.727147e+08  7.005585e+09  66.611010  ...              S   \n",
       "1   5.479984    1.314973e+09  7.206031e+09  77.928800  ...              M   \n",
       "2   8.421977    2.500222e+09  2.105681e+10  72.966446  ...              L   \n",
       "3   6.324986    1.779582e+09  1.125583e+10  56.492900  ...              M   \n",
       "4  11.473269    1.087572e+09  1.247800e+10  73.389854  ...              S   \n",
       "\n",
       "   mem_bucket   atomicity  split_bucket  urgency  latency_sensitive  \\\n",
       "0           M      atomic            NA     hard               True   \n",
       "1           L      atomic            NA     hard               True   \n",
       "2           M  splittable             S     hard               True   \n",
       "3           M      atomic            NA     hard               True   \n",
       "4           M      atomic            NA     hard               True   \n",
       "\n",
       "  compute_heavy  io_heavy memory_heavy routing_hint  \n",
       "0         False      True        False          MEC  \n",
       "1         False     False         True        CLOUD  \n",
       "2          True      True        False        CLOUD  \n",
       "3         False      True        False          MEC  \n",
       "4         False      True        False          MEC  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30636 entries, 0 to 30635\n",
      "Data columns (total 29 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   scenario           30636 non-null  object \n",
      " 1   episode_id         30636 non-null  int64  \n",
      " 2   task_id            30636 non-null  int64  \n",
      " 3   agent_id           30636 non-null  int64  \n",
      " 4   t_arrival_slot     30636 non-null  int64  \n",
      " 5   t_arrival_time     30636 non-null  float64\n",
      " 6   b_mb               30636 non-null  float64\n",
      " 7   rho_cyc_per_mb     30636 non-null  float64\n",
      " 8   c_cycles           30636 non-null  float64\n",
      " 9   mem_mb             30636 non-null  float64\n",
      " 10  modality           30636 non-null  object \n",
      " 11  has_deadline       30636 non-null  int64  \n",
      " 12  deadline_s         10673 non-null  float64\n",
      " 13  deadline_time      10673 non-null  float64\n",
      " 14  non_atomic         30636 non-null  int64  \n",
      " 15  split_ratio        30636 non-null  float64\n",
      " 16  action_space_hint  30636 non-null  object \n",
      " 17  deadline_slots     10673 non-null  float64\n",
      " 18  size_bucket        30636 non-null  object \n",
      " 19  compute_bucket     30636 non-null  object \n",
      " 20  mem_bucket         30636 non-null  object \n",
      " 21  atomicity          30636 non-null  object \n",
      " 22  split_bucket       30636 non-null  object \n",
      " 23  urgency            30636 non-null  object \n",
      " 24  latency_sensitive  30636 non-null  bool   \n",
      " 25  compute_heavy      30636 non-null  bool   \n",
      " 26  io_heavy           30636 non-null  bool   \n",
      " 27  memory_heavy       30636 non-null  bool   \n",
      " 28  routing_hint       30636 non-null  object \n",
      "dtypes: bool(4), float64(9), int64(6), object(10)\n",
      "memory usage: 6.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# env_configs: Produced in Step 6 (structure: episode → topology → scenario)\n",
    "env_configs, label_summary = label_all_tasks_in_env_configs(\n",
    "    env_configs,\n",
    "    q_low=0.33, q_high=0.66, urgent_slots_cap=2,  # tunable thresholds\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Example access:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "labeled_tasks = env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"]\n",
    "display(labeled_tasks.head())\n",
    "print(labeled_tasks.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.2. Task Type Classification </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-req: tasks already labeled by your previous step: \n",
    "#   size_bucket, compute_bucket, mem_bucket, urgency, atomicity, split_bucket, routing_hint, etc.\n",
    "\n",
    "def _derive_task_type_row(row: pd.Series) -> tuple[str, str, str, list, str]:\n",
    "    \"\"\"\n",
    "    Returns (task_type, task_subtype, type_reason, multi_flags, final_flag)\n",
    "    \"\"\"\n",
    "    # Collect boolean flags consistent with your earlier labeling:\n",
    "    urgency        = str(row.get(\"urgency\", \"none\"))         # \"hard\" | \"soft\" | \"none\"\n",
    "    latency_flag   = (urgency == \"hard\") or (urgency == \"soft\")\n",
    "    hard_deadline  = (urgency == \"hard\")\n",
    "\n",
    "    compute_heavy  = bool(row.get(\"compute_heavy\", False))   # compute_bucket == \"L\"\n",
    "    memory_heavy   = bool(row.get(\"memory_heavy\", False))    # mem_bucket == \"L\"\n",
    "    io_heavy       = bool(row.get(\"io_heavy\", False))        # size_bucket == \"L\"\n",
    "    non_atomic     = bool(row.get(\"atomicity\", \"atomic\") == \"splittable\")\n",
    "\n",
    "    # Keep all active signals for audit:\n",
    "    multi_flags = []\n",
    "    if hard_deadline:  multi_flags.append(\"deadline_hard\")\n",
    "    elif latency_flag: multi_flags.append(\"deadline_soft\")\n",
    "    if compute_heavy:  multi_flags.append(\"compute_heavy\")\n",
    "    if memory_heavy:   multi_flags.append(\"memory_heavy\")\n",
    "    if io_heavy:       multi_flags.append(\"io_heavy\")\n",
    "    if non_atomic:     multi_flags.append(\"splittable\")\n",
    "\n",
    "    # --- Priority resolution (Chapter 4) ---\n",
    "    # 1) Hard deadline dominates everything\n",
    "    if hard_deadline:\n",
    "        final_flag = \"deadline_hard\"\n",
    "        return (\"deadline_hard\", \"deadline_hard\", \"hard deadline (tight slots)\", multi_flags, final_flag)\n",
    "\n",
    "    # 2) Latency-sensitive (soft deadlines / delay-sensitive)\n",
    "    if latency_flag:\n",
    "        final_flag = \"latency_sensitive\"\n",
    "        return (\"latency_sensitive\", \"deadline_soft\", \"delay-sensitive (soft deadline)\", multi_flags, final_flag)\n",
    "\n",
    "    # 3) Compute-intensive (c or rho or mem heavy)\n",
    "    if compute_heavy or memory_heavy:\n",
    "        final_flag = \"compute_intensive\"\n",
    "        return (\"compute_intensive\", \"compute_or_memory_heavy\", \"high compute/memory demand\", multi_flags, final_flag)\n",
    "\n",
    "    # 4) Data-intensive (mainly large input size / high IO pressure)\n",
    "    if io_heavy:\n",
    "        final_flag = \"data_intensive\"\n",
    "        return (\"data_intensive\", \"large_input_bandwidth\", \"large data volume / IO heavy\", multi_flags, final_flag)\n",
    "\n",
    "    # 5) Otherwise general\n",
    "    final_flag = \"general\"\n",
    "    return (\"general\", \"general\", \"no dominant constraint\", multi_flags, final_flag)\n",
    "\n",
    "def apply_ch4_task_typing(tasks_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds Chapter-4 level task classes with priority rules into tasks_df (returns a COPY).\n",
    "    Columns added:\n",
    "      - task_type            (5-way class)\n",
    "      - task_subtype         (finer descriptor)\n",
    "      - type_reason          (short textual rationale)\n",
    "      - multi_flags          (list of all active boolean traits)\n",
    "      - final_flag           (single flag representing the task's priority class)\n",
    "    \"\"\"\n",
    "    df = tasks_df.copy()\n",
    "\n",
    "    # Ensure the expected helper columns exist (created in your previous labeling step).\n",
    "    required_cols = [\"urgency\", \"compute_heavy\", \"memory_heavy\", \"io_heavy\", \"atomicity\"]\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"apply_ch4_task_typing: missing label columns: {missing}\")\n",
    "\n",
    "    out_type, out_sub, out_reason, out_flags, out_final_flag = [], [], [], [], []\n",
    "    for _, r in df.iterrows():\n",
    "        t, s, msg, flags, final_flag = _derive_task_type_row(r)\n",
    "        out_type.append(t)\n",
    "        out_sub.append(s)\n",
    "        out_reason.append(msg)\n",
    "        out_flags.append(flags)\n",
    "        out_final_flag.append(final_flag)\n",
    "\n",
    "    df[\"task_type\"]   = out_type\n",
    "    df[\"task_subtype\"]= out_sub\n",
    "    df[\"type_reason\"] = out_reason\n",
    "    df[\"multi_flags\"] = out_flags\n",
    "    df[\"final_flag\"]  = out_final_flag  # Add the final flag to represent the primary category\n",
    "\n",
    "    # For convenience: one-hot view (optional)\n",
    "    df[\"is_general\"]            = (df[\"task_type\"] == \"general\")\n",
    "    df[\"is_deadline_hard\"]      = (df[\"task_type\"] == \"deadline_hard\")\n",
    "    df[\"is_latency_sensitive\"]  = (df[\"task_type\"] == \"latency_sensitive\")\n",
    "    df[\"is_compute_intensive\"]  = (df[\"task_type\"] == \"compute_intensive\")\n",
    "    df[\"is_data_intensive\"]     = (df[\"task_type\"] == \"data_intensive\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def apply_task_typing_in_env_configs(env_configs: Dict[str, Dict[str, Dict[str, Any]]],\n",
    "                                     verbose: bool = True) -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    env_configs structure (as we fixed earlier):\n",
    "      env_configs[ep_name][topology_name][scenario_name][\"tasks\"] -> DataFrame\n",
    "\n",
    "    This function:\n",
    "      - applies Chapter-4 task typing to every tasks DF\n",
    "      - writes back the enriched DataFrame\n",
    "      - prints a short summary if verbose=True\n",
    "    \"\"\"\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                tasks = env_cfg[\"tasks\"]\n",
    "                enriched = apply_ch4_task_typing(tasks)\n",
    "                env_cfg[\"tasks\"] = enriched\n",
    "\n",
    "                if verbose:\n",
    "                    n = len(enriched)\n",
    "                    counts = enriched[\"task_type\"].value_counts().to_dict()\n",
    "                    print(f\"[typing] {ep_name}/{topo_name}/{scen_name}  n={n}  → {counts}\")\n",
    "    return env_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[typing] ep_000/clustered/heavy  n=30636  → {'compute_intensive': 11370, 'deadline_hard': 10673, 'general': 5671, 'data_intensive': 2922}\n",
      "[typing] ep_000/clustered/light  n=2113  → {'compute_intensive': 1009, 'general': 502, 'deadline_hard': 322, 'data_intensive': 280}\n",
      "[typing] ep_000/clustered/moderate  n=8262  → {'compute_intensive': 3395, 'deadline_hard': 2117, 'general': 1829, 'data_intensive': 921}\n",
      "[typing] ep_000/full_mesh/heavy  n=30636  → {'compute_intensive': 11370, 'deadline_hard': 10673, 'general': 5671, 'data_intensive': 2922}\n",
      "[typing] ep_000/full_mesh/light  n=2113  → {'compute_intensive': 1009, 'general': 502, 'deadline_hard': 322, 'data_intensive': 280}\n",
      "[typing] ep_000/full_mesh/moderate  n=8262  → {'compute_intensive': 3395, 'deadline_hard': 2117, 'general': 1829, 'data_intensive': 921}\n",
      "[typing] ep_000/sparse_ring/heavy  n=30636  → {'compute_intensive': 11370, 'deadline_hard': 10673, 'general': 5671, 'data_intensive': 2922}\n",
      "[typing] ep_000/sparse_ring/light  n=2113  → {'compute_intensive': 1009, 'general': 502, 'deadline_hard': 322, 'data_intensive': 280}\n",
      "[typing] ep_000/sparse_ring/moderate  n=8262  → {'compute_intensive': 3395, 'deadline_hard': 2117, 'general': 1829, 'data_intensive': 921}\n",
      "\n",
      " ===EXAMPLE===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_subtype</th>\n",
       "      <th>type_reason</th>\n",
       "      <th>multi_flags</th>\n",
       "      <th>final_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, memory_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy, io_heavy, split...</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id      task_type   task_subtype                  type_reason  \\\n",
       "0        0  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "1        1  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "2        2  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "3        3  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "4        4  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "\n",
       "                                         multi_flags     final_flag  \n",
       "0                          [deadline_hard, io_heavy]  deadline_hard  \n",
       "1                      [deadline_hard, memory_heavy]  deadline_hard  \n",
       "2  [deadline_hard, compute_heavy, io_heavy, split...  deadline_hard  \n",
       "3                          [deadline_hard, io_heavy]  deadline_hard  \n",
       "4                          [deadline_hard, io_heavy]  deadline_hard  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Run typing on your current env_configs (episode → topology → scenario) ----\n",
    "env_configs = apply_task_typing_in_env_configs(env_configs, verbose=True)\n",
    "\n",
    "# Example access:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"][[\"task_id\",\"task_type\",\"task_subtype\",\"type_reason\",\"multi_flags\", \"final_flag\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_subtype</th>\n",
       "      <th>type_reason</th>\n",
       "      <th>multi_flags</th>\n",
       "      <th>final_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, memory_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy, io_heavy, split...</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, splittable]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>general</td>\n",
       "      <td>general</td>\n",
       "      <td>no dominant constraint</td>\n",
       "      <td>[]</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[memory_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>data_intensive</td>\n",
       "      <td>large_input_bandwidth</td>\n",
       "      <td>large data volume / IO heavy</td>\n",
       "      <td>[io_heavy, splittable]</td>\n",
       "      <td>data_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>general</td>\n",
       "      <td>general</td>\n",
       "      <td>no dominant constraint</td>\n",
       "      <td>[]</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, io_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, io_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, memory_heavy, splittable]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, io_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, io_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>general</td>\n",
       "      <td>general</td>\n",
       "      <td>no dominant constraint</td>\n",
       "      <td>[]</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, memory_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>general</td>\n",
       "      <td>general</td>\n",
       "      <td>no dominant constraint</td>\n",
       "      <td>[]</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, memory_heavy, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[memory_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, splittable]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>data_intensive</td>\n",
       "      <td>large_input_bandwidth</td>\n",
       "      <td>large data volume / IO heavy</td>\n",
       "      <td>[io_heavy]</td>\n",
       "      <td>data_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, memory_heavy, io_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[memory_heavy, io_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[memory_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, memory_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>general</td>\n",
       "      <td>general</td>\n",
       "      <td>no dominant constraint</td>\n",
       "      <td>[]</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[memory_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy, splittable]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[memory_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>data_intensive</td>\n",
       "      <td>large_input_bandwidth</td>\n",
       "      <td>large data volume / IO heavy</td>\n",
       "      <td>[io_heavy, splittable]</td>\n",
       "      <td>data_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>general</td>\n",
       "      <td>general</td>\n",
       "      <td>no dominant constraint</td>\n",
       "      <td>[splittable]</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>general</td>\n",
       "      <td>general</td>\n",
       "      <td>no dominant constraint</td>\n",
       "      <td>[]</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard]</td>\n",
       "      <td>deadline_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[memory_heavy]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>data_intensive</td>\n",
       "      <td>large_input_bandwidth</td>\n",
       "      <td>large data volume / IO heavy</td>\n",
       "      <td>[io_heavy]</td>\n",
       "      <td>data_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[compute_heavy, io_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>compute_intensive</td>\n",
       "      <td>compute_or_memory_heavy</td>\n",
       "      <td>high compute/memory demand</td>\n",
       "      <td>[memory_heavy, io_heavy, splittable]</td>\n",
       "      <td>compute_intensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_id          task_type             task_subtype  \\\n",
       "0         0      deadline_hard            deadline_hard   \n",
       "1         1      deadline_hard            deadline_hard   \n",
       "2         2      deadline_hard            deadline_hard   \n",
       "3         3      deadline_hard            deadline_hard   \n",
       "4         4      deadline_hard            deadline_hard   \n",
       "5         5      deadline_hard            deadline_hard   \n",
       "6         6            general                  general   \n",
       "7         7  compute_intensive  compute_or_memory_heavy   \n",
       "8         8      deadline_hard            deadline_hard   \n",
       "9         9      deadline_hard            deadline_hard   \n",
       "10       10  compute_intensive  compute_or_memory_heavy   \n",
       "11       11     data_intensive    large_input_bandwidth   \n",
       "12       12            general                  general   \n",
       "13       13  compute_intensive  compute_or_memory_heavy   \n",
       "14       14  compute_intensive  compute_or_memory_heavy   \n",
       "15       15      deadline_hard            deadline_hard   \n",
       "16       16  compute_intensive  compute_or_memory_heavy   \n",
       "17       17      deadline_hard            deadline_hard   \n",
       "18       18  compute_intensive  compute_or_memory_heavy   \n",
       "19       19            general                  general   \n",
       "20       20  compute_intensive  compute_or_memory_heavy   \n",
       "21       21      deadline_hard            deadline_hard   \n",
       "22       22            general                  general   \n",
       "23       23  compute_intensive  compute_or_memory_heavy   \n",
       "24       24      deadline_hard            deadline_hard   \n",
       "25       25  compute_intensive  compute_or_memory_heavy   \n",
       "26       26      deadline_hard            deadline_hard   \n",
       "27       27  compute_intensive  compute_or_memory_heavy   \n",
       "28       28  compute_intensive  compute_or_memory_heavy   \n",
       "29       29      deadline_hard            deadline_hard   \n",
       "30       30     data_intensive    large_input_bandwidth   \n",
       "31       31  compute_intensive  compute_or_memory_heavy   \n",
       "32       32      deadline_hard            deadline_hard   \n",
       "33       33  compute_intensive  compute_or_memory_heavy   \n",
       "34       34  compute_intensive  compute_or_memory_heavy   \n",
       "35       35  compute_intensive  compute_or_memory_heavy   \n",
       "36       36  compute_intensive  compute_or_memory_heavy   \n",
       "37       37            general                  general   \n",
       "38       38  compute_intensive  compute_or_memory_heavy   \n",
       "39       39      deadline_hard            deadline_hard   \n",
       "40       40  compute_intensive  compute_or_memory_heavy   \n",
       "41       41  compute_intensive  compute_or_memory_heavy   \n",
       "42       42     data_intensive    large_input_bandwidth   \n",
       "43       43            general                  general   \n",
       "44       44            general                  general   \n",
       "45       45      deadline_hard            deadline_hard   \n",
       "46       46  compute_intensive  compute_or_memory_heavy   \n",
       "47       47     data_intensive    large_input_bandwidth   \n",
       "48       48  compute_intensive  compute_or_memory_heavy   \n",
       "49       49  compute_intensive  compute_or_memory_heavy   \n",
       "\n",
       "                     type_reason  \\\n",
       "0    hard deadline (tight slots)   \n",
       "1    hard deadline (tight slots)   \n",
       "2    hard deadline (tight slots)   \n",
       "3    hard deadline (tight slots)   \n",
       "4    hard deadline (tight slots)   \n",
       "5    hard deadline (tight slots)   \n",
       "6         no dominant constraint   \n",
       "7     high compute/memory demand   \n",
       "8    hard deadline (tight slots)   \n",
       "9    hard deadline (tight slots)   \n",
       "10    high compute/memory demand   \n",
       "11  large data volume / IO heavy   \n",
       "12        no dominant constraint   \n",
       "13    high compute/memory demand   \n",
       "14    high compute/memory demand   \n",
       "15   hard deadline (tight slots)   \n",
       "16    high compute/memory demand   \n",
       "17   hard deadline (tight slots)   \n",
       "18    high compute/memory demand   \n",
       "19        no dominant constraint   \n",
       "20    high compute/memory demand   \n",
       "21   hard deadline (tight slots)   \n",
       "22        no dominant constraint   \n",
       "23    high compute/memory demand   \n",
       "24   hard deadline (tight slots)   \n",
       "25    high compute/memory demand   \n",
       "26   hard deadline (tight slots)   \n",
       "27    high compute/memory demand   \n",
       "28    high compute/memory demand   \n",
       "29   hard deadline (tight slots)   \n",
       "30  large data volume / IO heavy   \n",
       "31    high compute/memory demand   \n",
       "32   hard deadline (tight slots)   \n",
       "33    high compute/memory demand   \n",
       "34    high compute/memory demand   \n",
       "35    high compute/memory demand   \n",
       "36    high compute/memory demand   \n",
       "37        no dominant constraint   \n",
       "38    high compute/memory demand   \n",
       "39   hard deadline (tight slots)   \n",
       "40    high compute/memory demand   \n",
       "41    high compute/memory demand   \n",
       "42  large data volume / IO heavy   \n",
       "43        no dominant constraint   \n",
       "44        no dominant constraint   \n",
       "45   hard deadline (tight slots)   \n",
       "46    high compute/memory demand   \n",
       "47  large data volume / IO heavy   \n",
       "48    high compute/memory demand   \n",
       "49    high compute/memory demand   \n",
       "\n",
       "                                          multi_flags         final_flag  \n",
       "0                           [deadline_hard, io_heavy]      deadline_hard  \n",
       "1                       [deadline_hard, memory_heavy]      deadline_hard  \n",
       "2   [deadline_hard, compute_heavy, io_heavy, split...      deadline_hard  \n",
       "3                           [deadline_hard, io_heavy]      deadline_hard  \n",
       "4                           [deadline_hard, io_heavy]      deadline_hard  \n",
       "5                         [deadline_hard, splittable]      deadline_hard  \n",
       "6                                                  []            general  \n",
       "7                          [memory_heavy, splittable]  compute_intensive  \n",
       "8                      [deadline_hard, compute_heavy]      deadline_hard  \n",
       "9                      [deadline_hard, compute_heavy]      deadline_hard  \n",
       "10                                    [compute_heavy]  compute_intensive  \n",
       "11                             [io_heavy, splittable]     data_intensive  \n",
       "12                                                 []            general  \n",
       "13                          [compute_heavy, io_heavy]  compute_intensive  \n",
       "14                          [compute_heavy, io_heavy]  compute_intensive  \n",
       "15          [deadline_hard, memory_heavy, splittable]      deadline_hard  \n",
       "16              [compute_heavy, io_heavy, splittable]  compute_intensive  \n",
       "17           [deadline_hard, compute_heavy, io_heavy]      deadline_hard  \n",
       "18                          [compute_heavy, io_heavy]  compute_intensive  \n",
       "19                                                 []            general  \n",
       "20                      [compute_heavy, memory_heavy]  compute_intensive  \n",
       "21                                    [deadline_hard]      deadline_hard  \n",
       "22                                                 []            general  \n",
       "23                        [compute_heavy, splittable]  compute_intensive  \n",
       "24            [deadline_hard, memory_heavy, io_heavy]      deadline_hard  \n",
       "25                        [compute_heavy, splittable]  compute_intensive  \n",
       "26                     [deadline_hard, compute_heavy]      deadline_hard  \n",
       "27                                    [compute_heavy]  compute_intensive  \n",
       "28                         [memory_heavy, splittable]  compute_intensive  \n",
       "29                        [deadline_hard, splittable]      deadline_hard  \n",
       "30                                         [io_heavy]     data_intensive  \n",
       "31            [compute_heavy, memory_heavy, io_heavy]  compute_intensive  \n",
       "32           [deadline_hard, compute_heavy, io_heavy]      deadline_hard  \n",
       "33                           [memory_heavy, io_heavy]  compute_intensive  \n",
       "34                                     [memory_heavy]  compute_intensive  \n",
       "35                        [compute_heavy, splittable]  compute_intensive  \n",
       "36                      [compute_heavy, memory_heavy]  compute_intensive  \n",
       "37                                                 []            general  \n",
       "38                         [memory_heavy, splittable]  compute_intensive  \n",
       "39         [deadline_hard, compute_heavy, splittable]      deadline_hard  \n",
       "40                         [memory_heavy, splittable]  compute_intensive  \n",
       "41                        [compute_heavy, splittable]  compute_intensive  \n",
       "42                             [io_heavy, splittable]     data_intensive  \n",
       "43                                       [splittable]            general  \n",
       "44                                                 []            general  \n",
       "45                                    [deadline_hard]      deadline_hard  \n",
       "46                                     [memory_heavy]  compute_intensive  \n",
       "47                                         [io_heavy]     data_intensive  \n",
       "48              [compute_heavy, io_heavy, splittable]  compute_intensive  \n",
       "49               [memory_heavy, io_heavy, splittable]  compute_intensive  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"][[\"task_id\",\"task_type\",\"task_subtype\",\"type_reason\",\"multi_flags\", \"final_flag\"]].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "none → Tasks that do not have a specific deadline or time sensitivity </br>\n",
    "hard → Tasks that have a very limited deadline and delay is very important to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urgency\n",
      "none    19963\n",
      "hard    10673\n",
      "Name: count, dtype: int64\n",
      "\n",
      " task_type\n",
      "compute_intensive    11370\n",
      "deadline_hard        10673\n",
      "general               5671\n",
      "data_intensive        2922\n",
      "Name: count, dtype: int64\n",
      "\n",
      "                        b_mb  rho_cyc_per_mb     mem_mb\n",
      "task_type                                             \n",
      "compute_intensive  4.946632    1.933898e+09  80.518150\n",
      "data_intensive     8.263339    1.230034e+09  53.342833\n",
      "deadline_hard      4.971393    1.496501e+09  63.870583\n",
      "general            3.954205    1.223997e+09  53.340660\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>t_arrival_slot</th>\n",
       "      <th>t_arrival_time</th>\n",
       "      <th>b_mb</th>\n",
       "      <th>rho_cyc_per_mb</th>\n",
       "      <th>c_cycles</th>\n",
       "      <th>mem_mb</th>\n",
       "      <th>...</th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_subtype</th>\n",
       "      <th>type_reason</th>\n",
       "      <th>multi_flags</th>\n",
       "      <th>final_flag</th>\n",
       "      <th>is_general</th>\n",
       "      <th>is_deadline_hard</th>\n",
       "      <th>is_latency_sensitive</th>\n",
       "      <th>is_compute_intensive</th>\n",
       "      <th>is_data_intensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.202096</td>\n",
       "      <td>9.727147e+08</td>\n",
       "      <td>7.005585e+09</td>\n",
       "      <td>66.611010</td>\n",
       "      <td>...</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.479984</td>\n",
       "      <td>1.314973e+09</td>\n",
       "      <td>7.206031e+09</td>\n",
       "      <td>77.928800</td>\n",
       "      <td>...</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, memory_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.421977</td>\n",
       "      <td>2.500222e+09</td>\n",
       "      <td>2.105681e+10</td>\n",
       "      <td>72.966446</td>\n",
       "      <td>...</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy, io_heavy, split...</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.324986</td>\n",
       "      <td>1.779582e+09</td>\n",
       "      <td>1.125583e+10</td>\n",
       "      <td>56.492900</td>\n",
       "      <td>...</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.473269</td>\n",
       "      <td>1.087572e+09</td>\n",
       "      <td>1.247800e+10</td>\n",
       "      <td>73.389854</td>\n",
       "      <td>...</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "0    heavy           0        0         0               0             0.0   \n",
       "1    heavy           0        1         1               0             0.0   \n",
       "2    heavy           0        2         4               0             0.0   \n",
       "3    heavy           0        3         7               0             0.0   \n",
       "4    heavy           0        4        10               0             0.0   \n",
       "\n",
       "        b_mb  rho_cyc_per_mb      c_cycles     mem_mb  ...      task_type  \\\n",
       "0   7.202096    9.727147e+08  7.005585e+09  66.611010  ...  deadline_hard   \n",
       "1   5.479984    1.314973e+09  7.206031e+09  77.928800  ...  deadline_hard   \n",
       "2   8.421977    2.500222e+09  2.105681e+10  72.966446  ...  deadline_hard   \n",
       "3   6.324986    1.779582e+09  1.125583e+10  56.492900  ...  deadline_hard   \n",
       "4  11.473269    1.087572e+09  1.247800e+10  73.389854  ...  deadline_hard   \n",
       "\n",
       "    task_subtype                  type_reason  \\\n",
       "0  deadline_hard  hard deadline (tight slots)   \n",
       "1  deadline_hard  hard deadline (tight slots)   \n",
       "2  deadline_hard  hard deadline (tight slots)   \n",
       "3  deadline_hard  hard deadline (tight slots)   \n",
       "4  deadline_hard  hard deadline (tight slots)   \n",
       "\n",
       "                                         multi_flags     final_flag  \\\n",
       "0                          [deadline_hard, io_heavy]  deadline_hard   \n",
       "1                      [deadline_hard, memory_heavy]  deadline_hard   \n",
       "2  [deadline_hard, compute_heavy, io_heavy, split...  deadline_hard   \n",
       "3                          [deadline_hard, io_heavy]  deadline_hard   \n",
       "4                          [deadline_hard, io_heavy]  deadline_hard   \n",
       "\n",
       "   is_general is_deadline_hard  is_latency_sensitive is_compute_intensive  \\\n",
       "0       False             True                 False                False   \n",
       "1       False             True                 False                False   \n",
       "2       False             True                 False                False   \n",
       "3       False             True                 False                False   \n",
       "4       False             True                 False                False   \n",
       "\n",
       "  is_data_intensive  \n",
       "0             False  \n",
       "1             False  \n",
       "2             False  \n",
       "3             False  \n",
       "4             False  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30636 entries, 0 to 30635\n",
      "Data columns (total 39 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   scenario              30636 non-null  object \n",
      " 1   episode_id            30636 non-null  int64  \n",
      " 2   task_id               30636 non-null  int64  \n",
      " 3   agent_id              30636 non-null  int64  \n",
      " 4   t_arrival_slot        30636 non-null  int64  \n",
      " 5   t_arrival_time        30636 non-null  float64\n",
      " 6   b_mb                  30636 non-null  float64\n",
      " 7   rho_cyc_per_mb        30636 non-null  float64\n",
      " 8   c_cycles              30636 non-null  float64\n",
      " 9   mem_mb                30636 non-null  float64\n",
      " 10  modality              30636 non-null  object \n",
      " 11  has_deadline          30636 non-null  int64  \n",
      " 12  deadline_s            10673 non-null  float64\n",
      " 13  deadline_time         10673 non-null  float64\n",
      " 14  non_atomic            30636 non-null  int64  \n",
      " 15  split_ratio           30636 non-null  float64\n",
      " 16  action_space_hint     30636 non-null  object \n",
      " 17  deadline_slots        10673 non-null  float64\n",
      " 18  size_bucket           30636 non-null  object \n",
      " 19  compute_bucket        30636 non-null  object \n",
      " 20  mem_bucket            30636 non-null  object \n",
      " 21  atomicity             30636 non-null  object \n",
      " 22  split_bucket          30636 non-null  object \n",
      " 23  urgency               30636 non-null  object \n",
      " 24  latency_sensitive     30636 non-null  bool   \n",
      " 25  compute_heavy         30636 non-null  bool   \n",
      " 26  io_heavy              30636 non-null  bool   \n",
      " 27  memory_heavy          30636 non-null  bool   \n",
      " 28  routing_hint          30636 non-null  object \n",
      " 29  task_type             30636 non-null  object \n",
      " 30  task_subtype          30636 non-null  object \n",
      " 31  type_reason           30636 non-null  object \n",
      " 32  multi_flags           30636 non-null  object \n",
      " 33  final_flag            30636 non-null  object \n",
      " 34  is_general            30636 non-null  bool   \n",
      " 35  is_deadline_hard      30636 non-null  bool   \n",
      " 36  is_latency_sensitive  30636 non-null  bool   \n",
      " 37  is_compute_intensive  30636 non-null  bool   \n",
      " 38  is_data_intensive     30636 non-null  bool   \n",
      "dtypes: bool(9), float64(9), int64(6), object(15)\n",
      "memory usage: 7.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "labeled_tasks_completed = env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"]\n",
    "print(labeled_tasks_completed[\"urgency\"].value_counts())\n",
    "print(\"\\n\", labeled_tasks_completed[\"task_type\"].value_counts())\n",
    "print(\"\\n\", labeled_tasks_completed.groupby(\"task_type\")[[\"b_mb\",\"rho_cyc_per_mb\",\"mem_mb\"]].median())\n",
    "\n",
    "display(labeled_tasks_completed.head())\n",
    "print(labeled_tasks_completed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\heavy\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\heavy\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\heavy\\arrivals_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\heavy\\tasks_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\light\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\light\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\light\\arrivals_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\light\\tasks_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\moderate\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\moderate\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\moderate\\arrivals_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\moderate\\tasks_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\heavy\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\heavy\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\heavy\\arrivals_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\heavy\\tasks_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\light\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\light\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\light\\arrivals_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\light\\tasks_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\moderate\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\moderate\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\moderate\\arrivals_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\moderate\\tasks_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\heavy\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\heavy\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\heavy\\arrivals_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\heavy\\tasks_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\light\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\light\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\light\\arrivals_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\light\\tasks_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\moderate\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\moderate\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\moderate\\arrivals_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\moderate\\tasks_env_config.csv  (rows=8262)\n",
      "Done. Saved 36 dataframes for env_configs (episode, topology, scenario).\n"
     ]
    }
   ],
   "source": [
    "def _ensure_dir(path: str):\n",
    "    \"\"\"Create folder if it doesn't exist.\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def save_all_env_configs(env_configs, out_root: str = \"./artifacts/env_configs\"):\n",
    "    \"\"\"\n",
    "    Walk through env_configs (episode → topology → scenario) and save all data (tasks, agents, etc.) as CSV.\n",
    "    Example output: ./artifacts/env_configs/ep_000/clustered/heavy/env_config.csv\n",
    "    \"\"\"\n",
    "    n_saved = 0\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                out_dir = os.path.join(out_root, ep_name, topo_name, scen_name)\n",
    "                _ensure_dir(out_dir)\n",
    "\n",
    "                # Save tasks, agents, arrivals, and other components\n",
    "                for df_name, df in env_cfg.items():\n",
    "                    if isinstance(df, pd.DataFrame):\n",
    "                        file_path_csv = os.path.join(out_dir, f\"{df_name}_env_config.csv\")\n",
    "                        # file_path_pq = os.path.join(out_dir, f\"{df_name}_env_config.parquet\")\n",
    "\n",
    "                        df.to_csv(file_path_csv, index=False)\n",
    "                        # try:\n",
    "                        #     df.to_parquet(file_path_pq, index=False)  # optional\n",
    "                        # except Exception:\n",
    "                        #     pass\n",
    "\n",
    "                        print(f\"[saved] {file_path_csv}  (rows={len(df)})\")\n",
    "                        n_saved += 1\n",
    "\n",
    "    print(f\"Done. Saved {n_saved} dataframes for env_configs (episode, topology, scenario).\")\n",
    "\n",
    "# Save ALL env_configs\n",
    "save_all_env_configs(env_configs, out_root=\"./artifacts/env_configs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Step 3: Agent Profiling </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we construct a behavioral profile for each agent, capturing its local compute resources, task arrival rate, and the distribution of task types it generates. These profiles are later used for clustering agents and assigning suitable reinforcement learning strategies to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Helper 1: per-agent per-slot arrival counts ----\n",
    "def _per_agent_slot_counts(arrivals_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count how many tasks each agent generates in each time slot.\n",
    "    This is used to estimate lambda (arrival rate) statistics.\n",
    "    \"\"\"\n",
    "    if not {\"agent_id\", \"t_slot\"}.issubset(arrivals_df.columns):\n",
    "        raise ValueError(\"arrivals must contain 'agent_id' and 't_slot'.\")\n",
    "    grp = arrivals_df.groupby([\"agent_id\", \"t_slot\"], as_index=False).size()\n",
    "    grp.rename(columns={\"size\": \"count\"}, inplace=True)\n",
    "    return grp\n",
    "\n",
    "# ---- Helper 2: estimate λ-mean and λ-variance per agent (tight dtypes) ----\n",
    "def _lambda_stats_from_counts(counts_df: pd.DataFrame, Delta: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert per-slot counts to rate statistics:\n",
    "        lambda_mean = mean(count_per_slot) / Delta\n",
    "        lambda_var  = var(count_per_slot)  / Delta^2\n",
    "    \"\"\"\n",
    "    if counts_df.empty:\n",
    "        return pd.DataFrame(columns=[\"agent_id\", \"lambda_mean\", \"lambda_var\", \"slots_observed\"])\n",
    "\n",
    "    agg = counts_df.groupby(\"agent_id\")[\"count\"].agg(\n",
    "        lambda_mean_slot=\"mean\",\n",
    "        lambda_var_slot=\"var\",\n",
    "        slots_observed=\"count\"\n",
    "    ).reset_index()\n",
    "\n",
    "    # If only one observation exists, variance becomes NaN → treat as zero.\n",
    "    agg[\"lambda_var_slot\"] = agg[\"lambda_var_slot\"].fillna(0.0).astype(float)\n",
    "\n",
    "    # Convert to per-second rates\n",
    "    agg[\"lambda_mean\"] = (agg[\"lambda_mean_slot\"] / float(Delta)).astype(float)\n",
    "    agg[\"lambda_var\"]  = (agg[\"lambda_var_slot\"]  / float(Delta**2)).astype(float)\n",
    "\n",
    "    return agg[[\"agent_id\", \"lambda_mean\", \"lambda_var\", \"slots_observed\"]]\n",
    "\n",
    "# ---- Helper 3: task-type distribution per agent (robust + extra stats) ----\n",
    "_TASK_TYPES = [\"general\", \"latency_sensitive\", \"deadline_hard\", \"data_intensive\", \"compute_intensive\"]\n",
    "\n",
    "def _task_distribution_per_agent(tasks_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute distribution of task types per agent (probabilities sum to 1 for agents with tasks).\n",
    "    Also adds light median features useful for clustering: b_mb_med, rho_med, mem_med, hard_share.\n",
    "    \"\"\"\n",
    "    if not {\"agent_id\", \"task_type\"}.issubset(tasks_df.columns):\n",
    "        raise ValueError(\"tasks must contain 'agent_id' and 'task_type'.\")\n",
    "\n",
    "    # Raw counts per (agent_id, task_type)\n",
    "    cnt = tasks_df.groupby([\"agent_id\", \"task_type\"], as_index=False).size()\n",
    "    piv = cnt.pivot(index=\"agent_id\", columns=\"task_type\", values=\"size\").fillna(0.0)\n",
    "\n",
    "    # Ensure all expected classes exist\n",
    "    for t in _TASK_TYPES:\n",
    "        if t not in piv.columns:\n",
    "            piv[t] = 0.0\n",
    "\n",
    "    # True count across all seen labels\n",
    "    piv[\"n_tasks_agent\"] = piv[_TASK_TYPES].sum(axis=1).astype(float)\n",
    "\n",
    "    # Probabilities\n",
    "    for t in _TASK_TYPES:\n",
    "        piv[f\"P_{t}\"] = np.where(piv[\"n_tasks_agent\"] > 0, piv[t] / piv[\"n_tasks_agent\"], 0.0).astype(float)\n",
    "\n",
    "    # Optional extra features for clustering (guard on availability)\n",
    "    feats = {}\n",
    "    have_feats = {\"b_mb\", \"rho_cyc_per_mb\", \"mem_mb\", \"urgency\"}\n",
    "    if have_feats.issubset(tasks_df.columns):\n",
    "        agg = tasks_df.groupby(\"agent_id\").agg(\n",
    "            b_mb_med=(\"b_mb\", \"median\"),\n",
    "            rho_med=(\"rho_cyc_per_mb\", \"median\"),\n",
    "            mem_med=(\"mem_mb\", \"median\"),\n",
    "            hard_share=(\"urgency\", lambda s: float((s == \"hard\").mean()))\n",
    "        ).reset_index()\n",
    "        feats = agg.set_index(\"agent_id\")\n",
    "\n",
    "    # Join extra features (if any)\n",
    "    piv = piv.join(feats, how=\"left\")\n",
    "    for c in [\"b_mb_med\", \"rho_med\", \"mem_med\", \"hard_share\"]:\n",
    "        if c in piv.columns:\n",
    "            piv[c] = piv[c].fillna(0.0).astype(float)\n",
    "        else:\n",
    "            piv[c] = 0.0\n",
    "\n",
    "    # Probability mass sum (diagnostic)\n",
    "    prob_cols = [f\"P_{t}\" for t in _TASK_TYPES]\n",
    "    piv[\"TaskDist_sum\"] = piv[prob_cols].sum(axis=1).astype(float)\n",
    "\n",
    "    keep = [\"n_tasks_agent\", \"TaskDist_sum\", \"b_mb_med\", \"rho_med\", \"mem_med\", \"hard_share\"] + prob_cols\n",
    "    return piv[keep].reset_index()\n",
    "\n",
    "# ---- Helper 4: fraction of non-atomic (splittable) tasks ----\n",
    "def _non_atomic_share_per_agent(tasks_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the share of splittable (non-atomic) tasks per agent.\n",
    "    \"\"\"\n",
    "    if not {\"agent_id\", \"non_atomic\"}.issubset(tasks_df.columns):\n",
    "        # If missing, assume zero for all agents that exist in tasks\n",
    "        agents = tasks_df.get(\"agent_id\")\n",
    "        if agents is None or len(agents) == 0:\n",
    "            return pd.DataFrame(columns=[\"agent_id\", \"non_atomic_share\"])\n",
    "        return pd.DataFrame({\"agent_id\": agents.unique(), \"non_atomic_share\": 0.0})\n",
    "\n",
    "    grp = tasks_df.groupby(\"agent_id\")[\"non_atomic\"].agg(\n",
    "        non_atomic_share=lambda s: float((s == 1).mean())\n",
    "    ).reset_index()\n",
    "    return grp\n",
    "\n",
    "# ---- Build agent profiles for ONE env_config ----\n",
    "def build_agent_profiles_for_env(env_cfg: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construct per-agent profiles combining:\n",
    "      - Local resource capacity (f_local, m_local, f_local_slot)\n",
    "      - Arrival rate statistics (lambda_mean, lambda_var)\n",
    "      - Task type distribution (P_general, P_latency_sensitive, P_deadline_hard, P_data_intensive, P_compute_intensive)\n",
    "      - Splittability share (non_atomic_share)\n",
    "      - MEC mapping if available (mec_id)\n",
    "    \"\"\"\n",
    "    agents   = env_cfg[\"agents\"].copy()\n",
    "    arrivals = env_cfg[\"arrivals\"]\n",
    "    tasks    = env_cfg[\"tasks\"]\n",
    "    Delta    = float(env_cfg[\"Delta\"])\n",
    "\n",
    "    # Ensure cycles/slot exists\n",
    "    if \"f_local_slot\" not in agents.columns and \"f_local\" in agents.columns:\n",
    "        agents[\"f_local_slot\"] = agents[\"f_local\"].astype(float) * Delta\n",
    "\n",
    "    # 1) Arrival statistics\n",
    "    counts_df = _per_agent_slot_counts(arrivals)\n",
    "    lam_df    = _lambda_stats_from_counts(counts_df, Delta=Delta)\n",
    "\n",
    "    # 2) Task-type distribution (+ medians & hard_share)\n",
    "    dist_df   = _task_distribution_per_agent(tasks)\n",
    "\n",
    "    # 3) Splittable-task share\n",
    "    na_df     = _non_atomic_share_per_agent(tasks)\n",
    "\n",
    "    # 4) Agent→MEC mapping (optional)\n",
    "    mec_map = None\n",
    "    if \"agent_to_mec\" in env_cfg:\n",
    "        a2m = env_cfg[\"agent_to_mec\"]\n",
    "        if isinstance(a2m, pd.Series):\n",
    "            mec_map = a2m.rename(\"mec_id\").reset_index()\n",
    "            # if the index column name is lost, normalize it\n",
    "            if mec_map.columns.tolist() == [\"index\", \"mec_id\"]:\n",
    "                mec_map.rename(columns={\"index\": \"agent_id\"}, inplace=True)\n",
    "        else:\n",
    "            mec_map = pd.DataFrame({\n",
    "                \"agent_id\": np.arange(len(a2m), dtype=int),\n",
    "                \"mec_id\": np.asarray(a2m, dtype=int)\n",
    "            })\n",
    "\n",
    "    # Merge all components\n",
    "    base = agents[[\"agent_id\", \"f_local\", \"f_local_slot\", \"m_local\"]].copy()\n",
    "    base[[\"f_local\", \"f_local_slot\", \"m_local\"]] = base[[\"f_local\", \"f_local_slot\", \"m_local\"]].astype(float)\n",
    "\n",
    "    prof = (base\n",
    "            .merge(lam_df,  on=\"agent_id\", how=\"left\")\n",
    "            .merge(dist_df, on=\"agent_id\", how=\"left\")\n",
    "            .merge(na_df,   on=\"agent_id\", how=\"left\"))\n",
    "\n",
    "    if mec_map is not None:\n",
    "        prof = prof.merge(mec_map, on=\"agent_id\", how=\"left\")\n",
    "\n",
    "    # Fill missing for agents with no arrivals/tasks\n",
    "    fill_zero = [\n",
    "        \"lambda_mean\", \"lambda_var\", \"slots_observed\",\n",
    "        \"n_tasks_agent\", \"non_atomic_share\",\n",
    "        \"TaskDist_sum\", \"b_mb_med\", \"rho_med\", \"mem_med\", \"hard_share\"\n",
    "    ] + [f\"P_{t}\" for t in _TASK_TYPES]\n",
    "    for c in fill_zero:\n",
    "        if c in prof.columns:\n",
    "            prof[c] = prof[c].fillna(0.0).astype(float)\n",
    "\n",
    "    # Soft warning if probabilities don't sum to ~1 for agents with tasks\n",
    "    if \"n_tasks_agent\" in prof.columns and \"TaskDist_sum\" in prof.columns:\n",
    "        mask = (prof[\"n_tasks_agent\"] > 0) & (~np.isclose(prof[\"TaskDist_sum\"], 1.0, atol=1e-6))\n",
    "        if mask.any():\n",
    "            n_bad = int(mask.sum())\n",
    "            print(f\"[warn] TaskDist_sum != 1.0 for {n_bad} agent(s). (tolerance 1e-6)\")\n",
    "\n",
    "    return prof\n",
    "\n",
    "# ---- Batch profiling for ALL env_configs ----\n",
    "def build_all_agent_profiles(env_configs: Dict[str, Dict[str, Dict[str, Any]]]):\n",
    "    \"\"\"\n",
    "    Compute profiles for every (episode → topology → scenario) environment.\n",
    "    Stores result both in return dict AND env_configs[...] for convenience.\n",
    "    Output:\n",
    "      profiles[ep_name][topology_name][scen_name] = DataFrame\n",
    "    Also writes back to: env_configs[ep_name][topology_name][scen_name][\"agent_profiles\"]\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        out[ep_name] = {}\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            out[ep_name][topo_name] = {}\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                prof = build_agent_profiles_for_env(env_cfg)\n",
    "                out[ep_name][topo_name][scen_name] = prof\n",
    "                env_cfg[\"agent_profiles\"] = prof  # attach for direct access\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===EXAMPLE===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>f_local</th>\n",
       "      <th>f_local_slot</th>\n",
       "      <th>m_local</th>\n",
       "      <th>lambda_mean</th>\n",
       "      <th>lambda_var</th>\n",
       "      <th>slots_observed</th>\n",
       "      <th>n_tasks_agent</th>\n",
       "      <th>TaskDist_sum</th>\n",
       "      <th>b_mb_med</th>\n",
       "      <th>rho_med</th>\n",
       "      <th>mem_med</th>\n",
       "      <th>hard_share</th>\n",
       "      <th>P_general</th>\n",
       "      <th>P_latency_sensitive</th>\n",
       "      <th>P_deadline_hard</th>\n",
       "      <th>P_data_intensive</th>\n",
       "      <th>P_compute_intensive</th>\n",
       "      <th>non_atomic_share</th>\n",
       "      <th>mec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>1.400325</td>\n",
       "      <td>0.474341</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.975150</td>\n",
       "      <td>1.496395e+09</td>\n",
       "      <td>64.062160</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.182592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.379884</td>\n",
       "      <td>0.467311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>1.125348</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>718.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.903463</td>\n",
       "      <td>1.542846e+09</td>\n",
       "      <td>64.020492</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.169554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.092822</td>\n",
       "      <td>0.383663</td>\n",
       "      <td>0.433168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>1.134063</td>\n",
       "      <td>0.138167</td>\n",
       "      <td>731.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.910049</td>\n",
       "      <td>1.540341e+09</td>\n",
       "      <td>66.006420</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.184560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.086852</td>\n",
       "      <td>0.394451</td>\n",
       "      <td>0.434258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>1.139918</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>972.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.067142</td>\n",
       "      <td>1.470254e+09</td>\n",
       "      <td>64.517043</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.182310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.359206</td>\n",
       "      <td>0.435921</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>1.277666</td>\n",
       "      <td>0.287951</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.031714</td>\n",
       "      <td>1.515057e+09</td>\n",
       "      <td>64.294464</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.095538</td>\n",
       "      <td>0.374278</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id       f_local  f_local_slot      m_local  lambda_mean  lambda_var  \\\n",
       "0         0  1.741183e+09  1.741183e+09  5713.849721     1.400325    0.474341   \n",
       "1         1  1.352326e+09  1.352326e+09  4566.428755     1.125348    0.140472   \n",
       "2         2  1.726668e+09  1.726668e+09  5815.120004     1.134063    0.138167   \n",
       "3         3  1.543616e+09  1.543616e+09  3539.850245     1.139918    0.147241   \n",
       "4         4  1.130883e+09  1.130883e+09  4161.367769     1.277666    0.287951   \n",
       "\n",
       "   slots_observed  n_tasks_agent  TaskDist_sum  b_mb_med       rho_med  \\\n",
       "0          1846.0         2585.0           1.0  4.975150  1.496395e+09   \n",
       "1           718.0          808.0           1.0  4.903463  1.542846e+09   \n",
       "2           731.0          829.0           1.0  4.910049  1.540341e+09   \n",
       "3           972.0         1108.0           1.0  5.067142  1.470254e+09   \n",
       "4          1491.0         1905.0           1.0  5.031714  1.515057e+09   \n",
       "\n",
       "     mem_med  hard_share  P_general  P_latency_sensitive  P_deadline_hard  \\\n",
       "0  64.062160    0.343907   0.182592                  0.0         0.343907   \n",
       "1  64.020492    0.353960   0.169554                  0.0         0.353960   \n",
       "2  66.006420    0.334138   0.184560                  0.0         0.334138   \n",
       "3  64.517043    0.371841   0.182310                  0.0         0.371841   \n",
       "4  64.294464    0.344882   0.185302                  0.0         0.344882   \n",
       "\n",
       "   P_data_intensive  P_compute_intensive  non_atomic_share  mec_id  \n",
       "0          0.093617             0.379884          0.467311       0  \n",
       "1          0.092822             0.383663          0.433168       1  \n",
       "2          0.086852             0.394451          0.434258       2  \n",
       "3          0.086643             0.359206          0.435921       3  \n",
       "4          0.095538             0.374278          0.440945       4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>f_local</th>\n",
       "      <th>f_local_slot</th>\n",
       "      <th>m_local</th>\n",
       "      <th>lambda_mean</th>\n",
       "      <th>lambda_var</th>\n",
       "      <th>slots_observed</th>\n",
       "      <th>n_tasks_agent</th>\n",
       "      <th>TaskDist_sum</th>\n",
       "      <th>b_mb_med</th>\n",
       "      <th>rho_med</th>\n",
       "      <th>mem_med</th>\n",
       "      <th>hard_share</th>\n",
       "      <th>P_general</th>\n",
       "      <th>P_latency_sensitive</th>\n",
       "      <th>P_deadline_hard</th>\n",
       "      <th>P_data_intensive</th>\n",
       "      <th>P_compute_intensive</th>\n",
       "      <th>non_atomic_share</th>\n",
       "      <th>mec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>1.400325</td>\n",
       "      <td>0.474341</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.975150</td>\n",
       "      <td>1.496395e+09</td>\n",
       "      <td>64.062160</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.182592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.379884</td>\n",
       "      <td>0.467311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>1.125348</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>718.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.903463</td>\n",
       "      <td>1.542846e+09</td>\n",
       "      <td>64.020492</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.169554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.092822</td>\n",
       "      <td>0.383663</td>\n",
       "      <td>0.433168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>1.134063</td>\n",
       "      <td>0.138167</td>\n",
       "      <td>731.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.910049</td>\n",
       "      <td>1.540341e+09</td>\n",
       "      <td>66.006420</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.184560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.086852</td>\n",
       "      <td>0.394451</td>\n",
       "      <td>0.434258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>1.139918</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>972.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.067142</td>\n",
       "      <td>1.470254e+09</td>\n",
       "      <td>64.517043</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.182310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.359206</td>\n",
       "      <td>0.435921</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>1.277666</td>\n",
       "      <td>0.287951</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.031714</td>\n",
       "      <td>1.515057e+09</td>\n",
       "      <td>64.294464</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.095538</td>\n",
       "      <td>0.374278</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id       f_local  f_local_slot      m_local  lambda_mean  lambda_var  \\\n",
       "0         0  1.741183e+09  1.741183e+09  5713.849721     1.400325    0.474341   \n",
       "1         1  1.352326e+09  1.352326e+09  4566.428755     1.125348    0.140472   \n",
       "2         2  1.726668e+09  1.726668e+09  5815.120004     1.134063    0.138167   \n",
       "3         3  1.543616e+09  1.543616e+09  3539.850245     1.139918    0.147241   \n",
       "4         4  1.130883e+09  1.130883e+09  4161.367769     1.277666    0.287951   \n",
       "\n",
       "   slots_observed  n_tasks_agent  TaskDist_sum  b_mb_med       rho_med  \\\n",
       "0          1846.0         2585.0           1.0  4.975150  1.496395e+09   \n",
       "1           718.0          808.0           1.0  4.903463  1.542846e+09   \n",
       "2           731.0          829.0           1.0  4.910049  1.540341e+09   \n",
       "3           972.0         1108.0           1.0  5.067142  1.470254e+09   \n",
       "4          1491.0         1905.0           1.0  5.031714  1.515057e+09   \n",
       "\n",
       "     mem_med  hard_share  P_general  P_latency_sensitive  P_deadline_hard  \\\n",
       "0  64.062160    0.343907   0.182592                  0.0         0.343907   \n",
       "1  64.020492    0.353960   0.169554                  0.0         0.353960   \n",
       "2  66.006420    0.334138   0.184560                  0.0         0.334138   \n",
       "3  64.517043    0.371841   0.182310                  0.0         0.371841   \n",
       "4  64.294464    0.344882   0.185302                  0.0         0.344882   \n",
       "\n",
       "   P_data_intensive  P_compute_intensive  non_atomic_share  mec_id  \n",
       "0          0.093617             0.379884          0.467311       0  \n",
       "1          0.092822             0.383663          0.433168       1  \n",
       "2          0.086852             0.394451          0.434258       2  \n",
       "3          0.086643             0.359206          0.435921       3  \n",
       "4          0.095538             0.374278          0.440945       4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Build + quick peek (optional) ----\n",
    "agent_profiles = build_all_agent_profiles(env_configs)\n",
    "\n",
    "# Example: Access the profile table for a specific episode / topology / scenario\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "display(agent_profiles[\"ep_000\"][\"clustered\"][\"heavy\"].head())\n",
    "\n",
    "# Alternatively, read directly from env_configs:\n",
    "display(env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"agent_profiles\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>f_local</th>\n",
       "      <th>f_local_slot</th>\n",
       "      <th>m_local</th>\n",
       "      <th>lambda_mean</th>\n",
       "      <th>lambda_var</th>\n",
       "      <th>slots_observed</th>\n",
       "      <th>n_tasks_agent</th>\n",
       "      <th>TaskDist_sum</th>\n",
       "      <th>b_mb_med</th>\n",
       "      <th>rho_med</th>\n",
       "      <th>mem_med</th>\n",
       "      <th>hard_share</th>\n",
       "      <th>P_general</th>\n",
       "      <th>P_latency_sensitive</th>\n",
       "      <th>P_deadline_hard</th>\n",
       "      <th>P_data_intensive</th>\n",
       "      <th>P_compute_intensive</th>\n",
       "      <th>non_atomic_share</th>\n",
       "      <th>mec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>1.400325</td>\n",
       "      <td>0.474341</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.975150</td>\n",
       "      <td>1.496395e+09</td>\n",
       "      <td>64.062160</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.182592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.379884</td>\n",
       "      <td>0.467311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>1.125348</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>718.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.903463</td>\n",
       "      <td>1.542846e+09</td>\n",
       "      <td>64.020492</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.169554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.092822</td>\n",
       "      <td>0.383663</td>\n",
       "      <td>0.433168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>1.134063</td>\n",
       "      <td>0.138167</td>\n",
       "      <td>731.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.910049</td>\n",
       "      <td>1.540341e+09</td>\n",
       "      <td>66.006420</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.184560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.086852</td>\n",
       "      <td>0.394451</td>\n",
       "      <td>0.434258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>1.139918</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>972.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.067142</td>\n",
       "      <td>1.470254e+09</td>\n",
       "      <td>64.517043</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.182310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.359206</td>\n",
       "      <td>0.435921</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>1.277666</td>\n",
       "      <td>0.287951</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.031714</td>\n",
       "      <td>1.515057e+09</td>\n",
       "      <td>64.294464</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.095538</td>\n",
       "      <td>0.374278</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.761336e+09</td>\n",
       "      <td>1.761336e+09</td>\n",
       "      <td>7349.509397</td>\n",
       "      <td>1.214230</td>\n",
       "      <td>0.223240</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.954894</td>\n",
       "      <td>1.493983e+09</td>\n",
       "      <td>63.261272</td>\n",
       "      <td>0.333548</td>\n",
       "      <td>0.180296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333548</td>\n",
       "      <td>0.108822</td>\n",
       "      <td>0.377334</td>\n",
       "      <td>0.430779</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.093196e+09</td>\n",
       "      <td>1.093196e+09</td>\n",
       "      <td>6389.821853</td>\n",
       "      <td>1.410705</td>\n",
       "      <td>0.451062</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>2662.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.970322</td>\n",
       "      <td>1.509935e+09</td>\n",
       "      <td>64.400655</td>\n",
       "      <td>0.353494</td>\n",
       "      <td>0.187829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353494</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.367769</td>\n",
       "      <td>0.447032</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.022066e+09</td>\n",
       "      <td>1.022066e+09</td>\n",
       "      <td>5354.805771</td>\n",
       "      <td>1.251793</td>\n",
       "      <td>0.266059</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.874941</td>\n",
       "      <td>1.516990e+09</td>\n",
       "      <td>63.494762</td>\n",
       "      <td>0.348424</td>\n",
       "      <td>0.182808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348424</td>\n",
       "      <td>0.096275</td>\n",
       "      <td>0.372493</td>\n",
       "      <td>0.429799</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.280853e+09</td>\n",
       "      <td>1.280853e+09</td>\n",
       "      <td>3931.170813</td>\n",
       "      <td>1.346974</td>\n",
       "      <td>0.372042</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.979347</td>\n",
       "      <td>1.471601e+09</td>\n",
       "      <td>63.057762</td>\n",
       "      <td>0.351305</td>\n",
       "      <td>0.182713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351305</td>\n",
       "      <td>0.115105</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.452289</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.260889e+09</td>\n",
       "      <td>1.260889e+09</td>\n",
       "      <td>5133.304392</td>\n",
       "      <td>1.256874</td>\n",
       "      <td>0.291669</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.964419</td>\n",
       "      <td>1.506369e+09</td>\n",
       "      <td>62.987170</td>\n",
       "      <td>0.351250</td>\n",
       "      <td>0.196250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351250</td>\n",
       "      <td>0.091250</td>\n",
       "      <td>0.361250</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>8.077840e+08</td>\n",
       "      <td>8.077840e+08</td>\n",
       "      <td>6774.364061</td>\n",
       "      <td>1.384409</td>\n",
       "      <td>0.435798</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>2575.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.023674</td>\n",
       "      <td>1.492775e+09</td>\n",
       "      <td>64.190340</td>\n",
       "      <td>0.354563</td>\n",
       "      <td>0.182913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354563</td>\n",
       "      <td>0.088932</td>\n",
       "      <td>0.373592</td>\n",
       "      <td>0.445049</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.252718e+09</td>\n",
       "      <td>1.252718e+09</td>\n",
       "      <td>5907.761753</td>\n",
       "      <td>1.129310</td>\n",
       "      <td>0.129991</td>\n",
       "      <td>812.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.092201</td>\n",
       "      <td>1.533240e+09</td>\n",
       "      <td>64.098305</td>\n",
       "      <td>0.348964</td>\n",
       "      <td>0.170120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348964</td>\n",
       "      <td>0.088332</td>\n",
       "      <td>0.392585</td>\n",
       "      <td>0.443839</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.849537e+09</td>\n",
       "      <td>1.849537e+09</td>\n",
       "      <td>4251.816941</td>\n",
       "      <td>1.128293</td>\n",
       "      <td>0.144072</td>\n",
       "      <td>873.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.941554</td>\n",
       "      <td>1.475061e+09</td>\n",
       "      <td>63.059128</td>\n",
       "      <td>0.341117</td>\n",
       "      <td>0.189848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341117</td>\n",
       "      <td>0.096447</td>\n",
       "      <td>0.372589</td>\n",
       "      <td>0.458883</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2.013685e+09</td>\n",
       "      <td>2.013685e+09</td>\n",
       "      <td>3452.486291</td>\n",
       "      <td>1.197917</td>\n",
       "      <td>0.198849</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.024466</td>\n",
       "      <td>1.453782e+09</td>\n",
       "      <td>62.179445</td>\n",
       "      <td>0.339130</td>\n",
       "      <td>0.218116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339130</td>\n",
       "      <td>0.107971</td>\n",
       "      <td>0.334783</td>\n",
       "      <td>0.446377</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1.566043e+09</td>\n",
       "      <td>1.566043e+09</td>\n",
       "      <td>6514.168780</td>\n",
       "      <td>1.222313</td>\n",
       "      <td>0.230080</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.992622</td>\n",
       "      <td>1.487919e+09</td>\n",
       "      <td>63.739220</td>\n",
       "      <td>0.333111</td>\n",
       "      <td>0.190540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333111</td>\n",
       "      <td>0.091272</td>\n",
       "      <td>0.385077</td>\n",
       "      <td>0.457695</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.573528e+09</td>\n",
       "      <td>1.573528e+09</td>\n",
       "      <td>7018.517023</td>\n",
       "      <td>1.434669</td>\n",
       "      <td>0.481277</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.960894</td>\n",
       "      <td>1.498425e+09</td>\n",
       "      <td>64.496410</td>\n",
       "      <td>0.349782</td>\n",
       "      <td>0.175617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349782</td>\n",
       "      <td>0.096517</td>\n",
       "      <td>0.378084</td>\n",
       "      <td>0.464804</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.386095e+09</td>\n",
       "      <td>1.386095e+09</td>\n",
       "      <td>6122.347442</td>\n",
       "      <td>1.207278</td>\n",
       "      <td>0.218284</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.822063</td>\n",
       "      <td>1.508338e+09</td>\n",
       "      <td>65.064335</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.182176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.081913</td>\n",
       "      <td>0.389908</td>\n",
       "      <td>0.461337</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.604826e+09</td>\n",
       "      <td>1.604826e+09</td>\n",
       "      <td>3449.292167</td>\n",
       "      <td>1.268890</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.923450</td>\n",
       "      <td>1.509358e+09</td>\n",
       "      <td>63.177245</td>\n",
       "      <td>0.361052</td>\n",
       "      <td>0.188305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361052</td>\n",
       "      <td>0.096030</td>\n",
       "      <td>0.354614</td>\n",
       "      <td>0.445279</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agent_id       f_local  f_local_slot      m_local  lambda_mean  \\\n",
       "0          0  1.741183e+09  1.741183e+09  5713.849721     1.400325   \n",
       "1          1  1.352326e+09  1.352326e+09  4566.428755     1.125348   \n",
       "2          2  1.726668e+09  1.726668e+09  5815.120004     1.134063   \n",
       "3          3  1.543616e+09  1.543616e+09  3539.850245     1.139918   \n",
       "4          4  1.130883e+09  1.130883e+09  4161.367769     1.277666   \n",
       "5          5  1.761336e+09  1.761336e+09  7349.509397     1.214230   \n",
       "6          6  1.093196e+09  1.093196e+09  6389.821853     1.410705   \n",
       "7          7  1.022066e+09  1.022066e+09  5354.805771     1.251793   \n",
       "8          8  1.280853e+09  1.280853e+09  3931.170813     1.346974   \n",
       "9          9  1.260889e+09  1.260889e+09  5133.304392     1.256874   \n",
       "10        10  8.077840e+08  8.077840e+08  6774.364061     1.384409   \n",
       "11        11  1.252718e+09  1.252718e+09  5907.761753     1.129310   \n",
       "12        12  1.849537e+09  1.849537e+09  4251.816941     1.128293   \n",
       "13        13  2.013685e+09  2.013685e+09  3452.486291     1.197917   \n",
       "14        14  1.566043e+09  1.566043e+09  6514.168780     1.222313   \n",
       "15        15  1.573528e+09  1.573528e+09  7018.517023     1.434669   \n",
       "16        16  1.386095e+09  1.386095e+09  6122.347442     1.207278   \n",
       "17        17  1.604826e+09  1.604826e+09  3449.292167     1.268890   \n",
       "\n",
       "    lambda_var  slots_observed  n_tasks_agent  TaskDist_sum  b_mb_med  \\\n",
       "0     0.474341          1846.0         2585.0           1.0  4.975150   \n",
       "1     0.140472           718.0          808.0           1.0  4.903463   \n",
       "2     0.138167           731.0          829.0           1.0  4.910049   \n",
       "3     0.147241           972.0         1108.0           1.0  5.067142   \n",
       "4     0.287951          1491.0         1905.0           1.0  5.031714   \n",
       "5     0.223240          1279.0         1553.0           1.0  4.954894   \n",
       "6     0.451062          1887.0         2662.0           1.0  4.970322   \n",
       "7     0.266059          1394.0         1745.0           1.0  4.874941   \n",
       "8     0.372042          1735.0         2337.0           1.0  4.979347   \n",
       "9     0.291669          1273.0         1600.0           1.0  4.964419   \n",
       "10    0.435798          1860.0         2575.0           1.0  5.023674   \n",
       "11    0.129991           812.0          917.0           1.0  5.092201   \n",
       "12    0.144072           873.0          985.0           1.0  4.941554   \n",
       "13    0.198849          1152.0         1380.0           1.0  5.024466   \n",
       "14    0.230080          1228.0         1501.0           1.0  4.992622   \n",
       "15    0.481277          1921.0         2756.0           1.0  4.960894   \n",
       "16    0.218284          1264.0         1526.0           1.0  4.822063   \n",
       "17    0.294815          1469.0         1864.0           1.0  4.923450   \n",
       "\n",
       "         rho_med    mem_med  hard_share  P_general  P_latency_sensitive  \\\n",
       "0   1.496395e+09  64.062160    0.343907   0.182592                  0.0   \n",
       "1   1.542846e+09  64.020492    0.353960   0.169554                  0.0   \n",
       "2   1.540341e+09  66.006420    0.334138   0.184560                  0.0   \n",
       "3   1.470254e+09  64.517043    0.371841   0.182310                  0.0   \n",
       "4   1.515057e+09  64.294464    0.344882   0.185302                  0.0   \n",
       "5   1.493983e+09  63.261272    0.333548   0.180296                  0.0   \n",
       "6   1.509935e+09  64.400655    0.353494   0.187829                  0.0   \n",
       "7   1.516990e+09  63.494762    0.348424   0.182808                  0.0   \n",
       "8   1.471601e+09  63.057762    0.351305   0.182713                  0.0   \n",
       "9   1.506369e+09  62.987170    0.351250   0.196250                  0.0   \n",
       "10  1.492775e+09  64.190340    0.354563   0.182913                  0.0   \n",
       "11  1.533240e+09  64.098305    0.348964   0.170120                  0.0   \n",
       "12  1.475061e+09  63.059128    0.341117   0.189848                  0.0   \n",
       "13  1.453782e+09  62.179445    0.339130   0.218116                  0.0   \n",
       "14  1.487919e+09  63.739220    0.333111   0.190540                  0.0   \n",
       "15  1.498425e+09  64.496410    0.349782   0.175617                  0.0   \n",
       "16  1.508338e+09  65.064335    0.346003   0.182176                  0.0   \n",
       "17  1.509358e+09  63.177245    0.361052   0.188305                  0.0   \n",
       "\n",
       "    P_deadline_hard  P_data_intensive  P_compute_intensive  non_atomic_share  \\\n",
       "0          0.343907          0.093617             0.379884          0.467311   \n",
       "1          0.353960          0.092822             0.383663          0.433168   \n",
       "2          0.334138          0.086852             0.394451          0.434258   \n",
       "3          0.371841          0.086643             0.359206          0.435921   \n",
       "4          0.344882          0.095538             0.374278          0.440945   \n",
       "5          0.333548          0.108822             0.377334          0.430779   \n",
       "6          0.353494          0.090909             0.367769          0.447032   \n",
       "7          0.348424          0.096275             0.372493          0.429799   \n",
       "8          0.351305          0.115105             0.350877          0.452289   \n",
       "9          0.351250          0.091250             0.361250          0.460000   \n",
       "10         0.354563          0.088932             0.373592          0.445049   \n",
       "11         0.348964          0.088332             0.392585          0.443839   \n",
       "12         0.341117          0.096447             0.372589          0.458883   \n",
       "13         0.339130          0.107971             0.334783          0.446377   \n",
       "14         0.333111          0.091272             0.385077          0.457695   \n",
       "15         0.349782          0.096517             0.378084          0.464804   \n",
       "16         0.346003          0.081913             0.389908          0.461337   \n",
       "17         0.361052          0.096030             0.354614          0.445279   \n",
       "\n",
       "    mec_id  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        4  \n",
       "5        5  \n",
       "6        6  \n",
       "7        7  \n",
       "8        8  \n",
       "9        9  \n",
       "10      10  \n",
       "11      11  \n",
       "12      12  \n",
       "13      13  \n",
       "14      14  \n",
       "15      15  \n",
       "16      16  \n",
       "17      17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"agent_profiles\"].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Delta', 'K', 'topology_type', 'connection_matrix', 'private_cpu', 'public_cpu', 'cloud_cpu', 'N_agents', 'agent_to_mec', 'episodes', 'agents', 'arrivals', 'tasks', 'queues_initial', 'action_space', 'state_spec', 'checks', 'agent_profiles'])\n",
      "   agent_id       f_local  f_local_slot      m_local  lambda_mean  lambda_var  \\\n",
      "0         0  1.741183e+09  1.741183e+09  5713.849721     1.400325    0.474341   \n",
      "1         1  1.352326e+09  1.352326e+09  4566.428755     1.125348    0.140472   \n",
      "2         2  1.726668e+09  1.726668e+09  5815.120004     1.134063    0.138167   \n",
      "3         3  1.543616e+09  1.543616e+09  3539.850245     1.139918    0.147241   \n",
      "4         4  1.130883e+09  1.130883e+09  4161.367769     1.277666    0.287951   \n",
      "\n",
      "   slots_observed  n_tasks_agent  TaskDist_sum  b_mb_med       rho_med  \\\n",
      "0          1846.0         2585.0           1.0  4.975150  1.496395e+09   \n",
      "1           718.0          808.0           1.0  4.903463  1.542846e+09   \n",
      "2           731.0          829.0           1.0  4.910049  1.540341e+09   \n",
      "3           972.0         1108.0           1.0  5.067142  1.470254e+09   \n",
      "4          1491.0         1905.0           1.0  5.031714  1.515057e+09   \n",
      "\n",
      "     mem_med  hard_share  P_general  P_latency_sensitive  P_deadline_hard  \\\n",
      "0  64.062160    0.343907   0.182592                  0.0         0.343907   \n",
      "1  64.020492    0.353960   0.169554                  0.0         0.353960   \n",
      "2  66.006420    0.334138   0.184560                  0.0         0.334138   \n",
      "3  64.517043    0.371841   0.182310                  0.0         0.371841   \n",
      "4  64.294464    0.344882   0.185302                  0.0         0.344882   \n",
      "\n",
      "   P_data_intensive  P_compute_intensive  non_atomic_share  mec_id  \n",
      "0          0.093617             0.379884          0.467311       0  \n",
      "1          0.092822             0.383663          0.433168       1  \n",
      "2          0.086852             0.394451          0.434258       2  \n",
      "3          0.086643             0.359206          0.435921       3  \n",
      "4          0.095538             0.374278          0.440945       4  \n",
      "Index(['agent_id', 'f_local', 'f_local_slot', 'm_local', 'lambda_mean',\n",
      "       'lambda_var', 'slots_observed', 'n_tasks_agent', 'TaskDist_sum',\n",
      "       'b_mb_med', 'rho_med', 'mem_med', 'hard_share', 'P_general',\n",
      "       'P_latency_sensitive', 'P_deadline_hard', 'P_data_intensive',\n",
      "       'P_compute_intensive', 'non_atomic_share', 'mec_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ep   = \"ep_000\"\n",
    "topo = \"clustered\"\n",
    "scen = \"heavy\"\n",
    "\n",
    "env_cfg = env_configs[ep][topo][scen]\n",
    "\n",
    "print(env_cfg.keys())\n",
    "\n",
    "prof = env_cfg[\"agent_profiles\"]\n",
    "print(prof.head())\n",
    "print(prof.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Step 4: Clustering Agents </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.1. Feature Matrix </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform clustering, the characteristics of each agent must first be stored in a feature matrix. These characteristics include:\n",
    "\n",
    "1) Local resources\n",
    "2) task generation pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# STEP 4.1 – Agent Feature Matrix Construction\n",
    "\n",
    "# The feature matrix combines two key components:\n",
    "#   (1) Local resource capacities (hardware characteristics)\n",
    "#   (2) Task generation patterns (behavioral characteristics)\n",
    "# \n",
    "# The resulting matrix (X) is used for clustering agents in Step 4.2.\n",
    "\n",
    "\n",
    "AGENT_FEATURES_V1 = [\n",
    "    # ---- (1) Local resources ----\n",
    "    \"f_local_slot\",   # Local CPU cycles per slot\n",
    "    \"m_local\",        # Local memory capacity\n",
    "    \"lambda_mean\",    # Mean task arrival rate\n",
    "    \"lambda_var\",     # Variance of task arrival rate\n",
    "\n",
    "    # ---- (2) Task generation pattern ----\n",
    "    # Derived from labeled task distribution across final_flag categories\n",
    "    \"P_deadline_hard\",\n",
    "    \"P_latency_sensitive\",\n",
    "    \"P_compute_intensive\",\n",
    "    \"P_data_intensive\",\n",
    "    \"P_general\",\n",
    "\n",
    "    # ---- (optional statistical descriptors of generated tasks) ----\n",
    "    \"b_mb_med\",       # Median input size\n",
    "    \"rho_med\",        # Median compute demand (cycles/MB)\n",
    "    \"mem_med\",        # Median memory demand (MB)\n",
    "    \"non_atomic_share\", # Share of splittable tasks\n",
    "    \"hard_share\"        # Share of hard-deadline tasks\n",
    "]\n",
    "\n",
    "# Utility: Keep only existing columns; others will be filled with zeros\n",
    "def _safe_cols(df: pd.DataFrame, cols: List[str]) -> List[str]:\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "# Build feature matrix for one environment configuration\n",
    "def make_agent_feature_matrix_for_env(\n",
    "    env_cfg: Dict[str, Any],\n",
    "    feature_list: Optional[List[str]] = None,\n",
    "    standardize: bool = True,\n",
    ") -> Tuple[np.ndarray, List[str], np.ndarray, Optional[StandardScaler]]:\n",
    "    \"\"\"\n",
    "    Build the feature matrix (X) for all agents in one environment configuration.\n",
    "    Each row represents an agent; each column a numerical feature.\n",
    "    \n",
    "    Returns:\n",
    "        X_scaled       : np.ndarray (n_agents × n_features)\n",
    "        used_cols      : list of feature names in order\n",
    "        agent_ids      : np.ndarray of agent identifiers\n",
    "        scaler         : fitted StandardScaler object (or None if not standardized)\n",
    "    \"\"\"\n",
    "    if \"agent_profiles\" not in env_cfg or not isinstance(env_cfg[\"agent_profiles\"], pd.DataFrame):\n",
    "        raise ValueError(\"env_cfg['agent_profiles'] must contain a valid DataFrame.\")\n",
    "\n",
    "    prof = env_cfg[\"agent_profiles\"].copy()\n",
    "    if \"agent_id\" not in prof.columns:\n",
    "        raise ValueError(\"agent_profiles must include column 'agent_id'.\")\n",
    "\n",
    "    if feature_list is None:\n",
    "        feature_list = AGENT_FEATURES_V1\n",
    "\n",
    "    # Keep valid features and fill missing ones with zeros\n",
    "    cols = _safe_cols(prof, feature_list)\n",
    "    X = prof.reindex(columns=cols).fillna(0.0).astype(float).to_numpy()\n",
    "    agent_ids = prof[\"agent_id\"].to_numpy(dtype=int)\n",
    "\n",
    "    # Standardize features (mean=0, std=1) for clustering stability\n",
    "    scaler = None\n",
    "    if standardize and X.shape[0] > 0:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    return X, cols, agent_ids, scaler\n",
    "\n",
    "# Attach computed features to the environment configuration\n",
    "def attach_features_to_env(env_cfg: Dict[str, Any],\n",
    "                           feature_list: Optional[List[str]] = None,\n",
    "                           standardize: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Attach the constructed feature matrix and related metadata\n",
    "    to env_cfg[\"clustering\"][\"features\"].\n",
    "    \"\"\"\n",
    "    X, cols, agent_ids, scaler = make_agent_feature_matrix_for_env(env_cfg, feature_list, standardize)\n",
    "\n",
    "    env_cfg.setdefault(\"clustering\", {})\n",
    "    env_cfg[\"clustering\"][\"features\"] = {\n",
    "        \"X\": X,                          # Feature matrix (scaled)\n",
    "        \"feature_cols\": cols,            # List of column names\n",
    "        \"agent_ids\": agent_ids,          # Agent identifiers\n",
    "        \"scaler\": scaler,                # StandardScaler (for later inverse transform)\n",
    "        \"n_agents\": int(X.shape[0]),\n",
    "        \"n_features\": int(X.shape[1]),\n",
    "    }\n",
    "    return env_cfg\n",
    "\n",
    "# Apply feature construction to all topology-scenario combinations\n",
    "def attach_features_to_all_envs(\n",
    "    env_configs: Dict[str, Dict[str, Dict[str, Any]]],\n",
    "    feature_list: Optional[List[str]] = None,\n",
    "    standardize: bool = True,\n",
    ") -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Iterate through all (episode → topology → scenario) combinations\n",
    "    and build the feature matrix for each one.\n",
    "    \"\"\"\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                env_configs[ep_name][topo_name][scen_name] = attach_features_to_env(\n",
    "                    env_cfg, feature_list, standardize\n",
    "                )\n",
    "                fz = env_configs[ep_name][topo_name][scen_name][\"clustering\"][\"features\"]\n",
    "                print(f\"[features] {ep_name}/{topo_name}/{scen_name} \"\n",
    "                      f\"-> X.shape={fz['X'].shape}  (agents={fz['n_agents']}, feats={fz['n_features']})\")\n",
    "    return env_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assert_no_nan_inf(X: np.ndarray, where: str):\n",
    "    if not np.isfinite(X).all():\n",
    "        bad = np.isnan(X).sum(), np.isinf(X).sum()\n",
    "        raise AssertionError(f\"{where}: Feature matrix contains NaN or Inf. counts={bad}\")\n",
    "\n",
    "def _assert_agent_count_match(env_cfg: Dict[str, Any], where: str):\n",
    "    n_agents_ep = int(env_cfg[\"episodes\"][\"N_agents\"].iloc[0])\n",
    "    n_agents_prof = len(env_cfg[\"agent_profiles\"])\n",
    "    fz = env_cfg[\"clustering\"][\"features\"]\n",
    "    if not (fz[\"n_agents\"] == n_agents_prof == n_agents_ep):\n",
    "        raise AssertionError(\n",
    "            f\"{where}: Agent count mismatch. episodes={n_agents_ep}, \"\n",
    "            f\"profiles={n_agents_prof}, X={fz['n_agents']}\"\n",
    "        )\n",
    "\n",
    "def _assert_feature_prob_sum_hint(env_cfg: Dict[str, Any], tol=1e-3):\n",
    "    prof = env_cfg[\"agent_profiles\"]\n",
    "    if \"TaskDist_sum\" in prof.columns and \"n_tasks_agent\" in prof.columns:\n",
    "        mask = prof[\"n_tasks_agent\"] > 0\n",
    "        if mask.any():\n",
    "            mean_sum = float(prof.loc[mask, \"TaskDist_sum\"].mean())\n",
    "            if abs(mean_sum - 1.0) > tol:\n",
    "                print(f\"[warn] Mean(TaskDist_sum)={mean_sum:.4f} ≠ 1 (tol={tol})\")\n",
    "\n",
    "def run_feature_matrix_sanity_checks(env_configs: Dict[str, Dict[str, Dict[str, Any]]]):\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                where = f\"{ep_name}/{topo_name}/{scen_name}\"\n",
    "                if \"clustering\" not in env_cfg or \"features\" not in env_cfg[\"clustering\"]:\n",
    "                    raise AssertionError(f\"{where}: Missing features.\")\n",
    "                X = env_cfg[\"clustering\"][\"features\"][\"X\"]\n",
    "                _assert_no_nan_inf(X, where)\n",
    "                _assert_agent_count_match(env_cfg, where)\n",
    "                _assert_feature_prob_sum_hint(env_cfg)\n",
    "                if X.shape[1] == 0:\n",
    "                    raise AssertionError(f\"{where}: Empty feature matrix.\")\n",
    "    print(\"[checks] All sanity checks passed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[features] ep_000/clustered/heavy -> X.shape=(18, 14)  (agents=18, feats=14)\n",
      "[features] ep_000/clustered/light -> X.shape=(18, 14)  (agents=18, feats=14)\n",
      "[features] ep_000/clustered/moderate -> X.shape=(18, 14)  (agents=18, feats=14)\n",
      "[features] ep_000/full_mesh/heavy -> X.shape=(18, 14)  (agents=18, feats=14)\n",
      "[features] ep_000/full_mesh/light -> X.shape=(18, 14)  (agents=18, feats=14)\n",
      "[features] ep_000/full_mesh/moderate -> X.shape=(18, 14)  (agents=18, feats=14)\n",
      "[features] ep_000/sparse_ring/heavy -> X.shape=(18, 14)  (agents=18, feats=14)\n",
      "[features] ep_000/sparse_ring/light -> X.shape=(18, 14)  (agents=18, feats=14)\n",
      "[features] ep_000/sparse_ring/moderate -> X.shape=(18, 14)  (agents=18, feats=14)\n",
      "[checks] All sanity checks passed successfully.\n",
      "\n",
      "=== EXAMPLE: features of ep_000 / clustered / heavy ===\n",
      "X.shape: (18, 14)\n",
      "feature_cols: ['f_local_slot', 'm_local', 'lambda_mean', 'lambda_var', 'P_deadline_hard', 'P_latency_sensitive', 'P_compute_intensive', 'P_data_intensive', 'P_general', 'b_mb_med', 'rho_med', 'mem_med', 'non_atomic_share', 'hard_share']\n",
      "agent_ids (first 10): [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Build feature matrices for all envs\n",
    "env_configs = attach_features_to_all_envs(env_configs, feature_list=AGENT_FEATURES_V1, standardize=True)\n",
    "\n",
    "# Run sanity checks\n",
    "run_feature_matrix_sanity_checks(env_configs)\n",
    "\n",
    "# Example inspection\n",
    "print(\"\\n=== EXAMPLE: features of ep_000 / clustered / heavy ===\")\n",
    "fz = env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"clustering\"][\"features\"]\n",
    "print(\"X.shape:\", fz[\"X\"].shape)\n",
    "print(\"feature_cols:\", fz[\"feature_cols\"])\n",
    "print(\"agent_ids (first 10):\", fz[\"agent_ids\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing features: []\n",
      "   f_local_slot      m_local  lambda_mean  lambda_var  P_deadline_hard  \\\n",
      "0  1.741183e+09  5713.849721     1.400325    0.474341         0.343907   \n",
      "1  1.352326e+09  4566.428755     1.125348    0.140472         0.353960   \n",
      "2  1.726668e+09  5815.120004     1.134063    0.138167         0.334138   \n",
      "3  1.543616e+09  3539.850245     1.139918    0.147241         0.371841   \n",
      "4  1.130883e+09  4161.367769     1.277666    0.287951         0.344882   \n",
      "\n",
      "   P_latency_sensitive  P_compute_intensive  P_data_intensive  P_general  \\\n",
      "0                  0.0             0.379884          0.093617   0.182592   \n",
      "1                  0.0             0.383663          0.092822   0.169554   \n",
      "2                  0.0             0.394451          0.086852   0.184560   \n",
      "3                  0.0             0.359206          0.086643   0.182310   \n",
      "4                  0.0             0.374278          0.095538   0.185302   \n",
      "\n",
      "   b_mb_med       rho_med    mem_med  non_atomic_share  hard_share  \n",
      "0  4.975150  1.496395e+09  64.062160          0.467311    0.343907  \n",
      "1  4.903463  1.542846e+09  64.020492          0.433168    0.353960  \n",
      "2  4.910049  1.540341e+09  66.006420          0.434258    0.334138  \n",
      "3  5.067142  1.470254e+09  64.517043          0.435921    0.371841  \n",
      "4  5.031714  1.515057e+09  64.294464          0.440945    0.344882  \n"
     ]
    }
   ],
   "source": [
    "print(\"missing features:\",\n",
    "      [c for c in AGENT_FEATURES_V1 if c not in prof.columns])\n",
    "\n",
    "print(prof[ [c for c in AGENT_FEATURES_V1 if c in prof.columns] ].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (18, 14)\n",
      "feature_cols actually used: ['f_local_slot', 'm_local', 'lambda_mean', 'lambda_var', 'P_deadline_hard', 'P_latency_sensitive', 'P_compute_intensive', 'P_data_intensive', 'P_general', 'b_mb_med', 'rho_med', 'mem_med', 'non_atomic_share', 'hard_share']\n",
      "agent_ids[:10]: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "fz = env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"clustering\"][\"features\"]\n",
    "print(\"X.shape:\", fz[\"X\"].shape)\n",
    "print(\"feature_cols actually used:\", fz[\"feature_cols\"])\n",
    "print(\"agent_ids[:10]:\", fz[\"agent_ids\"][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.2. Optimal Number of Clusters </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the optimal number of clusters (K), we use a hybrid method that combines evaluation indices such as WCSS, Silhouette, DBI, and CH Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============================================\n",
    "# Step 4.2 — Selecting the number of clusters (K)\n",
    "# ===============================================\n",
    "#\n",
    "# Uses feature matrix from Step 4.1:\n",
    "#   env_cfg[\"clustering\"][\"features\"] = {\n",
    "#       \"X\", \"feature_cols\", \"agent_ids\",\n",
    "#       \"scaler\", \"n_agents\", \"n_features\"\n",
    "#   }\n",
    "#\n",
    "# For each (episode → topology → scenario) we:\n",
    "#   1) Build candidate K set based on n_agents.\n",
    "#   2) Run KMeans for each K.\n",
    "#   3) Compute metrics:\n",
    "#        - inertia (WCSS)\n",
    "#        - silhouette\n",
    "#        - Calinski–Harabasz\n",
    "#        - Davies–Bouldin\n",
    "#   4) Normalize them and compute composite score:\n",
    "#        Score(K) = α·Sil_norm(K) + β·CH_norm(K) − γ·DB_norm(K)\n",
    "#   5) Compute elbow_score from inertia curvature.\n",
    "#   6) Select:\n",
    "#        best_K  = argmax(Score(K))\n",
    "#        K_elbow = argmax(elbow_score)\n",
    "#   7) Save plot: elbow + composite score per triple:\n",
    "#        ./artifacts/clustering/<ep>/<topology>/<scenario>/elbow_and_score.png\n",
    "#\n",
    "# Results are attached to:\n",
    "#   env_cfg[\"clustering\"][\"k_selection\"] = {\n",
    "#       \"metrics_df\", \"best_K\", \"K_elbow\", \"elbow_plot_path\"\n",
    "#   }\n",
    "# And returned as:\n",
    "#   K_selection[ep][topology][scenario] = {...}\n",
    "# ===============================================\n",
    "\n",
    "# ---------- 4.2.1 Candidate K values ----------\n",
    "def _candidate_K_values(\n",
    "    n_agents: int,\n",
    "    k_min: int = 2,\n",
    "    max_K_fraction: float = 0.25,\n",
    "    max_K_abs: int = 10\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Build a reasonable candidate set for K given n_agents.\n",
    "\n",
    "    - Lower bound is k_min (default 2).\n",
    "    - Upper bound is min(max_K_abs, floor(max_K_fraction * n_agents), n_agents - 1).\n",
    "    - If n_agents is too small, returns an empty list.\n",
    "    \"\"\"\n",
    "    if n_agents <= k_min:\n",
    "        return []\n",
    "\n",
    "    k_max_by_fraction = int(np.floor(max_K_fraction * n_agents))\n",
    "    k_max = min(max_K_abs, n_agents - 1, max(k_min, k_max_by_fraction))\n",
    "\n",
    "    if k_max < k_min:\n",
    "        return []\n",
    "\n",
    "    return list(range(k_min, k_max + 1))\n",
    "\n",
    "# ---------- 4.2.2 Evaluate KMeans for a single K ----------\n",
    "def _evaluate_kmeans_for_K(\n",
    "    X: np.ndarray,\n",
    "    K: int,\n",
    "    random_state: int = 42\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run KMeans for a given K and compute clustering metrics.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          \"K\": int,\n",
    "          \"inertia\": float,\n",
    "          \"silhouette\": float or np.nan,\n",
    "          \"davies_bouldin\": float or np.nan,\n",
    "          \"calinski_harabasz\": float or np.nan,\n",
    "        }\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    result = {\n",
    "        \"K\": int(K),\n",
    "        \"inertia\": np.nan,\n",
    "        \"silhouette\": np.nan,\n",
    "        \"davies_bouldin\": np.nan,\n",
    "        \"calinski_harabasz\": np.nan,\n",
    "    }\n",
    "\n",
    "    if K <= 1 or K > n_samples:\n",
    "        return result\n",
    "\n",
    "    try:\n",
    "        km = KMeans(\n",
    "            n_clusters=K,\n",
    "            random_state=random_state,\n",
    "            n_init=\"auto\"\n",
    "        )\n",
    "        labels = km.fit_predict(X)\n",
    "        result[\"inertia\"] = float(km.inertia_)\n",
    "\n",
    "        unique_labels = np.unique(labels)\n",
    "        if unique_labels.shape[0] > 1:\n",
    "            # Silhouette\n",
    "            try:\n",
    "                result[\"silhouette\"] = float(silhouette_score(X, labels))\n",
    "            except Exception:\n",
    "                result[\"silhouette\"] = np.nan\n",
    "\n",
    "            # Davies–Bouldin\n",
    "            try:\n",
    "                result[\"davies_bouldin\"] = float(davies_bouldin_score(X, labels))\n",
    "            except Exception:\n",
    "                result[\"davies_bouldin\"] = np.nan\n",
    "\n",
    "            # Calinski–Harabasz\n",
    "            try:\n",
    "                result[\"calinski_harabasz\"] = float(calinski_harabasz_score(X, labels))\n",
    "            except Exception:\n",
    "                result[\"calinski_harabasz\"] = np.nan\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] KMeans failed for K={K}: {e}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# ---------- 4.2.3 Min-max normalization ----------\n",
    "def _min_max_normalize(\n",
    "    arr: np.ndarray,\n",
    "    invert: bool = False\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Min-max normalize a 1D array to [0, 1].\n",
    "\n",
    "    - If all values are NaN or the range is zero, returns NaN array.\n",
    "    - If invert=True, larger original values map to lower normalized ones.\n",
    "      (Useful if 'smaller is better' in the original metric.)\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr, dtype=float)\n",
    "    if np.all(np.isnan(arr)):\n",
    "        return np.full_like(arr, np.nan)\n",
    "\n",
    "    valid = ~np.isnan(arr)\n",
    "    if valid.sum() <= 1:\n",
    "        return np.full_like(arr, np.nan)\n",
    "\n",
    "    vmin = np.nanmin(arr[valid])\n",
    "    vmax = np.nanmax(arr[valid])\n",
    "    if vmax - vmin == 0:\n",
    "        return np.full_like(arr, np.nan)\n",
    "\n",
    "    norm = (arr - vmin) / (vmax - vmin)\n",
    "    if invert:\n",
    "        norm = 1.0 - norm\n",
    "    return norm\n",
    "\n",
    "# ---------- 4.2.4 Add composite score ----------\n",
    "def _add_composite_score(\n",
    "    metrics_df: pd.DataFrame,\n",
    "    alpha: float = 0.4,\n",
    "    beta: float = 0.4,\n",
    "    gamma: float = 0.2\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given metrics_df with:\n",
    "        K, inertia, silhouette, calinski_harabasz, davies_bouldin\n",
    "\n",
    "    Add:\n",
    "        sil_norm, ch_norm, db_norm, score\n",
    "    where:\n",
    "        score = alpha * sil_norm + beta * ch_norm - gamma * db_norm\n",
    "    \"\"\"\n",
    "    df = metrics_df.copy().reset_index(drop=True)\n",
    "\n",
    "    sil = df[\"silhouette\"].to_numpy(dtype=float)\n",
    "    ch  = df[\"calinski_harabasz\"].to_numpy(dtype=float)\n",
    "    db  = df[\"davies_bouldin\"].to_numpy(dtype=float)\n",
    "\n",
    "    # Silhouette: higher is better\n",
    "    df[\"sil_norm\"] = _min_max_normalize(sil, invert=False)\n",
    "\n",
    "    # Calinski–Harabasz: higher is better\n",
    "    df[\"ch_norm\"] = _min_max_normalize(ch, invert=False)\n",
    "\n",
    "    # Davies–Bouldin: lower is better → we subtract db_norm in the score\n",
    "    df[\"db_norm\"] = _min_max_normalize(db, invert=False)\n",
    "\n",
    "    df[\"score\"] = (\n",
    "        alpha * df[\"sil_norm\"].fillna(0.0)\n",
    "        + beta * df[\"ch_norm\"].fillna(0.0)\n",
    "        - gamma * df[\"db_norm\"].fillna(0.0)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- 4.2.5 Elbow score from curvature ----------\n",
    "def _compute_elbow_rank(metrics_df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute a simple 'elbow_score' based on curvature of inertia vs K.\n",
    "\n",
    "    - Normalize inertia to [0,1].\n",
    "    - Use discrete second derivative:\n",
    "        curvature_i ≈ |y_{i-1} - 2*y_i + y_{i+1}|\n",
    "    - Endpoints get curvature 0.\n",
    "    \"\"\"\n",
    "    df = metrics_df.sort_values(\"K\").reset_index(drop=True)\n",
    "    inertia = df[\"inertia\"].to_numpy(dtype=float)\n",
    "\n",
    "    if inertia.shape[0] < 3:\n",
    "        return np.zeros_like(inertia, dtype=float)\n",
    "\n",
    "    inertia_norm = _min_max_normalize(inertia, invert=False)\n",
    "    if np.all(np.isnan(inertia_norm)):\n",
    "        return np.zeros_like(inertia, dtype=float)\n",
    "\n",
    "    curv = np.zeros_like(inertia_norm, dtype=float)\n",
    "    for i in range(1, len(inertia_norm) - 1):\n",
    "        y_prev = inertia_norm[i - 1]\n",
    "        y_curr = inertia_norm[i]\n",
    "        y_next = inertia_norm[i + 1]\n",
    "        if np.isnan(y_prev) or np.isnan(y_curr) or np.isnan(y_next):\n",
    "            curv[i] = 0.0\n",
    "        else:\n",
    "            curv[i] = abs(y_prev - 2.0 * y_curr + y_next)\n",
    "\n",
    "    curv_norm = _min_max_normalize(curv, invert=False)\n",
    "    curv_norm = np.nan_to_num(curv_norm, nan=0.0)\n",
    "    return curv_norm\n",
    "\n",
    "# ---------- 4.2.6 Select best_K and K_elbow ----------\n",
    "def _select_best_K_from_df(metrics_with_scores: pd.DataFrame) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Given metrics_with_scores with columns:\n",
    "        K, score, elbow_score\n",
    "\n",
    "    Returns:\n",
    "        best_K  : K with max composite score  (tie → smallest K)\n",
    "        K_elbow : K with max elbow_score     (tie → smallest K)\n",
    "    \"\"\"\n",
    "    df = metrics_with_scores.sort_values(\"K\").reset_index(drop=True)\n",
    "\n",
    "    # best_K from composite score\n",
    "    if df[\"score\"].notna().any():\n",
    "        idx_best = df[\"score\"].idxmax()\n",
    "    else:\n",
    "        idx_best = df[\"K\"].idxmin()\n",
    "    best_K = int(df.loc[idx_best, \"K\"])\n",
    "\n",
    "    # K_elbow from elbow_score\n",
    "    if \"elbow_score\" in df.columns and df[\"elbow_score\"].notna().any():\n",
    "        idx_elb = df[\"elbow_score\"].idxmax()\n",
    "    else:\n",
    "        idx_elb = idx_best\n",
    "    K_elbow = int(df.loc[idx_elb, \"K\"])\n",
    "\n",
    "    return best_K, K_elbow\n",
    "\n",
    "# ---------- 4.2.7 Plot elbow + composite score ----------\n",
    "def _plot_elbow_and_scores(\n",
    "    metrics_df: pd.DataFrame,\n",
    "    ep_name: str,\n",
    "    topo_name: str,\n",
    "    scen_name: str,\n",
    "    out_root: str = \"./artifacts/clustering\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Plot:\n",
    "      - inertia (WCSS) vs K  → classic elbow\n",
    "      - composite score vs K\n",
    "\n",
    "    Save under:\n",
    "      ./artifacts/clustering/<ep>/<topology>/<scenario>/elbow_and_score.png\n",
    "    \"\"\"\n",
    "    df = metrics_df.sort_values(\"K\").reset_index(drop=True)\n",
    "\n",
    "    Ks      = df[\"K\"].to_numpy(dtype=int)\n",
    "    inertia = df[\"inertia\"].to_numpy(dtype=float)\n",
    "    scores  = df[\"score\"].to_numpy(dtype=float)\n",
    "\n",
    "    out_dir = os.path.join(out_root, ep_name, topo_name, scen_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, \"elbow_and_score.png\")\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Left axis: inertia (WCSS)\n",
    "    ax1 = plt.gca()\n",
    "    ax1.plot(Ks, inertia, marker=\"o\", linestyle=\"-\", label=\"WCSS (inertia)\")\n",
    "    ax1.set_xlabel(\"Number of clusters K\")\n",
    "    ax1.set_ylabel(\"WCSS (inertia)\")\n",
    "\n",
    "    # Right axis: composite score\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(Ks, scores, marker=\"s\", linestyle=\"--\", label=\"Composite score\")\n",
    "    ax2.set_ylabel(\"Composite score\")\n",
    "\n",
    "    title = f\"Elbow & Score: {ep_name} / {topo_name} / {scen_name}\"\n",
    "    ax1.set_title(title)\n",
    "\n",
    "    # Combine legends\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    return out_path\n",
    "\n",
    "# ---------- 4.2.8 Main driver over all env_configs ----------\n",
    "def step4_2_select_K_for_all_envs(\n",
    "    env_configs: Dict[str, Dict[str, Dict[str, Any]]],\n",
    "    random_state: int = 42,\n",
    "    alpha: float = 0.4,\n",
    "    beta: float = 0.4,\n",
    "    gamma: float = 0.2,\n",
    "    verbose: bool = True,\n",
    ") -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Step 4.2: K-selection for all environments.\n",
    "\n",
    "    For each:\n",
    "        env_configs[ep_name][topology_name][scenario_name][\"clustering\"][\"features\"][\"X\"]\n",
    "    we:\n",
    "      - build candidate K list\n",
    "      - run KMeans for each K\n",
    "      - compute metrics + composite score\n",
    "      - compute elbow_score\n",
    "      - select best_K and K_elbow\n",
    "      - plot & save elbow figure\n",
    "      - store results in:\n",
    "            env_cfg[\"clustering\"][\"k_selection\"]\n",
    "\n",
    "    Returns:\n",
    "      K_selection[ep_name][topology_name][scenario_name] = {\n",
    "        \"best_K\", \"K_elbow\", \"metrics_df\", \"elbow_plot_path\"\n",
    "      }\n",
    "    \"\"\"\n",
    "    K_selection: Dict[str, Dict[str, Dict[str, Any]]] = {}\n",
    "\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        K_selection[ep_name] = {}\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            K_selection[ep_name][topo_name] = {}\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "\n",
    "                # Check clustering features exist\n",
    "                clust = env_cfg.get(\"clustering\", {})\n",
    "                feats = clust.get(\"features\", None)\n",
    "                if feats is None or \"X\" not in feats:\n",
    "                    if verbose:\n",
    "                        print(f\"[4.2/skip] {ep_name}/{topo_name}/{scen_name}: \"\n",
    "                              f\"no clustering features found.\")\n",
    "                    continue\n",
    "\n",
    "                X = np.asarray(feats[\"X\"], dtype=float)\n",
    "                if X.ndim != 2 or X.shape[0] == 0:\n",
    "                    if verbose:\n",
    "                        print(f\"[4.2/skip] {ep_name}/{topo_name}/{scen_name}: \"\n",
    "                              f\"empty or invalid feature matrix.\")\n",
    "                    continue\n",
    "\n",
    "                n_agents = X.shape[0]\n",
    "                K_candidates = _candidate_K_values(n_agents)\n",
    "                if not K_candidates:\n",
    "                    if verbose:\n",
    "                        print(f\"[4.2/skip] {ep_name}/{topo_name}/{scen_name}: \"\n",
    "                              f\"not enough agents for clustering (n_agents={n_agents}).\")\n",
    "                    continue\n",
    "\n",
    "                # 1) Evaluate KMeans for all candidate K\n",
    "                metrics_list = []\n",
    "                for K in K_candidates:\n",
    "                    m = _evaluate_kmeans_for_K(X, K, random_state=random_state)\n",
    "                    metrics_list.append(m)\n",
    "                metrics_df_raw = pd.DataFrame(metrics_list).sort_values(\"K\").reset_index(drop=True)\n",
    "\n",
    "                # 2) Add composite score\n",
    "                metrics_df_full = _add_composite_score(\n",
    "                    metrics_df_raw,\n",
    "                    alpha=alpha,\n",
    "                    beta=beta,\n",
    "                    gamma=gamma\n",
    "                )\n",
    "\n",
    "                # 3) Add elbow_score\n",
    "                metrics_df_full[\"elbow_score\"] = _compute_elbow_rank(metrics_df_full)\n",
    "\n",
    "                # 4) Select best_K and K_elbow\n",
    "                best_K, K_elbow = _select_best_K_from_df(metrics_df_full)\n",
    "\n",
    "                # 5) Plot elbow + composite score\n",
    "                elbow_plot_path = _plot_elbow_and_scores(\n",
    "                    metrics_df_full,\n",
    "                    ep_name=ep_name,\n",
    "                    topo_name=topo_name,\n",
    "                    scen_name=scen_name,\n",
    "                    out_root=\"./artifacts/clustering\"\n",
    "                )\n",
    "\n",
    "                # 6) Attach to env_config\n",
    "                env_cfg.setdefault(\"clustering\", {})\n",
    "                env_cfg[\"clustering\"][\"k_selection\"] = {\n",
    "                    \"metrics_df\": metrics_df_full,\n",
    "                    \"best_K\": best_K,\n",
    "                    \"K_elbow\": K_elbow,\n",
    "                    \"elbow_plot_path\": elbow_plot_path,\n",
    "                }\n",
    "\n",
    "                # 7) Record summary\n",
    "                K_selection[ep_name][topo_name][scen_name] = {\n",
    "                    \"best_K\": best_K,\n",
    "                    \"K_elbow\": K_elbow,\n",
    "                    \"metrics_df\": metrics_df_full,\n",
    "                    \"elbow_plot_path\": elbow_plot_path,\n",
    "                }\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"[4.2] {ep_name}/{topo_name}/{scen_name}: \"\n",
    "                          f\"n_agents={n_agents}, candidates={K_candidates}\")\n",
    "                    print(f\"      → best_K  (composite score) = {best_K}\")\n",
    "                    print(f\"      → K_elbow (inertia elbow)    = {K_elbow}\")\n",
    "                    print(f\"      → elbow plot saved at: {elbow_plot_path}\")\n",
    "                    cols_show = [\n",
    "                        \"K\", \"inertia\", \"silhouette\",\n",
    "                        \"calinski_harabasz\", \"davies_bouldin\", \"score\"\n",
    "                    ]\n",
    "                    print(metrics_df_full[cols_show].round(4))\n",
    "                    print(\"-\" * 60)\n",
    "\n",
    "    return K_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.2] ep_000/clustered/heavy: n_agents=18, candidates=[2, 3, 4]\n",
      "      → best_K  (composite score) = 2\n",
      "      → K_elbow (inertia elbow)    = 3\n",
      "      → elbow plot saved at: ./artifacts/clustering\\ep_000\\clustered\\heavy\\elbow_and_score.png\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  195.3431      0.1870             3.1663          1.2104  0.4000\n",
      "1  3  152.4095      0.1484             4.0150          1.5941  0.2173\n",
      "2  4  130.2877      0.1467             3.7148          1.4449  0.1363\n",
      "------------------------------------------------------------\n",
      "[4.2] ep_000/clustered/light: n_agents=18, candidates=[2, 3, 4]\n",
      "      → best_K  (composite score) = 3\n",
      "      → K_elbow (inertia elbow)    = 3\n",
      "      → elbow plot saved at: ./artifacts/clustering\\ep_000\\clustered\\light\\elbow_and_score.png\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6009      0.1106             3.2394          1.9864 -0.2000\n",
      "1  3  154.7616      0.1461             3.8400          1.6312  0.7478\n",
      "2  4  136.0080      0.1367             3.3623          1.5057  0.3751\n",
      "------------------------------------------------------------\n",
      "[4.2] ep_000/clustered/moderate: n_agents=18, candidates=[2, 3, 4]\n",
      "      → best_K  (composite score) = 4\n",
      "      → K_elbow (inertia elbow)    = 3\n",
      "      → elbow plot saved at: ./artifacts/clustering\\ep_000\\clustered\\moderate\\elbow_and_score.png\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6764      0.1176             3.2319          2.0302 -0.2000\n",
      "1  3  159.4309      0.1580             3.5079          1.8522  0.4790\n",
      "2  4  130.3884      0.1386             3.7083          1.2767  0.6079\n",
      "------------------------------------------------------------\n",
      "[4.2] ep_000/full_mesh/heavy: n_agents=18, candidates=[2, 3, 4]\n",
      "      → best_K  (composite score) = 2\n",
      "      → K_elbow (inertia elbow)    = 3\n",
      "      → elbow plot saved at: ./artifacts/clustering\\ep_000\\full_mesh\\heavy\\elbow_and_score.png\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  195.3431      0.1870             3.1663          1.2104  0.4000\n",
      "1  3  152.4095      0.1484             4.0150          1.5941  0.2173\n",
      "2  4  130.2877      0.1467             3.7148          1.4449  0.1363\n",
      "------------------------------------------------------------\n",
      "[4.2] ep_000/full_mesh/light: n_agents=18, candidates=[2, 3, 4]\n",
      "      → best_K  (composite score) = 3\n",
      "      → K_elbow (inertia elbow)    = 3\n",
      "      → elbow plot saved at: ./artifacts/clustering\\ep_000\\full_mesh\\light\\elbow_and_score.png\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6009      0.1106             3.2394          1.9864 -0.2000\n",
      "1  3  154.7616      0.1461             3.8400          1.6312  0.7478\n",
      "2  4  136.0080      0.1367             3.3623          1.5057  0.3751\n",
      "------------------------------------------------------------\n",
      "[4.2] ep_000/full_mesh/moderate: n_agents=18, candidates=[2, 3, 4]\n",
      "      → best_K  (composite score) = 4\n",
      "      → K_elbow (inertia elbow)    = 3\n",
      "      → elbow plot saved at: ./artifacts/clustering\\ep_000\\full_mesh\\moderate\\elbow_and_score.png\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6764      0.1176             3.2319          2.0302 -0.2000\n",
      "1  3  159.4309      0.1580             3.5079          1.8522  0.4790\n",
      "2  4  130.3884      0.1386             3.7083          1.2767  0.6079\n",
      "------------------------------------------------------------\n",
      "[4.2] ep_000/sparse_ring/heavy: n_agents=18, candidates=[2, 3, 4]\n",
      "      → best_K  (composite score) = 2\n",
      "      → K_elbow (inertia elbow)    = 3\n",
      "      → elbow plot saved at: ./artifacts/clustering\\ep_000\\sparse_ring\\heavy\\elbow_and_score.png\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  195.3431      0.1870             3.1663          1.2104  0.4000\n",
      "1  3  152.4095      0.1484             4.0150          1.5941  0.2173\n",
      "2  4  130.2877      0.1467             3.7148          1.4449  0.1363\n",
      "------------------------------------------------------------\n",
      "[4.2] ep_000/sparse_ring/light: n_agents=18, candidates=[2, 3, 4]\n",
      "      → best_K  (composite score) = 3\n",
      "      → K_elbow (inertia elbow)    = 3\n",
      "      → elbow plot saved at: ./artifacts/clustering\\ep_000\\sparse_ring\\light\\elbow_and_score.png\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6009      0.1106             3.2394          1.9864 -0.2000\n",
      "1  3  154.7616      0.1461             3.8400          1.6312  0.7478\n",
      "2  4  136.0080      0.1367             3.3623          1.5057  0.3751\n",
      "------------------------------------------------------------\n",
      "[4.2] ep_000/sparse_ring/moderate: n_agents=18, candidates=[2, 3, 4]\n",
      "      → best_K  (composite score) = 4\n",
      "      → K_elbow (inertia elbow)    = 3\n",
      "      → elbow plot saved at: ./artifacts/clustering\\ep_000\\sparse_ring\\moderate\\elbow_and_score.png\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6764      0.1176             3.2319          2.0302 -0.2000\n",
      "1  3  159.4309      0.1580             3.5079          1.8522  0.4790\n",
      "2  4  130.3884      0.1386             3.7083          1.2767  0.6079\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== STEP 4.2 EXAMPLE: ep_000 / clustered / heavy ===\n",
      "Chosen best_K  (composite score): 2\n",
      "Elbow-based K_elbow             : 3\n",
      "Elbow plot path                 : ./artifacts/clustering\\ep_000\\clustered\\heavy\\elbow_and_score.png\n",
      "\n",
      "Metrics per K:\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  195.3431      0.1870             3.1663          1.2104  0.4000\n",
      "1  3  152.4095      0.1484             4.0150          1.5941  0.2173\n",
      "2  4  130.2877      0.1467             3.7148          1.4449  0.1363\n"
     ]
    }
   ],
   "source": [
    "# ---------- 4.2.9 Example driver ----------\n",
    "\n",
    "# After Step 4.1 (attach_features_to_all_envs + sanity checks), run:\n",
    "K_selection = step4_2_select_K_for_all_envs(\n",
    "    env_configs,\n",
    "    random_state=42,\n",
    "    alpha=0.4,\n",
    "    beta=0.4,\n",
    "    gamma=0.2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== STEP 4.2 EXAMPLE: ep_000 / clustered / heavy ===\")\n",
    "ex_ep   = \"ep_000\"\n",
    "ex_topo = \"clustered\"\n",
    "ex_scen = \"heavy\"\n",
    "\n",
    "if (ex_ep in K_selection and\n",
    "    ex_topo in K_selection[ex_ep] and\n",
    "    ex_scen in K_selection[ex_ep][ex_topo]):\n",
    "\n",
    "    ex_sel = K_selection[ex_ep][ex_topo][ex_scen]\n",
    "    print(\"Chosen best_K  (composite score):\", ex_sel[\"best_K\"])\n",
    "    print(\"Elbow-based K_elbow             :\", ex_sel[\"K_elbow\"])\n",
    "    print(\"Elbow plot path                 :\", ex_sel[\"elbow_plot_path\"])\n",
    "    print(\"\\nMetrics per K:\")\n",
    "    print(\n",
    "        ex_sel[\"metrics_df\"][\n",
    "            [\"K\", \"inertia\", \"silhouette\", \"calinski_harabasz\", \"davies_bouldin\", \"score\"]\n",
    "        ].round(4)\n",
    "    )\n",
    "else:\n",
    "    print(\"[warn] Example triple (ep_000/clustered/heavy) not found in K_selection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The checkups !!! (the charts are alike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. profile differences between light/moderate/heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_light vs X_heavy allclose: False\n",
      "X_light vs X_mod   allclose: False\n",
      "shapes: (18, 14) (18, 14) (18, 14)\n"
     ]
    }
   ],
   "source": [
    "ep   = \"ep_000\"\n",
    "topo = \"clustered\"\n",
    "\n",
    "X_light = env_configs[ep][topo][\"light\"][\"clustering\"][\"features\"][\"X\"]\n",
    "X_mod   = env_configs[ep][topo][\"moderate\"][\"clustering\"][\"features\"][\"X\"]\n",
    "X_heavy = env_configs[ep][topo][\"heavy\"][\"clustering\"][\"features\"][\"X\"]\n",
    "\n",
    "print(\"X_light vs X_heavy allclose:\", np.allclose(X_light, X_heavy))\n",
    "print(\"X_light vs X_mod   allclose:\", np.allclose(X_light, X_mod))\n",
    "print(\"shapes:\", X_light.shape, X_mod.shape, X_heavy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profiles equal (light vs heavy): False\n",
      "profiles equal (light vs mod)  : False\n"
     ]
    }
   ],
   "source": [
    "prof_light = env_configs[ep][topo][\"light\"][\"agent_profiles\"]\n",
    "prof_mod   = env_configs[ep][topo][\"moderate\"][\"agent_profiles\"]\n",
    "prof_heavy = env_configs[ep][topo][\"heavy\"][\"agent_profiles\"]\n",
    "\n",
    "print(\"profiles equal (light vs heavy):\", prof_light.equals(prof_heavy))\n",
    "print(\"profiles equal (light vs mod)  :\", prof_light.equals(prof_mod))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Distributions differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ep_000 / clustered / light ===\n",
      "\n",
      "lambda stats:\n",
      "       lambda_mean  lambda_var\n",
      "count    18.000000   18.000000\n",
      "mean      1.015374    0.015084\n",
      "std       0.013708    0.013243\n",
      "min       1.000000    0.000000\n",
      "25%       1.002294    0.002294\n",
      "50%       1.015236    0.015119\n",
      "75%       1.020173    0.019915\n",
      "max       1.047904    0.045884\n",
      "\n",
      "P(task_type) stats:\n",
      "       P_deadline_hard  P_latency_sensitive  P_compute_intensive  \\\n",
      "count        18.000000                 18.0            18.000000   \n",
      "mean          0.155862                  0.0             0.479526   \n",
      "std           0.033705                  0.0             0.048789   \n",
      "min           0.097826                  0.0             0.397959   \n",
      "25%           0.129342                  0.0             0.443677   \n",
      "50%           0.157262                  0.0             0.481857   \n",
      "75%           0.184173                  0.0             0.522028   \n",
      "max           0.208333                  0.0             0.562500   \n",
      "\n",
      "       P_data_intensive  P_general  \n",
      "count         18.000000  18.000000  \n",
      "mean           0.129295   0.235318  \n",
      "std            0.034889   0.038460  \n",
      "min            0.020833   0.171875  \n",
      "25%            0.115809   0.204738  \n",
      "50%            0.134366   0.239790  \n",
      "75%            0.150419   0.260887  \n",
      "max            0.182432   0.300000  \n",
      "\n",
      "median task resource stats:\n",
      "        b_mb_med       rho_med    mem_med\n",
      "count  18.000000  1.800000e+01  18.000000\n",
      "mean    2.033081  9.980534e+08  64.447748\n",
      "std     0.097993  6.619527e+07   1.851027\n",
      "min     1.837864  9.092673e+08  61.267400\n",
      "25%     1.968880  9.464900e+08  63.133130\n",
      "50%     2.023764  9.799799e+08  64.274434\n",
      "75%     2.118074  1.035023e+09  65.679627\n",
      "max     2.174956  1.134073e+09  67.328752\n",
      "\n",
      "=== ep_000 / clustered / moderate ===\n",
      "\n",
      "lambda stats:\n",
      "       lambda_mean  lambda_var\n",
      "count    18.000000   18.000000\n",
      "mean      1.064552    0.067814\n",
      "std       0.028898    0.030877\n",
      "min       1.018182    0.017960\n",
      "25%       1.041839    0.044965\n",
      "50%       1.058680    0.063160\n",
      "75%       1.088895    0.100448\n",
      "max       1.114478    0.112175\n",
      "\n",
      "P(task_type) stats:\n",
      "       P_deadline_hard  P_latency_sensitive  P_compute_intensive  \\\n",
      "count        18.000000                 18.0            18.000000   \n",
      "mean          0.254431                  0.0             0.414990   \n",
      "std           0.024213                  0.0             0.028308   \n",
      "min           0.190476                  0.0             0.364055   \n",
      "25%           0.236573                  0.0             0.401106   \n",
      "50%           0.263997                  0.0             0.405475   \n",
      "75%           0.269543                  0.0             0.425123   \n",
      "max           0.288360                  0.0             0.470238   \n",
      "\n",
      "       P_data_intensive  P_general  \n",
      "count         18.000000  18.000000  \n",
      "mean           0.109298   0.221281  \n",
      "std            0.014643   0.024688  \n",
      "min            0.084656   0.176471  \n",
      "25%            0.101985   0.210411  \n",
      "50%            0.109999   0.223877  \n",
      "75%            0.115031   0.232346  \n",
      "max            0.137850   0.285714  \n",
      "\n",
      "median task resource stats:\n",
      "        b_mb_med       rho_med    mem_med\n",
      "count  18.000000  1.800000e+01  18.000000\n",
      "mean    3.004444  1.211254e+09  64.452075\n",
      "std     0.078639  3.314238e+07   1.545911\n",
      "min     2.863606  1.129436e+09  62.257278\n",
      "25%     2.965035  1.197956e+09  63.466866\n",
      "50%     3.002903  1.208787e+09  64.439324\n",
      "75%     3.039499  1.231009e+09  65.608720\n",
      "max     3.178289  1.277348e+09  67.249938\n",
      "\n",
      "=== ep_000 / clustered / heavy ===\n",
      "\n",
      "lambda stats:\n",
      "       lambda_mean  lambda_var\n",
      "count    18.000000   18.000000\n",
      "mean      1.251721    0.273634\n",
      "std       0.105210    0.122347\n",
      "min       1.125348    0.129991\n",
      "25%       1.154417    0.160143\n",
      "50%       1.237053    0.248070\n",
      "75%       1.329647    0.352736\n",
      "max       1.434669    0.481277\n",
      "\n",
      "P(task_type) stats:\n",
      "       P_deadline_hard  P_latency_sensitive  P_compute_intensive  \\\n",
      "count        18.000000                 18.0            18.000000   \n",
      "mean          0.347804                  0.0             0.372358   \n",
      "std           0.009857                  0.0             0.015568   \n",
      "min           0.333111                  0.0             0.334783   \n",
      "25%           0.341814                  0.0             0.362880   \n",
      "50%           0.348694                  0.0             0.373935   \n",
      "75%           0.352946                  0.0             0.382719   \n",
      "max           0.371841                  0.0             0.394451   \n",
      "\n",
      "       P_data_intensive  P_general  \n",
      "count         18.000000  18.000000  \n",
      "mean           0.094736   0.185103  \n",
      "std            0.008436   0.010577  \n",
      "min            0.081913   0.169554  \n",
      "25%            0.089426   0.182209  \n",
      "50%            0.093219   0.182860  \n",
      "75%            0.096404   0.188186  \n",
      "max            0.115105   0.218116  \n",
      "\n",
      "median task resource stats:\n",
      "        b_mb_med       rho_med    mem_med\n",
      "count  18.000000  1.800000e+01  18.000000\n",
      "mean    4.967354  1.501259e+09  63.894813\n",
      "std     0.067208  2.431461e+07   0.888811\n",
      "min     4.822063  1.453782e+09  62.179445\n",
      "25%     4.927976  1.489133e+09  63.198252\n",
      "50%     4.967370  1.502397e+09  64.041326\n",
      "75%     5.015911  1.513776e+09  64.374107\n",
      "max     5.092201  1.542846e+09  66.006420\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    (\"clustered\", \"light\"),\n",
    "    (\"clustered\", \"moderate\"),\n",
    "    (\"clustered\", \"heavy\"),\n",
    "]\n",
    "\n",
    "for topo, scen in targets:\n",
    "    print(f\"\\n=== {ep} / {topo} / {scen} ===\")\n",
    "    prof = env_configs[ep][topo][scen][\"agent_profiles\"]\n",
    "\n",
    "    print(\"\\nlambda stats:\")\n",
    "    print(prof[[\"lambda_mean\", \"lambda_var\"]].describe())\n",
    "\n",
    "    print(\"\\nP(task_type) stats:\")\n",
    "    cols_p = [f\"P_{t}\" for t in [\"deadline_hard\",\"latency_sensitive\",\n",
    "                                  \"compute_intensive\",\"data_intensive\",\"general\"]]\n",
    "    print(prof[cols_p].describe())\n",
    "\n",
    "    print(\"\\nmedian task resource stats:\")\n",
    "    print(prof[[\"b_mb_med\",\"rho_med\",\"mem_med\"]].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. metrics similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== clustered / light ===\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6009      0.1106             3.2394          1.9864 -0.2000\n",
      "1  3  154.7616      0.1461             3.8400          1.6312  0.7478\n",
      "2  4  136.0080      0.1367             3.3623          1.5057  0.3751\n",
      "\n",
      "=== clustered / moderate ===\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6764      0.1176             3.2319          2.0302 -0.2000\n",
      "1  3  159.4309      0.1580             3.5079          1.8522  0.4790\n",
      "2  4  130.3884      0.1386             3.7083          1.2767  0.6079\n",
      "\n",
      "=== clustered / heavy ===\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  195.3431      0.1870             3.1663          1.2104  0.4000\n",
      "1  3  152.4095      0.1484             4.0150          1.5941  0.2173\n",
      "2  4  130.2877      0.1467             3.7148          1.4449  0.1363\n",
      "\n",
      "=== full_mesh / light ===\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6009      0.1106             3.2394          1.9864 -0.2000\n",
      "1  3  154.7616      0.1461             3.8400          1.6312  0.7478\n",
      "2  4  136.0080      0.1367             3.3623          1.5057  0.3751\n",
      "\n",
      "=== full_mesh / moderate ===\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6764      0.1176             3.2319          2.0302 -0.2000\n",
      "1  3  159.4309      0.1580             3.5079          1.8522  0.4790\n",
      "2  4  130.3884      0.1386             3.7083          1.2767  0.6079\n",
      "\n",
      "=== full_mesh / heavy ===\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  195.3431      0.1870             3.1663          1.2104  0.4000\n",
      "1  3  152.4095      0.1484             4.0150          1.5941  0.2173\n",
      "2  4  130.2877      0.1467             3.7148          1.4449  0.1363\n",
      "\n",
      "=== sparse_ring / light ===\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6009      0.1106             3.2394          1.9864 -0.2000\n",
      "1  3  154.7616      0.1461             3.8400          1.6312  0.7478\n",
      "2  4  136.0080      0.1367             3.3623          1.5057  0.3751\n",
      "\n",
      "=== sparse_ring / moderate ===\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  194.6764      0.1176             3.2319          2.0302 -0.2000\n",
      "1  3  159.4309      0.1580             3.5079          1.8522  0.4790\n",
      "2  4  130.3884      0.1386             3.7083          1.2767  0.6079\n",
      "\n",
      "=== sparse_ring / heavy ===\n",
      "   K   inertia  silhouette  calinski_harabasz  davies_bouldin   score\n",
      "0  2  195.3431      0.1870             3.1663          1.2104  0.4000\n",
      "1  3  152.4095      0.1484             4.0150          1.5941  0.2173\n",
      "2  4  130.2877      0.1467             3.7148          1.4449  0.1363\n"
     ]
    }
   ],
   "source": [
    "for topo in [\"clustered\", \"full_mesh\", \"sparse_ring\"]:\n",
    "    for scen in [\"light\", \"moderate\", \"heavy\"]:\n",
    "        sel = K_selection[\"ep_000\"][topo][scen]\n",
    "        dfm = sel[\"metrics_df\"]\n",
    "        print(f\"\\n=== {topo} / {scen} ===\")\n",
    "        print(dfm[[\"K\",\"inertia\",\"silhouette\",\n",
    "                   \"calinski_harabasz\",\"davies_bouldin\",\"score\"]].round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.3. Implementing K-Means Clustering </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting the optimal number of clusters (K_opt), we use the K-Means algorithm for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Dict, Any\n",
    "\n",
    "# ======================================================\n",
    "# Step 4.3 — Final K-Means Clustering Using Selected K\n",
    "# ======================================================\n",
    "#\n",
    "# For each (episode → topology → scenario), we:\n",
    "#   1) Fetch best_K from step 4.2\n",
    "#   2) Run K-Means (once) using best_K\n",
    "#   3) Store:\n",
    "#        - cluster_labels (per agent)\n",
    "#        - cluster_centers (scaled feature space)\n",
    "#        - agent_ids for mapping\n",
    "#\n",
    "# Results written to:\n",
    "#   env_cfg[\"clustering\"][\"final\"] = {\n",
    "#       \"K\": best_K,\n",
    "#       \"labels\": np.ndarray shape (n_agents,),\n",
    "#       \"centers\": np.ndarray shape (K, n_features),\n",
    "#       \"agent_ids\": np.ndarray\n",
    "#   }\n",
    "# ======================================================\n",
    "\n",
    "\n",
    "def step4_3_run_final_kmeans_for_all_envs(\n",
    "    env_configs: Dict[str, Dict[str, Dict[str, Any]]],\n",
    "    random_state: int = 42,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "\n",
    "    clustering_results = {}\n",
    "\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        clustering_results[ep_name] = {}\n",
    "\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            clustering_results[ep_name][topo_name] = {}\n",
    "\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "\n",
    "                clust = env_cfg.get(\"clustering\", {})\n",
    "                feats = clust.get(\"features\", None)\n",
    "                k_sel = clust.get(\"k_selection\", None)\n",
    "\n",
    "                # sanity check\n",
    "                if feats is None or \"X\" not in feats:\n",
    "                    if verbose:\n",
    "                        print(f\"[4.3/skip] {ep_name}/{topo_name}/{scen_name}: no feature matrix.\")\n",
    "                    continue\n",
    "\n",
    "                if k_sel is None or \"best_K\" not in k_sel:\n",
    "                    if verbose:\n",
    "                        print(f\"[4.3/skip] {ep_name}/{topo_name}/{scen_name}: no K chosen.\")\n",
    "                    continue\n",
    "\n",
    "                X = feats[\"X\"]\n",
    "                agent_ids = feats[\"agent_ids\"]\n",
    "                best_K = int(k_sel[\"best_K\"])\n",
    "\n",
    "                if best_K <= 1 or best_K > X.shape[0]:\n",
    "                    if verbose:\n",
    "                        print(f\"[4.3/skip] invalid best_K={best_K} for {ep_name}/{topo_name}/{scen_name}.\")\n",
    "                    continue\n",
    "\n",
    "                # ------------------------------\n",
    "                # Final K-Means fit\n",
    "                # ------------------------------\n",
    "                km = KMeans(\n",
    "                    n_clusters=best_K,\n",
    "                    random_state=random_state,\n",
    "                    n_init=\"auto\"\n",
    "                )\n",
    "                labels = km.fit_predict(X)\n",
    "                centers = km.cluster_centers_\n",
    "\n",
    "                # Store results\n",
    "                env_cfg[\"clustering\"][\"final\"] = {\n",
    "                    \"K\": best_K,\n",
    "                    \"labels\": labels,\n",
    "                    \"centers\": centers,\n",
    "                    \"agent_ids\": agent_ids,\n",
    "                }\n",
    "\n",
    "                clustering_results[ep_name][topo_name][scen_name] = {\n",
    "                    \"K\": best_K,\n",
    "                    \"labels\": labels,\n",
    "                    \"centers\": centers,\n",
    "                    \"agent_ids\": agent_ids,\n",
    "                }\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"[4.3] {ep_name}/{topo_name}/{scen_name}:\")\n",
    "                    print(f\"      best_K = {best_K}\")\n",
    "                    print(f\"      labels distribution:\", np.bincount(labels))\n",
    "                    print(f\"      centers shape:\", centers.shape)\n",
    "                    print(\"-\" * 50)\n",
    "\n",
    "    return clustering_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3] ep_000/clustered/heavy:\n",
      "      best_K = 2\n",
      "      labels distribution: [16  2]\n",
      "      centers shape: (2, 14)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3] ep_000/clustered/light:\n",
      "      best_K = 3\n",
      "      labels distribution: [7 6 5]\n",
      "      centers shape: (3, 14)\n",
      "--------------------------------------------------\n",
      "[4.3] ep_000/clustered/moderate:\n",
      "      best_K = 4\n",
      "      labels distribution: [10  4  3  1]\n",
      "      centers shape: (4, 14)\n",
      "--------------------------------------------------\n",
      "[4.3] ep_000/full_mesh/heavy:\n",
      "      best_K = 2\n",
      "      labels distribution: [16  2]\n",
      "      centers shape: (2, 14)\n",
      "--------------------------------------------------\n",
      "[4.3] ep_000/full_mesh/light:\n",
      "      best_K = 3\n",
      "      labels distribution: [7 6 5]\n",
      "      centers shape: (3, 14)\n",
      "--------------------------------------------------\n",
      "[4.3] ep_000/full_mesh/moderate:\n",
      "      best_K = 4\n",
      "      labels distribution: [10  4  3  1]\n",
      "      centers shape: (4, 14)\n",
      "--------------------------------------------------\n",
      "[4.3] ep_000/sparse_ring/heavy:\n",
      "      best_K = 2\n",
      "      labels distribution: [16  2]\n",
      "      centers shape: (2, 14)\n",
      "--------------------------------------------------\n",
      "[4.3] ep_000/sparse_ring/light:\n",
      "      best_K = 3\n",
      "      labels distribution: [7 6 5]\n",
      "      centers shape: (3, 14)\n",
      "--------------------------------------------------\n",
      "[4.3] ep_000/sparse_ring/moderate:\n",
      "      best_K = 4\n",
      "      labels distribution: [10  4  3  1]\n",
      "      centers shape: (4, 14)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== STEP 4.3 EXAMPLE: ep_000 / clustered / heavy ===\n",
      "K: 2\n",
      "Label counts: [16  2]\n",
      "Centers shape: (2, 14)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Example run\n",
    "# ------------------------\n",
    "clustering_final = step4_3_run_final_kmeans_for_all_envs(\n",
    "    env_configs,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Example inspection\n",
    "print(\"\\n=== STEP 4.3 EXAMPLE: ep_000 / clustered / heavy ===\")\n",
    "ex = clustering_final[\"ep_000\"][\"clustered\"][\"heavy\"]\n",
    "print(\"K:\", ex[\"K\"])\n",
    "print(\"Label counts:\", np.bincount(ex[\"labels\"]))\n",
    "print(\"Centers shape:\", ex[\"centers\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def step4_3_plot_clusters_pca(\n",
    "    env_configs: Dict[str, Dict[str, Dict[str, Any]]],\n",
    "    out_root: str = \"./artifacts/clustering\",\n",
    "    verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    For each environment (ep/topology/scenario), take:\n",
    "        - X (scaled feature matrix)\n",
    "        - labels (final K-Means labels)\n",
    "    Project X to 2D via PCA and save scatter plot.\n",
    "\n",
    "    Output saved as:\n",
    "        <out_root>/<ep>/<topology>/<scenario>/cluster_plot_pca.png\n",
    "    \"\"\"\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "\n",
    "                # Must have clustering results\n",
    "                clust = env_cfg.get(\"clustering\", {})\n",
    "                feats = clust.get(\"features\", None)\n",
    "                final = clust.get(\"final\", None)\n",
    "\n",
    "                if feats is None or \"X\" not in feats:\n",
    "                    continue\n",
    "                if final is None or \"labels\" not in final:\n",
    "                    if verbose:\n",
    "                        print(f\"[PCA/skip] {ep_name}/{topo_name}/{scen_name}: no final KMeans labels.\")\n",
    "                    continue\n",
    "\n",
    "                X = feats[\"X\"]\n",
    "                labels = final[\"labels\"]\n",
    "                K = final[\"K\"]\n",
    "\n",
    "                # PCA projection\n",
    "                pca = PCA(n_components=2, random_state=42)\n",
    "                X_2d = pca.fit_transform(X)\n",
    "\n",
    "                # Plot\n",
    "                out_dir = os.path.join(out_root, ep_name, topo_name, scen_name)\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "                out_path = os.path.join(out_dir, \"cluster_plot_pca.png\")\n",
    "\n",
    "                plt.figure(figsize=(6, 5))\n",
    "\n",
    "                for cl in np.unique(labels):\n",
    "                    mask = (labels == cl)\n",
    "                    plt.scatter(\n",
    "                        X_2d[mask, 0],\n",
    "                        X_2d[mask, 1],\n",
    "                        label=f\"Cluster {cl}\",\n",
    "                        alpha=0.75,\n",
    "                        s=50\n",
    "                    )\n",
    "\n",
    "                plt.title(f\"PCA Clusters: {ep_name} / {topo_name} / {scen_name}  (K={K})\")\n",
    "                plt.xlabel(\"PCA Component 1\")\n",
    "                plt.ylabel(\"PCA Component 2\")\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(out_path, dpi=150)\n",
    "                plt.close()\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"[PCA] Saved PCA cluster plot → {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PCA] Saved PCA cluster plot → ./artifacts/clustering\\ep_000\\clustered\\heavy\\cluster_plot_pca.png\n",
      "[PCA] Saved PCA cluster plot → ./artifacts/clustering\\ep_000\\clustered\\light\\cluster_plot_pca.png\n",
      "[PCA] Saved PCA cluster plot → ./artifacts/clustering\\ep_000\\clustered\\moderate\\cluster_plot_pca.png\n",
      "[PCA] Saved PCA cluster plot → ./artifacts/clustering\\ep_000\\full_mesh\\heavy\\cluster_plot_pca.png\n",
      "[PCA] Saved PCA cluster plot → ./artifacts/clustering\\ep_000\\full_mesh\\light\\cluster_plot_pca.png\n",
      "[PCA] Saved PCA cluster plot → ./artifacts/clustering\\ep_000\\full_mesh\\moderate\\cluster_plot_pca.png\n",
      "[PCA] Saved PCA cluster plot → ./artifacts/clustering\\ep_000\\sparse_ring\\heavy\\cluster_plot_pca.png\n",
      "[PCA] Saved PCA cluster plot → ./artifacts/clustering\\ep_000\\sparse_ring\\light\\cluster_plot_pca.png\n",
      "[PCA] Saved PCA cluster plot → ./artifacts/clustering\\ep_000\\sparse_ring\\moderate\\cluster_plot_pca.png\n"
     ]
    }
   ],
   "source": [
    "step4_3_plot_clusters_pca(env_configs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization — Display clusters in 2D space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.4. Store cluster labels </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-by-step implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
