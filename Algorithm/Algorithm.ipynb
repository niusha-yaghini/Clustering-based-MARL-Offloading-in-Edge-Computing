{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Imports </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\Users\\niush\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Step 1: Prepare data and configure the environment </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1. Data Loading (Data I/O) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directories\n",
    "dataset_dir = '../Data_Generator/datasets'\n",
    "topology_dir = '../Topology_Generator/topologies'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global container\n",
    "datasets = {}\n",
    "\n",
    "def load_datasets_from_directory(dataset_dir, verbose=True):\n",
    "    \"\"\"\n",
    "    Build 'episode-first' structure:\n",
    "    datasets = {\n",
    "        \"ep_000\": {\n",
    "            \"light\":   { \"episodes\": df, \"agents\": df, \"arrivals\": df, \"tasks\": df },\n",
    "            \"moderate\":{ ... },\n",
    "            \"heavy\":   { ... }\n",
    "        },\n",
    "        \"ep_001\": { ... },\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Step 1 — detect scenarios (light/moderate/heavy/...)\n",
    "    scenarios = [\n",
    "        name for name in os.listdir(dataset_dir)\n",
    "        if os.path.isdir(os.path.join(dataset_dir, name))\n",
    "    ]\n",
    "\n",
    "    # Step 2 — load per scenario and per episode (ep_XXX)\n",
    "    scenario_to_episodes = {}\n",
    "    for scenario in scenarios:\n",
    "        scn_path = os.path.join(dataset_dir, scenario)\n",
    "        ep_dirs = sorted([\n",
    "            ep for ep in os.listdir(scn_path)\n",
    "            if os.path.isdir(os.path.join(scn_path, ep)) and ep.startswith(\"ep_\")\n",
    "        ])\n",
    "        if not ep_dirs and verbose:\n",
    "            print(f\"[warn] no ep_* folders found under scenario '{scenario}'\")\n",
    "\n",
    "        scenario_to_episodes[scenario] = {}\n",
    "        for ep_name in ep_dirs:\n",
    "            ep_path = os.path.join(scn_path, ep_name)\n",
    "            try:\n",
    "                scenario_to_episodes[scenario][ep_name] = {\n",
    "                    \"episodes\": pd.read_csv(os.path.join(ep_path, \"episodes.csv\")),\n",
    "                    \"agents\":   pd.read_csv(os.path.join(ep_path, \"agents.csv\")),\n",
    "                    \"arrivals\": pd.read_csv(os.path.join(ep_path, \"arrivals.csv\")),\n",
    "                    \"tasks\":    pd.read_csv(os.path.join(ep_path, \"tasks.csv\")),\n",
    "                }\n",
    "            except FileNotFoundError as e:\n",
    "                if verbose:\n",
    "                    print(f\"[error] missing CSV in {ep_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Step 3 — invert structure: episodes → scenarios\n",
    "    datasets.clear()\n",
    "    for scenario, eps in scenario_to_episodes.items():\n",
    "        for ep_name, dfs in eps.items():\n",
    "            if ep_name not in datasets:\n",
    "                datasets[ep_name] = {}\n",
    "            datasets[ep_name][scenario] = dfs\n",
    "\n",
    "    # Optional summary printing\n",
    "    if verbose:\n",
    "        print(\"=== Dataset Summary (episode-first) ===\")\n",
    "        print(f\"episodes: {len(datasets)}  | scenarios detected: {len(scenarios)} -> {sorted(scenarios)}\")\n",
    "        for ep_name in sorted(datasets.keys()):\n",
    "            scenarios_here = sorted(datasets[ep_name].keys())\n",
    "            print(f\"  - {ep_name}: scenarios = {scenarios_here}\")\n",
    "            for scn in scenarios_here:\n",
    "                dfs = datasets[ep_name][scn]\n",
    "                n_ep   = len(dfs['episodes'])\n",
    "                n_ag   = len(dfs['agents'])\n",
    "                n_arr  = len(dfs['arrivals'])\n",
    "                n_task = len(dfs['tasks'])\n",
    "                print(f\"      {scn:9s} → episodes:{n_ep:3d}  agents:{n_ag:4d}  arrivals:{n_arr:6d}  tasks:{n_task:6d}\")\n",
    "        print(\"=======================================\")\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Summary (episode-first) ===\n",
      "episodes: 1  | scenarios detected: 3 -> ['heavy', 'light', 'moderate']\n",
      "  - ep_000: scenarios = ['heavy', 'light', 'moderate']\n",
      "      heavy     → episodes:  1  agents:  18  arrivals: 30636  tasks: 30636\n",
      "      light     → episodes:  1  agents:  18  arrivals:  2113  tasks:  2113\n",
      "      moderate  → episodes:  1  agents:  18  arrivals:  8262  tasks:  8262\n",
      "=======================================\n",
      "\n",
      "[info] printing from episode='ep_000', scenario='heavy'\n",
      "\n",
      "agents:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>f_local</th>\n",
       "      <th>m_local</th>\n",
       "      <th>lam_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>0.708673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>0.234989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>0.228174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>0.310369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>0.548990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id       f_local      m_local   lam_sec\n",
       "0         0  1.741183e+09  5713.849721  0.708673\n",
       "1         1  1.352326e+09  4566.428755  0.234989\n",
       "2         2  1.726668e+09  5815.120004  0.228174\n",
       "3         3  1.543616e+09  3539.850245  0.310369\n",
       "4         4  1.130883e+09  4161.367769  0.548990"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   agent_id  18 non-null     int64  \n",
      " 1   f_local   18 non-null     float64\n",
      " 2   m_local   18 non-null     float64\n",
      " 3   lam_sec   18 non-null     float64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 704.0 bytes\n",
      "\n",
      "arrivals:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>t_slot</th>\n",
       "      <th>t_time</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>task_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "0    heavy           0       0     0.0         0        0\n",
       "1    heavy           0       0     0.0         1        1\n",
       "2    heavy           0       0     0.0         4        2\n",
       "3    heavy           0       0     0.0         7        3\n",
       "4    heavy           0       0     0.0        10        4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30636 entries, 0 to 30635\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   scenario    30636 non-null  object \n",
      " 1   episode_id  30636 non-null  int64  \n",
      " 2   t_slot      30636 non-null  int64  \n",
      " 3   t_time      30636 non-null  float64\n",
      " 4   agent_id    30636 non-null  int64  \n",
      " 5   task_id     30636 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 1.4+ MB\n",
      "\n",
      "episodes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>Delta</th>\n",
       "      <th>T_slots</th>\n",
       "      <th>hours</th>\n",
       "      <th>N_agents</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "0    heavy           0    1.0     3600    1.0        18   345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   scenario    1 non-null      object \n",
      " 1   episode_id  1 non-null      int64  \n",
      " 2   Delta       1 non-null      float64\n",
      " 3   T_slots     1 non-null      int64  \n",
      " 4   hours       1 non-null      float64\n",
      " 5   N_agents    1 non-null      int64  \n",
      " 6   seed        1 non-null      int64  \n",
      "dtypes: float64(2), int64(4), object(1)\n",
      "memory usage: 184.0+ bytes\n",
      "\n",
      "tasks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>t_arrival_slot</th>\n",
       "      <th>t_arrival_time</th>\n",
       "      <th>b_mb</th>\n",
       "      <th>rho_cyc_per_mb</th>\n",
       "      <th>c_cycles</th>\n",
       "      <th>mem_mb</th>\n",
       "      <th>modality</th>\n",
       "      <th>has_deadline</th>\n",
       "      <th>deadline_s</th>\n",
       "      <th>deadline_time</th>\n",
       "      <th>non_atomic</th>\n",
       "      <th>split_ratio</th>\n",
       "      <th>action_space_hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.202096</td>\n",
       "      <td>9.727147e+08</td>\n",
       "      <td>7.005585e+09</td>\n",
       "      <td>66.611010</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800726</td>\n",
       "      <td>0.800726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.479984</td>\n",
       "      <td>1.314973e+09</td>\n",
       "      <td>7.206031e+09</td>\n",
       "      <td>77.928800</td>\n",
       "      <td>image</td>\n",
       "      <td>1</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.421977</td>\n",
       "      <td>2.500222e+09</td>\n",
       "      <td>2.105681e+10</td>\n",
       "      <td>72.966446</td>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323007</td>\n",
       "      <td>0.323007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539704</td>\n",
       "      <td>continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.324986</td>\n",
       "      <td>1.779582e+09</td>\n",
       "      <td>1.125583e+10</td>\n",
       "      <td>56.492900</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481587</td>\n",
       "      <td>0.481587</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.473269</td>\n",
       "      <td>1.087572e+09</td>\n",
       "      <td>1.247800e+10</td>\n",
       "      <td>73.389854</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594564</td>\n",
       "      <td>0.594564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>discrete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "0    heavy           0        0         0               0             0.0   \n",
       "1    heavy           0        1         1               0             0.0   \n",
       "2    heavy           0        2         4               0             0.0   \n",
       "3    heavy           0        3         7               0             0.0   \n",
       "4    heavy           0        4        10               0             0.0   \n",
       "\n",
       "        b_mb  rho_cyc_per_mb      c_cycles     mem_mb modality  has_deadline  \\\n",
       "0   7.202096    9.727147e+08  7.005585e+09  66.611010   sensor             1   \n",
       "1   5.479984    1.314973e+09  7.206031e+09  77.928800    image             1   \n",
       "2   8.421977    2.500222e+09  2.105681e+10  72.966446     text             1   \n",
       "3   6.324986    1.779582e+09  1.125583e+10  56.492900   sensor             1   \n",
       "4  11.473269    1.087572e+09  1.247800e+10  73.389854   sensor             1   \n",
       "\n",
       "   deadline_s  deadline_time  non_atomic  split_ratio action_space_hint  \n",
       "0    0.800726       0.800726           0     0.000000          discrete  \n",
       "1    0.615113       0.615113           0     0.000000          discrete  \n",
       "2    0.323007       0.323007           1     0.539704        continuous  \n",
       "3    0.481587       0.481587           0     0.000000          discrete  \n",
       "4    0.594564       0.594564           0     0.000000          discrete  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30636 entries, 0 to 30635\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   scenario           30636 non-null  object \n",
      " 1   episode_id         30636 non-null  int64  \n",
      " 2   task_id            30636 non-null  int64  \n",
      " 3   agent_id           30636 non-null  int64  \n",
      " 4   t_arrival_slot     30636 non-null  int64  \n",
      " 5   t_arrival_time     30636 non-null  float64\n",
      " 6   b_mb               30636 non-null  float64\n",
      " 7   rho_cyc_per_mb     30636 non-null  float64\n",
      " 8   c_cycles           30636 non-null  float64\n",
      " 9   mem_mb             30636 non-null  float64\n",
      " 10  modality           30636 non-null  object \n",
      " 11  has_deadline       30636 non-null  int64  \n",
      " 12  deadline_s         10673 non-null  float64\n",
      " 13  deadline_time      10673 non-null  float64\n",
      " 14  non_atomic         30636 non-null  int64  \n",
      " 15  split_ratio        30636 non-null  float64\n",
      " 16  action_space_hint  30636 non-null  object \n",
      "dtypes: float64(8), int64(6), object(3)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# ---- load all datasets (episode-first) ----\n",
    "datasets = load_datasets_from_directory(dataset_dir, verbose=True)\n",
    "\n",
    "# ---- choose an episode and a scenario for printing ----\n",
    "# pick first available episode if you don't want to hardcode\n",
    "ep_name = sorted(datasets.keys())[0] if datasets else None\n",
    "scenario = \"heavy\"  # you can change to \"light\"/\"moderate\" if needed\n",
    "\n",
    "if ep_name is not None and scenario in datasets[ep_name]:\n",
    "    print(f\"\\n[info] printing from episode='{ep_name}', scenario='{scenario}'\")\n",
    "\n",
    "    print(\"\\nagents:\")\n",
    "    display(datasets[ep_name][scenario]['agents'].head())\n",
    "    datasets[ep_name][scenario]['agents'].info()\n",
    "\n",
    "    print(\"\\narrivals:\")\n",
    "    display(datasets[ep_name][scenario]['arrivals'].head())\n",
    "    datasets[ep_name][scenario]['arrivals'].info()\n",
    "\n",
    "    print(\"\\nepisodes:\")\n",
    "    display(datasets[ep_name][scenario]['episodes'].head())\n",
    "    datasets[ep_name][scenario]['episodes'].info()\n",
    "\n",
    "    print(\"\\ntasks:\")\n",
    "    display(datasets[ep_name][scenario]['tasks'].head())\n",
    "    datasets[ep_name][scenario]['tasks'].info()\n",
    "else:\n",
    "    print(\"[error] no datasets found or requested scenario is missing for the chosen episode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global container\n",
    "topologies = {}\n",
    "\n",
    "def load_topologies_from_directory(topology_dir):\n",
    "    \n",
    "    for topology_name in os.listdir(topology_dir):\n",
    "        topology_path = os.path.join(topology_dir, topology_name)\n",
    "        \n",
    "        # Only process directories\n",
    "        if os.path.isdir(topology_path):\n",
    "            topology_json_path = os.path.join(topology_path, \"topology.json\")\n",
    "            meta_json_path = os.path.join(topology_path, \"topology_meta.json\")\n",
    "            connection_matrix_csv_path = os.path.join(topology_path, \"connection_matrix.csv\")\n",
    "            \n",
    "             # --- Load JSON & CSV files ---\n",
    "            topology_data = None\n",
    "            meta_data = None\n",
    "            with open(topology_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                topology_data = json.load(f)\n",
    "            with open(meta_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                meta_data = json.load(f)\n",
    "            \n",
    "            # The first column is just for displaying row names, not part of the capacity matrix. \n",
    "            # So the best way is to index the first column. (index_col=0)\n",
    "            connection_matrix = pd.read_csv(connection_matrix_csv_path, index_col=0)\n",
    "            \n",
    "            # Store the topology details and the loaded CSV\n",
    "            topologies[topology_name] = {\n",
    "                \"topology_data\": topology_data,\n",
    "                \"meta_data\": meta_data,\n",
    "                \"connection_matrix\": connection_matrix  # Store the loaded CSV data\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topology clustered -> connection_matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mec_0</th>\n",
       "      <th>mec_1</th>\n",
       "      <th>mec_2</th>\n",
       "      <th>mec_3</th>\n",
       "      <th>mec_4</th>\n",
       "      <th>mec_5</th>\n",
       "      <th>mec_6</th>\n",
       "      <th>mec_7</th>\n",
       "      <th>mec_8</th>\n",
       "      <th>mec_9</th>\n",
       "      <th>mec_10</th>\n",
       "      <th>mec_11</th>\n",
       "      <th>mec_12</th>\n",
       "      <th>mec_13</th>\n",
       "      <th>mec_14</th>\n",
       "      <th>mec_15</th>\n",
       "      <th>mec_16</th>\n",
       "      <th>mec_17</th>\n",
       "      <th>cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mec_0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.798801</td>\n",
       "      <td>11.958295</td>\n",
       "      <td>11.470404</td>\n",
       "      <td>9.980195</td>\n",
       "      <td>8.814050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.912800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_1</th>\n",
       "      <td>9.798801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.375143</td>\n",
       "      <td>11.535600</td>\n",
       "      <td>10.702584</td>\n",
       "      <td>9.136893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.609202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_2</th>\n",
       "      <td>11.958295</td>\n",
       "      <td>8.375143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.814632</td>\n",
       "      <td>9.637714</td>\n",
       "      <td>9.170700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.055348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_3</th>\n",
       "      <td>11.470404</td>\n",
       "      <td>11.535600</td>\n",
       "      <td>8.814632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.377054</td>\n",
       "      <td>11.920252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.851664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mec_4</th>\n",
       "      <td>9.980195</td>\n",
       "      <td>10.702584</td>\n",
       "      <td>9.637714</td>\n",
       "      <td>10.377054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.105383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.076301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mec_0      mec_1      mec_2      mec_3      mec_4      mec_5  \\\n",
       "mec_0   0.000000   9.798801  11.958295  11.470404   9.980195   8.814050   \n",
       "mec_1   9.798801   0.000000   8.375143  11.535600  10.702584   9.136893   \n",
       "mec_2  11.958295   8.375143   0.000000   8.814632   9.637714   9.170700   \n",
       "mec_3  11.470404  11.535600   8.814632   0.000000  10.377054  11.920252   \n",
       "mec_4   9.980195  10.702584   9.637714  10.377054   0.000000   8.105383   \n",
       "\n",
       "       mec_6  mec_7  mec_8  mec_9  mec_10  mec_11  mec_12  mec_13  mec_14  \\\n",
       "mec_0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mec_1    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mec_2    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mec_3    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "mec_4    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       mec_15  mec_16  mec_17       cloud  \n",
       "mec_0     0.0     0.0     0.0   98.912800  \n",
       "mec_1     0.0     0.0     0.0  104.609202  \n",
       "mec_2     0.0     0.0     0.0   92.055348  \n",
       "mec_3     0.0     0.0     0.0   84.851664  \n",
       "mec_4     0.0     0.0     0.0   99.076301  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18 entries, mec_0 to mec_17\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mec_0   18 non-null     float64\n",
      " 1   mec_1   18 non-null     float64\n",
      " 2   mec_2   18 non-null     float64\n",
      " 3   mec_3   18 non-null     float64\n",
      " 4   mec_4   18 non-null     float64\n",
      " 5   mec_5   18 non-null     float64\n",
      " 6   mec_6   18 non-null     float64\n",
      " 7   mec_7   18 non-null     float64\n",
      " 8   mec_8   18 non-null     float64\n",
      " 9   mec_9   18 non-null     float64\n",
      " 10  mec_10  18 non-null     float64\n",
      " 11  mec_11  18 non-null     float64\n",
      " 12  mec_12  18 non-null     float64\n",
      " 13  mec_13  18 non-null     float64\n",
      " 14  mec_14  18 non-null     float64\n",
      " 15  mec_15  18 non-null     float64\n",
      " 16  mec_16  18 non-null     float64\n",
      " 17  mec_17  18 non-null     float64\n",
      " 18  cloud   18 non-null     float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 2.8+ KB\n",
      "\n",
      "topology clustered -> topology_data\n",
      "{'number_of_servers': 18, 'private_cpu_capacities': [1417026512.123894, 1465835517.1380253, 1400296152.8672054, 1219863115.6758468, 1270376631.237273, 1348019534.1092064, 1786161289.9722981, 1380932007.7716885, 1739680378.9314957, 1606151704.3138125, 1722792016.067419, 1452119690.3718696, 1575323717.1732426, 1675176049.772993, 1465269239.5654364, 1565743740.4168038, 1715259832.5839007, 1225832428.456285], 'public_cpu_capacities': [768946447.3896191, 753418540.8443304, 702715947.6715652, 545197668.8935852, 670994513.1813464, 680525151.7601619, 811159071.5491732, 782943570.2288362, 501997671.50295806, 685198791.9005744, 822519853.1111488, 716138690.9607652, 822355072.296565, 556428866.3646028, 805978940.2755054, 790274917.5537901, 602437544.1146357, 709495765.381235], 'cloud_computational_capacity': 30000000000.0, 'connection_matrix': [[0.0, 9.798800609449902, 11.958295388571093, 11.470404384171585, 9.980195439399376, 8.8140500666217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.91279981562592], [9.798800609449902, 0.0, 8.375143239602235, 11.535600106180025, 10.702584376249934, 9.136893120492793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.60920207554163], [11.958295388571093, 8.375143239602235, 0.0, 8.814631907625701, 9.637714071509851, 9.170700424264968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 92.05534806322484], [11.470404384171585, 11.535600106180025, 8.814631907625701, 0.0, 10.37705391001423, 11.920252079923895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 84.85166371762908], [9.980195439399376, 10.702584376249934, 9.637714071509851, 10.37705391001423, 0.0, 8.10538323609413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.0763009651688], [8.8140500666217, 9.136893120492793, 9.170700424264968, 11.920252079923895, 8.10538323609413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 115.0792791055983], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.844690223161571, 9.566567838535661, 11.01158338193066, 10.132206014485726, 11.731761213672993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 115.87637059619391], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.844690223161571, 0.0, 8.17265481777462, 11.317250164676846, 9.944330066939582, 11.698994881774604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 85.49730491373893], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.566567838535661, 8.17265481777462, 0.0, 11.919271797879857, 9.162931925532463, 11.22074688068535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.13111014716404], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.01158338193066, 11.317250164676846, 11.919271797879857, 0.0, 11.8680001020066, 11.393785145055949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 87.20532264682294], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.132206014485726, 9.944330066939582, 9.162931925532463, 11.8680001020066, 0.0, 9.548734790752288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 98.89380625765318], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.731761213672993, 11.698994881774604, 11.22074688068535, 11.393785145055949, 9.548734790752288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.16242880696842], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.573089728358958, 10.155633210306574, 11.202595781660758, 10.69123291440641, 11.439129446848145, 94.68338717140213], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.573089728358958, 0.0, 10.795539716597093, 9.382485758460357, 8.156515169162681, 10.108953651086749, 86.2148806997884], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.155633210306574, 10.795539716597093, 0.0, 8.183423253938845, 9.055460579237527, 8.857865582666564, 100.51802149006446], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.202595781660758, 9.382485758460357, 8.183423253938845, 0.0, 10.922031113226154, 8.777507498932518, 85.56329833615376], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.69123291440641, 8.156515169162681, 9.055460579237527, 10.922031113226154, 0.0, 11.48804541896262, 109.44902761831553], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.439129446848145, 10.108953651086749, 8.857865582666564, 8.777507498932518, 11.48804541896262, 0.0, 119.21419244342577]], 'time_step': 1.0, 'topology_type': 'clustered', 'skip_k': 5, 'symmetric': True, 'num_clusters': 3}\n",
      "\n",
      "topology clustered -> meta_data\n",
      "{'generated_at_utc': '2025-11-05T07:48:30Z', 'fingerprint': '9a3a6cc2768b6834', 'env': {'python': '3.10.9', 'user': 'niush'}, 'units': {'compute': 'CPU cycles per slot', 'links': 'MB per slot', 'time_step': 'seconds'}, 'notes': {'inputs_unit': {'compute': 'CPU cycles per second', 'links': 'MB per second'}, 'conversion': 'per_slot = per_second * time_step', 'topology_semantics': {'skip_connections': \"k-nearest ring; each MEC connects to next 'skip_k' neighbors on a circle\"}}, 'hyperparameters': {'number_of_servers': 18, 'time_step': 1.0, 'private_cpu_min': 1200000000.0, 'private_cpu_max': 1800000000.0, 'public_cpu_min': 500000000.0, 'public_cpu_max': 900000000.0, 'cpu_total_min': None, 'cpu_total_max': None, 'public_share': None, 'cloud_capacity': 30000000000.0, 'cloud_capacity_min': None, 'cloud_capacity_max': None, 'horiz_cap_min': 8.0, 'horiz_cap_max': 12.0, 'cloud_cap_min': 80.0, 'cloud_cap_max': 120.0, 'topology_type': 'clustered', 'skip_k': 5, 'symmetric': True, 'num_clusters': 3, 'inter_cluster_frac': 0.0, 'seed': 20251229}}\n"
     ]
    }
   ],
   "source": [
    "load_topologies_from_directory(topology_dir)\n",
    "\n",
    "print('topology clustered -> connection_matrix')\n",
    "display(topologies['clustered']['connection_matrix'].head())\n",
    "topologies['clustered']['connection_matrix'].info()\n",
    "\n",
    "print('\\ntopology clustered -> topology_data')\n",
    "print(topologies['clustered']['topology_data'])\n",
    "\n",
    "print('\\ntopology clustered -> meta_data')\n",
    "print(topologies['clustered']['meta_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.2. Data Validation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the data, we must validate that required columns exist and that IDs match properly.\n",
    "\n",
    "**The code below performs three layers of checks:** \n",
    "\n",
    "- Validate each dataset (episodes/agents/arrivals/tasks)\n",
    "- Validate each topology (JSON and connection matrix)\n",
    "- Validate dataset–topology pairs for unit alignment and overall consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Generic helpers ----------\n",
    "def _require(cond: bool, msg: str, errors: list):\n",
    "    # Collect errors instead of stopping at first failure\n",
    "    if not cond:\n",
    "        errors.append(msg)\n",
    "\n",
    "def _has_cols(df: pd.DataFrame, cols: list) -> bool:\n",
    "    return all(c in df.columns for c in cols)\n",
    "\n",
    "# ---------- Dataset-level validation ----------\n",
    "def validate_one_dataset(dataset_key: str, ds: dict) -> list:\n",
    "    \"\"\"\n",
    "    Validate a single dataset pack (episodes/agents/arrivals/tasks) for one (episode, scenario).\n",
    "    'dataset_key' is just a label for error messages, e.g. 'ep_000/heavy'.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    episodes = ds.get(\"episodes\")\n",
    "    agents   = ds.get(\"agents\")\n",
    "    arrivals = ds.get(\"arrivals\")\n",
    "    tasks    = ds.get(\"tasks\")\n",
    "\n",
    "    # 1) Presence checks\n",
    "    _require(isinstance(episodes, pd.DataFrame), f\"[{dataset_key}] episodes missing or not a DataFrame\", errors)\n",
    "    _require(isinstance(agents,   pd.DataFrame), f\"[{dataset_key}] agents missing or not a DataFrame\", errors)\n",
    "    _require(isinstance(arrivals, pd.DataFrame), f\"[{dataset_key}] arrivals missing or not a DataFrame\", errors)\n",
    "    _require(isinstance(tasks,    pd.DataFrame), f\"[{dataset_key}] tasks missing or not a DataFrame\", errors)\n",
    "    if errors:\n",
    "        return errors\n",
    "\n",
    "    # 2) Required columns (based on your generators)\n",
    "    req_ep_cols  = [\"scenario\", \"episode_id\", \"Delta\", \"T_slots\", \"hours\", \"N_agents\", \"seed\"]\n",
    "    req_ag_cols  = [\"agent_id\", \"f_local\", \"m_local\", \"lam_sec\"]\n",
    "    req_ar_cols  = [\"scenario\", \"episode_id\", \"t_slot\", \"t_time\", \"agent_id\", \"task_id\"]\n",
    "    req_tk_cols  = [\n",
    "        \"scenario\",\"episode_id\",\"task_id\",\"agent_id\",\"t_arrival_slot\",\"t_arrival_time\",\n",
    "        \"b_mb\",\"rho_cyc_per_mb\",\"c_cycles\",\"mem_mb\",\"modality\",\n",
    "        \"has_deadline\",\"deadline_s\",\"deadline_time\",\"non_atomic\",\"split_ratio\",\"action_space_hint\"\n",
    "    ]\n",
    "    _require(_has_cols(episodes, req_ep_cols), f\"[{dataset_key}] episodes missing required columns\", errors)\n",
    "    _require(_has_cols(agents,   req_ag_cols), f\"[{dataset_key}] agents missing required columns\", errors)\n",
    "    _require(_has_cols(arrivals, req_ar_cols), f\"[{dataset_key}] arrivals missing required columns\", errors)\n",
    "    _require(_has_cols(tasks,    req_tk_cols), f\"[{dataset_key}] tasks missing required columns\", errors)\n",
    "    if errors:\n",
    "        return errors\n",
    "\n",
    "    # 3) Integrity checks\n",
    "    # unique task_id\n",
    "    _require(tasks[\"task_id\"].is_unique, f\"[{dataset_key}] task_id is not unique\", errors)\n",
    "\n",
    "    # agent id range & count vs episodes.N_agents\n",
    "    if len(agents):\n",
    "        min_id = agents[\"agent_id\"].min()\n",
    "        max_id = agents[\"agent_id\"].max()\n",
    "        expected_n = int(episodes[\"N_agents\"].iloc[0])\n",
    "        _require(min_id == 0, f\"[{dataset_key}] agent_id should start at 0 (got {min_id})\", errors)\n",
    "        _require(max_id == expected_n - 1,\n",
    "                 f\"[{dataset_key}] agent_id max should be N_agents-1 ({expected_n-1}), got {max_id}\", errors)\n",
    "\n",
    "    # cross refs\n",
    "    valid_agents = set(agents[\"agent_id\"].tolist())\n",
    "    bad_arr_agents = set(arrivals[\"agent_id\"]) - valid_agents\n",
    "    bad_task_agents = set(tasks[\"agent_id\"]) - valid_agents\n",
    "    _require(len(bad_arr_agents) == 0, f\"[{dataset_key}] arrivals contain unknown agent_id(s): {sorted(bad_arr_agents)}\", errors)\n",
    "    _require(len(bad_task_agents) == 0, f\"[{dataset_key}] tasks contain unknown agent_id(s): {sorted(bad_task_agents)}\", errors)\n",
    "\n",
    "    # non-negative task numerics\n",
    "    for col in [\"b_mb\",\"rho_cyc_per_mb\",\"c_cycles\",\"mem_mb\"]:\n",
    "        if col in tasks.columns:\n",
    "            _require((tasks[col] >= 0).all(), f\"[{dataset_key}] tasks.{col} has negative values\", errors)\n",
    "\n",
    "    # deadline coherence\n",
    "    if \"has_deadline\" in tasks.columns and \"deadline_s\" in tasks.columns:\n",
    "        bad_deadline = tasks[(tasks[\"has_deadline\"] == 1) & ((tasks[\"deadline_s\"].isna()) | (tasks[\"deadline_s\"] <= 0))]\n",
    "        _require(len(bad_deadline) == 0, f\"[{dataset_key}] tasks with deadline have invalid deadline_s\", errors)\n",
    "\n",
    "    # single Delta / T_slots inside this (episode, scenario)\n",
    "    _require(episodes[\"Delta\"].nunique() == 1, f\"[{dataset_key}] multiple Delta values in episodes\", errors)\n",
    "    _require(episodes[\"T_slots\"].nunique() == 1, f\"[{dataset_key}] multiple T_slots in episodes\", errors)\n",
    "\n",
    "    # arrivals inside range\n",
    "    T_slots = int(episodes[\"T_slots\"].iloc[0])\n",
    "    _require(int(tasks[\"t_arrival_slot\"].max()) <= T_slots - 1,\n",
    "             f\"[{dataset_key}] t_arrival_slot exceeds T_slots-1\", errors)\n",
    "\n",
    "    return errors\n",
    "\n",
    "# ---------- Topology-level validation ----------\n",
    "def validate_one_topology(topology_name: str, topo_entry: dict) -> list:\n",
    "    errors = []\n",
    "    topo = topo_entry.get(\"topology_data\")\n",
    "    meta = topo_entry.get(\"meta_data\")\n",
    "    Mdf  = topo_entry.get(\"connection_matrix\")\n",
    "\n",
    "    _require(isinstance(topo, dict), f\"[{topology_name}] topology_data missing or not a dict\", errors)\n",
    "    _require(isinstance(meta, dict), f\"[{topology_name}] meta_data missing or not a dict\", errors)\n",
    "    _require(isinstance(Mdf,  pd.DataFrame), f\"[{topology_name}] connection_matrix CSV missing or not a DataFrame\", errors)\n",
    "    if errors:\n",
    "        return errors\n",
    "\n",
    "    req_keys = [\n",
    "        \"number_of_servers\",\"private_cpu_capacities\",\"public_cpu_capacities\",\n",
    "        \"cloud_computational_capacity\",\"connection_matrix\",\"time_step\"\n",
    "    ]\n",
    "    for k in req_keys:\n",
    "        _require(k in topo, f\"[{topology_name}] topology.json missing key: {k}\", errors)\n",
    "    if errors:\n",
    "        return errors\n",
    "\n",
    "    K = int(topo[\"number_of_servers\"])\n",
    "    _require(len(topo[\"private_cpu_capacities\"]) == K, f\"[{topology_name}] private_cpu_capacities length != K\", errors)\n",
    "    _require(len(topo[\"public_cpu_capacities\"])  == K, f\"[{topology_name}] public_cpu_capacities length != K\", errors)\n",
    "\n",
    "    Mjson = topo[\"connection_matrix\"]\n",
    "    _require(isinstance(Mjson, list) and len(Mjson) == K and (K == 0 or len(Mjson[0]) == K+1),\n",
    "             f\"[{topology_name}] connection_matrix in JSON must be K x (K+1)\", errors)\n",
    "    _require(Mdf.shape == (K, K+1), f\"[{topology_name}] connection_matrix.csv shape must be K x (K+1)\", errors)\n",
    "\n",
    "    vert_csv = Mdf.iloc[:, K]\n",
    "    _require((vert_csv > 0).all(), f\"[{topology_name}] MEC->Cloud capacities must be > 0\", errors)\n",
    "    horiz_csv = Mdf.iloc[:, :K]\n",
    "    _require((horiz_csv.values >= 0).all(), f\"[{topology_name}] MEC<->MEC capacities contain negatives\", errors)\n",
    "\n",
    "    _require(\"time_step\" in topo, f\"[{topology_name}] missing time_step\", errors)\n",
    "    return errors\n",
    "\n",
    "# ---------- Pairwise validation (dataset <-> topology) ----------\n",
    "def validate_dataset_topology_pair(ep_name: str, scenario: str, ds: dict,\n",
    "                                   topology_name: str, topo_entry: dict) -> list:\n",
    "    \"\"\"\n",
    "    Validate alignment between one (episode, scenario) dataset and one topology.\n",
    "    Ensures Delta == time_step and basic feasibility checks.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    episodes = ds[\"episodes\"]\n",
    "    topo     = topo_entry[\"topology_data\"]\n",
    "    K        = int(topo[\"number_of_servers\"])\n",
    "\n",
    "    # Delta vs time_step\n",
    "    Delta = float(episodes[\"Delta\"].iloc[0])\n",
    "    time_step = float(topo[\"time_step\"])\n",
    "    _require(abs(Delta - time_step) < 1e-9,\n",
    "             f\"[{ep_name}/{scenario} x {topology_name}] Delta ({Delta}) != time_step ({time_step})\", errors)\n",
    "\n",
    "    # Non-negative compute capacities\n",
    "    priv = topo[\"private_cpu_capacities\"]\n",
    "    pub  = topo[\"public_cpu_capacities\"]\n",
    "    cloud = topo[\"cloud_computational_capacity\"]\n",
    "    _require(all(x >= 0 for x in priv) and all(x >= 0 for x in pub) and cloud >= 0,\n",
    "             f\"[{ep_name}/{scenario} x {topology_name}] negative compute capacities detected\", errors)\n",
    "\n",
    "    # Simple agent→MEC mapping (modulo) is within bounds\n",
    "    N_agents = int(episodes[\"N_agents\"].iloc[0])\n",
    "    mapped = [(aid % K) for aid in range(N_agents)] if K > 0 else []\n",
    "    _require(all(0 <= m < K for m in mapped) if mapped else True,\n",
    "             f\"[{ep_name}/{scenario} x {topology_name}] agent->MEC mapping out of bounds\", errors)\n",
    "\n",
    "    return errors\n",
    "\n",
    "# ---------- Episode-level Delta consistency across scenarios ----------\n",
    "def validate_episode_delta_consistency(ep_name: str, ep_dict: dict) -> list:\n",
    "    \"\"\"\n",
    "    Check that all scenarios inside one episode share the same Delta and T_slots.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    deltas = set()\n",
    "    tslots = set()\n",
    "    for scenario, ds in ep_dict.items():\n",
    "        ep_df = ds[\"episodes\"]\n",
    "        if len(ep_df):\n",
    "            deltas.add(float(ep_df[\"Delta\"].iloc[0]))\n",
    "            tslots.add(int(ep_df[\"T_slots\"].iloc[0]))\n",
    "        else:\n",
    "            errors.append(f\"[{ep_name}/{scenario}] episodes.csv is empty\")\n",
    "    if len(deltas) > 1:\n",
    "        errors.append(f\"[{ep_name}] multiple Delta values across scenarios: {sorted(deltas)}\")\n",
    "    if len(tslots) > 1:\n",
    "        errors.append(f\"[{ep_name}] multiple T_slots values across scenarios: {sorted(tslots)}\")\n",
    "    return errors\n",
    "\n",
    "# ---------- Orchestrator over ALL datasets (episode-first) and ALL topologies ----------\n",
    "def validate_everything_episode_first(datasets: dict, topologies: dict) -> dict:\n",
    "    \"\"\"\n",
    "    'datasets' shape:\n",
    "        {\n",
    "          \"ep_000\": {\n",
    "             \"light\":   {\"episodes\": df, \"agents\": df, \"arrivals\": df, \"tasks\": df},\n",
    "             \"moderate\":{...},\n",
    "             \"heavy\":   {...}\n",
    "          },\n",
    "          \"ep_001\": {...}\n",
    "        }\n",
    "    \"\"\"\n",
    "    report = {\"datasets\": {}, \"episodes_consistency\": {}, \"topologies\": {}, \"pairs\": {}}\n",
    "\n",
    "    # 1) Validate each (episode, scenario)\n",
    "    for ep_name, ep_pack in datasets.items():\n",
    "        report[\"datasets\"][ep_name] = {}\n",
    "        for scenario, dpack in ep_pack.items():\n",
    "            key = f\"{ep_name}/{scenario}\"\n",
    "            errs = validate_one_dataset(key, dpack)\n",
    "            report[\"datasets\"][ep_name][scenario] = {\"ok\": len(errs) == 0, \"errors\": errs}\n",
    "\n",
    "    # 2) Episode-level Delta/T_slots consistency across scenarios\n",
    "    for ep_name, ep_pack in datasets.items():\n",
    "        errs = validate_episode_delta_consistency(ep_name, ep_pack)\n",
    "        report[\"episodes_consistency\"][ep_name] = {\"ok\": len(errs) == 0, \"errors\": errs}\n",
    "\n",
    "    # 3) Validate each topology\n",
    "    for tname, tpack in topologies.items():\n",
    "        errs = validate_one_topology(tname, tpack)\n",
    "        report[\"topologies\"][tname] = {\"ok\": len(errs) == 0, \"errors\": errs}\n",
    "\n",
    "    # 4) Pairwise validation for every valid (ep, scenario) × valid topology\n",
    "    for ep_name, ep_pack in datasets.items():\n",
    "        for scenario, dpack in ep_pack.items():\n",
    "            d_ok = report[\"datasets\"][ep_name][scenario][\"ok\"]\n",
    "            ep_ok = report[\"episodes_consistency\"][ep_name][\"ok\"]\n",
    "            for tname, tres in report[\"topologies\"].items():\n",
    "                key = f\"{ep_name}/{scenario}__{tname}\"\n",
    "                if d_ok and ep_ok and tres[\"ok\"]:\n",
    "                    errs = validate_dataset_topology_pair(ep_name, scenario, dpack, tname, topologies[tname])\n",
    "                    report[\"pairs\"][key] = {\"ok\": len(errs) == 0, \"errors\": errs}\n",
    "                else:\n",
    "                    report[\"pairs\"][key] = {\"ok\": False, \"errors\": [\"Skipped due to upstream invalid dataset/episode/topology.\"]}\n",
    "\n",
    "    return report\n",
    "\n",
    "# ---------- Pretty printer ----------\n",
    "def print_validation_report_episode_first(report: dict):\n",
    "    print(\"=== DATASETS (episode/scenario) ===\")\n",
    "    for ep_name, ep_res in report[\"datasets\"].items():\n",
    "        for scenario, info in ep_res.items():\n",
    "            status = \"OK\" if info[\"ok\"] else \"FAIL\"\n",
    "            print(f\"[{status}] {ep_name}/{scenario}\")\n",
    "            for e in info[\"errors\"]:\n",
    "                print(f\"  - {e}\")\n",
    "\n",
    "    print(\"\\n=== EPISODE-LEVEL CONSISTENCY (Delta & T_slots) ===\")\n",
    "    for ep_name, info in report[\"episodes_consistency\"].items():\n",
    "        status = \"OK\" if info[\"ok\"] else \"FAIL\"\n",
    "        print(f\"[{status}] {ep_name}\")\n",
    "        for e in info[\"errors\"]:\n",
    "            print(f\"  - {e}\")\n",
    "\n",
    "    print(\"\\n=== TOPOLOGIES ===\")\n",
    "    for name, info in report[\"topologies\"].items():\n",
    "        status = \"OK\" if info[\"ok\"] else \"FAIL\"\n",
    "        print(f\"[{status}] {name}\")\n",
    "        for e in info[\"errors\"]:\n",
    "            print(f\"  - {e}\")\n",
    "\n",
    "    print(\"\\n=== (EPISODE/SCENARIO) × TOPOLOGY PAIRS ===\")\n",
    "    for key, info in report[\"pairs\"].items():\n",
    "        status = \"OK\" if info[\"ok\"] else \"FAIL\"\n",
    "        print(f\"[{status}] {key}\")\n",
    "        for e in info[\"errors\"]:\n",
    "            print(f\"  - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASETS (episode/scenario) ===\n",
      "[OK] ep_000/heavy\n",
      "[OK] ep_000/light\n",
      "[OK] ep_000/moderate\n",
      "\n",
      "=== EPISODE-LEVEL CONSISTENCY (Delta & T_slots) ===\n",
      "[OK] ep_000\n",
      "\n",
      "=== TOPOLOGIES ===\n",
      "[OK] clustered\n",
      "[OK] full_mesh\n",
      "[OK] sparse_ring\n",
      "\n",
      "=== (EPISODE/SCENARIO) × TOPOLOGY PAIRS ===\n",
      "[OK] ep_000/heavy__clustered\n",
      "[OK] ep_000/heavy__full_mesh\n",
      "[OK] ep_000/heavy__sparse_ring\n",
      "[OK] ep_000/light__clustered\n",
      "[OK] ep_000/light__full_mesh\n",
      "[OK] ep_000/light__sparse_ring\n",
      "[OK] ep_000/moderate__clustered\n",
      "[OK] ep_000/moderate__full_mesh\n",
      "[OK] ep_000/moderate__sparse_ring\n"
     ]
    }
   ],
   "source": [
    "# ---- run the new validator ----\n",
    "report = validate_everything_episode_first(datasets, topologies)\n",
    "print_validation_report_episode_first(report)\n",
    "\n",
    "all_ok = (\n",
    "    all(info[\"ok\"] for ep in report[\"datasets\"].values() for info in ep.values())\n",
    "    and all(info[\"ok\"] for info in report[\"episodes_consistency\"].values())\n",
    "    and all(info[\"ok\"] for info in report[\"topologies\"].values())\n",
    "    and all(info[\"ok\"] for info in report[\"pairs\"].values())\n",
    ")\n",
    "if not all_ok:\n",
    "    raise RuntimeError(\"Validation failed. See printed report for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.3. Units Alignment </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we align units for all dataset episodes and scenarios\n",
    "and run consistency checks against all topologies.\n",
    "- Datasets: use Delta from episodes.csv; add per-slot helpers:\n",
    "    agents.f_local_slot (cycles/slot), tasks.deadline_slots (integer or NaN)\n",
    "    \n",
    "- Topologies: capacities are already per-slot (generator multiplied by Δ);\n",
    "    we only verify time_step == Delta and non-negative capacities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Helpers: safe getters =====\n",
    "def _get_delta(episodes_df: pd.DataFrame) -> float:\n",
    "    # Expect a single Delta value in episodes; take the first row\n",
    "    if \"Delta\" not in episodes_df.columns:\n",
    "        raise ValueError(\"episodes.csv must contain a 'Delta' column.\")\n",
    "    return float(episodes_df[\"Delta\"].iloc[0])\n",
    "\n",
    "def _ensure_numeric_positive(name: str, arr: np.ndarray):\n",
    "    # Basic sanity: finite and no negatives for capacities/links\n",
    "    if not np.isfinite(arr).all():\n",
    "        raise ValueError(f\"{name} contains non-finite values.\")\n",
    "    if (arr < 0).any():\n",
    "        raise ValueError(f\"{name} contains negative values.\")\n",
    "\n",
    "# ===== Alignment: per-dataset (one (episode, scenario) pack) =====\n",
    "def align_units_for_dataset(dataset: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Given one dataset dict {\"episodes\",\"agents\",\"arrivals\",\"tasks\"},\n",
    "    return a copy with aligned/derived columns (per-slot helpers).\n",
    "    \"\"\"\n",
    "    episodes = dataset[\"episodes\"].copy()\n",
    "    agents   = dataset[\"agents\"].copy()\n",
    "    arrivals = dataset[\"arrivals\"].copy()\n",
    "    tasks    = dataset[\"tasks\"].copy()\n",
    "\n",
    "    Delta = _get_delta(episodes)\n",
    "\n",
    "    # Agents: add per-slot compute capacity helper (cycles/slot)\n",
    "    if \"f_local\" not in agents.columns:\n",
    "        raise ValueError(\"agents.csv must contain 'f_local'.\")\n",
    "    agents[\"f_local\"] = agents[\"f_local\"].astype(float)\n",
    "    agents[\"f_local_slot\"] = agents[\"f_local\"] * Delta\n",
    "\n",
    "    # Memory is MB; keep as float\n",
    "    if \"m_local\" in agents.columns:\n",
    "        agents[\"m_local\"] = agents[\"m_local\"].astype(float)\n",
    "\n",
    "    # Tasks: ensure integer arrival slot\n",
    "    if \"t_arrival_slot\" not in tasks.columns:\n",
    "        raise ValueError(\"tasks.csv must contain 't_arrival_slot'.\")\n",
    "    tasks[\"t_arrival_slot\"] = tasks[\"t_arrival_slot\"].astype(int)\n",
    "\n",
    "    # Build deadline_slots = ceil(deadline_s / Delta) when has_deadline == 1, else NaN\n",
    "    if \"has_deadline\" in tasks.columns and \"deadline_s\" in tasks.columns:\n",
    "        def _to_deadline_slots(row):\n",
    "            if int(row[\"has_deadline\"]) == 1 and np.isfinite(row[\"deadline_s\"]):\n",
    "                return int(math.ceil(float(row[\"deadline_s\"]) / Delta))\n",
    "            return np.nan\n",
    "        tasks[\"deadline_slots\"] = tasks.apply(_to_deadline_slots, axis=1)\n",
    "        # Keep as nullable integer when possible\n",
    "        try:\n",
    "            tasks[\"deadline_slots\"] = tasks[\"deadline_slots\"].astype(\"Int64\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Ensure key numeric task fields are floats\n",
    "    for col in [\"b_mb\", \"rho_cyc_per_mb\", \"c_cycles\", \"mem_mb\"]:\n",
    "        if col in tasks.columns:\n",
    "            tasks[col] = tasks[col].astype(float)\n",
    "\n",
    "    return {\n",
    "        \"episodes\": episodes,\n",
    "        \"agents\":   agents,\n",
    "        \"arrivals\": arrivals,\n",
    "        \"tasks\":    tasks,\n",
    "    }\n",
    "\n",
    "# ===== Verification: per-topology against a target Delta =====\n",
    "def verify_topology_units(topology: Dict[str, Any], target_Delta: float) -> Tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Ensure topology capacities are per-slot and consistent with dataset Delta:\n",
    "    - time_step == target_Delta\n",
    "    - shapes are valid (K x (K+1))\n",
    "    - capacities non-negative\n",
    "    Returns (ok, message).\n",
    "    \"\"\"\n",
    "    # time_step check\n",
    "    ts = float(topology.get(\"time_step\", -1.0))\n",
    "    if not np.isclose(ts, target_Delta, atol=1e-9):\n",
    "        return (False, f\"time_step mismatch (topology={ts}, dataset Delta={target_Delta})\")\n",
    "\n",
    "    # K and lists\n",
    "    K = int(topology.get(\"number_of_servers\", -1))\n",
    "    priv = np.array(topology.get(\"private_cpu_capacities\", []), dtype=float)\n",
    "    pub  = np.array(topology.get(\"public_cpu_capacities\", []), dtype=float)\n",
    "    cloud = float(topology.get(\"cloud_computational_capacity\", -1.0))\n",
    "    M = np.array(topology.get(\"connection_matrix\", []), dtype=float)\n",
    "\n",
    "    if K <= 0:\n",
    "        return (False, \"Invalid 'number_of_servers' (K<=0).\")\n",
    "    if priv.shape[0] != K or pub.shape[0] != K:\n",
    "        return (False, \"private/public capacities must have length K.\")\n",
    "    if M.shape != (K, K+1):\n",
    "        return (False, f\"connection_matrix shape must be (K, K+1), got {M.shape}.\")\n",
    "\n",
    "    # Non-negative checks\n",
    "    _ensure_numeric_positive(\"private_cpu_capacities\", priv)\n",
    "    _ensure_numeric_positive(\"public_cpu_capacities\",  pub)\n",
    "    if not np.isfinite(cloud) or cloud < 0:\n",
    "        return (False, \"cloud_computational_capacity must be non-negative and finite.\")\n",
    "    _ensure_numeric_positive(\"connection_matrix\", M)\n",
    "\n",
    "    return (True, \"topology verified (per-slot, consistent).\")\n",
    "\n",
    "# ===== Batch alignment for ALL datasets (episode-first) & ALL topologies =====\n",
    "def align_all_units_episode_first(\n",
    "    datasets_ep_first: Dict[str, Dict[str, Dict[str, pd.DataFrame]]],\n",
    "    topologies_by_name: Dict[str, Dict[str, Any]]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Input 'datasets_ep_first' shape:\n",
    "        {\n",
    "          \"ep_000\": {\n",
    "             \"light\":   {\"episodes\": df, \"agents\": df, \"arrivals\": df, \"tasks\": df},\n",
    "             \"moderate\":{...},\n",
    "             \"heavy\":   {...}\n",
    "          },\n",
    "          \"ep_001\": {...}\n",
    "        }\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          \"datasets_aligned\": { ep_name: { scenario: aligned_pack, ... }, ... },\n",
    "          \"topology_checks\":  { topo_name: { ep_name: { scenario: {ok, message} } } }\n",
    "        }\n",
    "    \"\"\"\n",
    "    out = {\n",
    "        \"datasets_aligned\": {},\n",
    "        \"topology_checks\":  {}\n",
    "    }\n",
    "\n",
    "    # Align datasets (episode/scenario)\n",
    "    for ep_name, ep_pack in datasets_ep_first.items():\n",
    "        out[\"datasets_aligned\"][ep_name] = {}\n",
    "        for scenario, ds in ep_pack.items():\n",
    "            try:\n",
    "                out[\"datasets_aligned\"][ep_name][scenario] = align_units_for_dataset(ds)\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"[{ep_name}/{scenario}] dataset alignment failed: {e}\") from e\n",
    "\n",
    "    # Verify each topology against each (episode, scenario) Delta\n",
    "    for topo_name, topo_bundle in topologies_by_name.items():\n",
    "        topo_obj = topo_bundle.get(\"topology_data\", None)\n",
    "        if not isinstance(topo_obj, dict):\n",
    "            raise RuntimeError(f\"[{topo_name}] 'topology_data' missing or not a dict.\")\n",
    "        out[\"topology_checks\"][topo_name] = {}\n",
    "\n",
    "        for ep_name, ep_pack in out[\"datasets_aligned\"].items():\n",
    "            out[\"topology_checks\"][topo_name][ep_name] = {}\n",
    "            for scenario, aligned in ep_pack.items():\n",
    "                Delta = _get_delta(aligned[\"episodes\"])\n",
    "                ok, msg = verify_topology_units(topo_obj, Delta)\n",
    "                out[\"topology_checks\"][topo_name][ep_name][scenario] = {\"ok\": bool(ok), \"message\": msg}\n",
    "\n",
    "    return out\n",
    "\n",
    "# ===== Pretty printer (episode-first) =====\n",
    "def print_alignment_summary_episode_first(result: Dict[str, Any]):\n",
    "    # Datasets\n",
    "    print(\"=== DATASETS (aligned, episode/scenario) ===\")\n",
    "    for ep_name in sorted(result[\"datasets_aligned\"].keys()):\n",
    "        for scenario in sorted(result[\"datasets_aligned\"][ep_name].keys()):\n",
    "            ds = result[\"datasets_aligned\"][ep_name][scenario]\n",
    "            Delta = _get_delta(ds[\"episodes\"])\n",
    "            n_tasks = len(ds[\"tasks\"])\n",
    "            n_agents = len(ds[\"agents\"])\n",
    "            print(f\"[{ep_name}/{scenario}] Delta={Delta}  tasks={n_tasks}  agents={n_agents}\")\n",
    "\n",
    "    # Topologies\n",
    "    print(\"\\n=== TOPOLOGIES (checks vs each episode/scenario) ===\")\n",
    "    for topo_name, by_ep in result[\"topology_checks\"].items():\n",
    "        print(f\"Topology: {topo_name}\")\n",
    "        for ep_name in sorted(by_ep.keys()):\n",
    "            for scenario in sorted(by_ep[ep_name].keys()):\n",
    "                r = by_ep[ep_name][scenario]\n",
    "                flag = \"OK\" if r[\"ok\"] else \"FAIL\"\n",
    "                print(f\"  - {ep_name}/{scenario}: {flag}  -> {r['message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASETS (aligned, episode/scenario) ===\n",
      "[ep_000/heavy] Delta=1.0  tasks=30636  agents=18\n",
      "[ep_000/light] Delta=1.0  tasks=2113  agents=18\n",
      "[ep_000/moderate] Delta=1.0  tasks=8262  agents=18\n",
      "\n",
      "=== TOPOLOGIES (checks vs each episode/scenario) ===\n",
      "Topology: clustered\n",
      "  - ep_000/heavy: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/light: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/moderate: OK  -> topology verified (per-slot, consistent).\n",
      "Topology: full_mesh\n",
      "  - ep_000/heavy: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/light: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/moderate: OK  -> topology verified (per-slot, consistent).\n",
      "Topology: sparse_ring\n",
      "  - ep_000/heavy: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/light: OK  -> topology verified (per-slot, consistent).\n",
      "  - ep_000/moderate: OK  -> topology verified (per-slot, consistent).\n"
     ]
    }
   ],
   "source": [
    "# ==== Example driver (after your loading step) ====\n",
    "# datasets: episode-first dict\n",
    "# topologies: { \"full_mesh\": {...}, \"clustered\": {...}, \"sparse_ring\": {...} }\n",
    "\n",
    "result_align = align_all_units_episode_first(datasets_ep_first=datasets, topologies_by_name=topologies)\n",
    "print_alignment_summary_episode_first(result_align)\n",
    "\n",
    "# Access aligned data for a specific episode/scenario:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "aligned_light_ep0 = result_align[\"datasets_aligned\"][\"ep_000\"][\"light\"]\n",
    "agents_ep0_light  = aligned_light_ep0[\"agents\"]   # has f_local_slot\n",
    "tasks_ep0_light   = aligned_light_ep0[\"tasks\"]    # has deadline_slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.4. Build Scenario–Topology Pairs </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, all datasets are paired with all topologies (Cartesian product). Each pair is checked for matching time parameters, then a basic bundle is created for further enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _delta_from_episodes(episodes_df: pd.DataFrame) -> float:\n",
    "    \"\"\"Extract a single Delta value from episodes table.\"\"\"\n",
    "    if \"Delta\" not in episodes_df.columns:\n",
    "        raise ValueError(\"episodes.csv must contain 'Delta'.\")\n",
    "    return float(episodes_df[\"Delta\"].iloc[0])\n",
    "\n",
    "def _topology_time_step(topo_json: Dict[str, Any]) -> float:\n",
    "    \"\"\"Extract the topology time_step.\"\"\"\n",
    "    ts = topo_json.get(\"time_step\", None)\n",
    "    if ts is None:\n",
    "        raise ValueError(\"topology.json must contain 'time_step'.\")\n",
    "    return float(ts)\n",
    "\n",
    "def build_topology_episode_pairs(\n",
    "    datasets_ep_first: Dict[str, Dict[str, Dict[str, pd.DataFrame]]],\n",
    "    topologies: Dict[str, Dict[str, Any]],\n",
    "    strict_delta_match: bool = True\n",
    ") -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Build pairs between every topology and every (episode, scenario) dataset.\n",
    "    If strict_delta_match is True, any mismatch between dataset Delta and topology time_step raises an error.\n",
    "    \"\"\"\n",
    "    pairs_by_topology: Dict[str, Dict[str, Dict[str, Any]]] = {}\n",
    "\n",
    "    # Iterate topologies first (topology-centric)\n",
    "    for topo_name, topo_bundle in topologies.items():\n",
    "        topo_data = topo_bundle.get(\"topology_data\", None)\n",
    "        meta_data = topo_bundle.get(\"meta_data\", None)\n",
    "        cm_df     = topo_bundle.get(\"connection_matrix\", None)\n",
    "\n",
    "        if not isinstance(topo_data, dict):\n",
    "            raise ValueError(f\"[{topo_name}] topology_data missing or not a dict.\")\n",
    "        if cm_df is None:\n",
    "            raise ValueError(f\"[{topo_name}] connection_matrix DataFrame is missing.\")\n",
    "\n",
    "        # Validate K and connection matrix shape\n",
    "        K = int(topo_data.get(\"number_of_servers\", -1))\n",
    "        if K <= 0:\n",
    "            raise ValueError(f\"[{topo_name}] invalid 'number_of_servers' in topology.json\")\n",
    "        if not (cm_df.shape[0] == K and cm_df.shape[1] == K + 1):\n",
    "            raise ValueError(\n",
    "                f\"[{topo_name}] connection_matrix shape must be (K, K+1); got {cm_df.shape}\"\n",
    "            )\n",
    "\n",
    "        topo_ts = _topology_time_step(topo_data)\n",
    "\n",
    "        # Prepare container for this topology\n",
    "        if topo_name not in pairs_by_topology:\n",
    "            pairs_by_topology[topo_name] = {}\n",
    "\n",
    "        # Compare with every (episode, scenario)\n",
    "        for ep_name, scenarios in datasets_ep_first.items():\n",
    "            if ep_name not in pairs_by_topology[topo_name]:\n",
    "                pairs_by_topology[topo_name][ep_name] = {}\n",
    "\n",
    "            for scen_name, ds in scenarios.items():\n",
    "                ds_Delta = _delta_from_episodes(ds[\"episodes\"])\n",
    "                delta_ok = bool(np.isclose(ds_Delta, topo_ts, atol=1e-12))\n",
    "                msg = \"OK\" if delta_ok else (\n",
    "                    f\"time_step mismatch (dataset Delta={ds_Delta}, topology time_step={topo_ts})\"\n",
    "                )\n",
    "                if (not delta_ok) and strict_delta_match:\n",
    "                    raise ValueError(f\"[{topo_name} × {ep_name}/{scen_name}] {msg}\")\n",
    "\n",
    "                # Store bundle\n",
    "                pairs_by_topology[topo_name][ep_name][scen_name] = {\n",
    "                    \"scenario\": scen_name,\n",
    "                    \"episode\": ep_name,\n",
    "                    \"topology\": topo_name,\n",
    "                    \"Delta\": ds_Delta,\n",
    "                    \"K\": K,\n",
    "                    \"dataset\": ds,\n",
    "                    \"topology_data\": topo_data,\n",
    "                    \"topology_meta_data\": meta_data,\n",
    "                    \"connection_matrix_df\": cm_df,\n",
    "                    \"checks\": {\"delta_match\": delta_ok, \"message\": msg}\n",
    "                }\n",
    "\n",
    "    return pairs_by_topology\n",
    "\n",
    "def print_pairs_summary_topology_first_ep(\n",
    "    pairs_by_topology: Dict[str, Dict[str, Dict[str, Any]]]\n",
    ") -> None:\n",
    "    \"\"\"Pretty-print summary as topology → episode → scenario.\"\"\"\n",
    "    print(\"=== TOPOLOGY × EPISODE × SCENARIO ===\")\n",
    "    for topo_name, by_ep in pairs_by_topology.items():\n",
    "        print(f\"[TOPOLOGY] {topo_name}\")\n",
    "        for ep_name in sorted(by_ep.keys()):\n",
    "            print(f\"  ├─ Episode: {ep_name}\")\n",
    "            scen_map = by_ep[ep_name]\n",
    "            for scen_name in sorted(scen_map.keys()):\n",
    "                bundle = scen_map[scen_name]\n",
    "                flag  = \"OK\" if bundle[\"checks\"][\"delta_match\"] else \"FAIL\"\n",
    "                K     = bundle[\"K\"]\n",
    "                Delta = bundle[\"Delta\"]\n",
    "                msg   = bundle[\"checks\"][\"message\"]\n",
    "                print(f\"  │    - [{flag}] {scen_name:9s} | K={K:2d}  Δ={Delta:g}  -> {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOPOLOGY × EPISODE × SCENARIO ===\n",
      "[TOPOLOGY] clustered\n",
      "  ├─ Episode: ep_000\n",
      "  │    - [OK] heavy     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] light     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] moderate  | K=18  Δ=1  -> OK\n",
      "[TOPOLOGY] full_mesh\n",
      "  ├─ Episode: ep_000\n",
      "  │    - [OK] heavy     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] light     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] moderate  | K=18  Δ=1  -> OK\n",
      "[TOPOLOGY] sparse_ring\n",
      "  ├─ Episode: ep_000\n",
      "  │    - [OK] heavy     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] light     | K=18  Δ=1  -> OK\n",
      "  │    - [OK] moderate  | K=18  Δ=1  -> OK\n"
     ]
    }
   ],
   "source": [
    "# --- Example driver (with your current variables) ---\n",
    "pairs_by_topology = build_topology_episode_pairs(\n",
    "    datasets_ep_first=datasets,   # episode-first dict you already built\n",
    "    topologies=topologies,\n",
    "    strict_delta_match=True\n",
    ")\n",
    "\n",
    "print_pairs_summary_topology_first_ep(pairs_by_topology)\n",
    "\n",
    "# Access examples:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "pairs_by_topology[\"full_mesh\"][\"ep_000\"][\"light\"][\"dataset\"][\"tasks\"]\n",
    "pairs_by_topology[\"clustered\"][\"ep_000\"][\"heavy\"][\"connection_matrix_df\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.5. Agent→MEC mapping (for all pairs) </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent → MEC Mapping assigns each agent to a specific MEC server.\n",
    "This creates a fixed mec_id for every agent (e.g., agent_id % K), which determines where its tasks are initially queued and processed in the MDP environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_agents_to_mecs(pairs_by_topology):\n",
    "    \"\"\"\n",
    "    Adds agent→MEC mapping to each (topology / ep / scenario) bundle.\n",
    "    - Rule: mec_id = agent_id % K\n",
    "    - Writes:\n",
    "        bundle[\"agent_to_mec\"]                  (pd.Series, index=agent_id)\n",
    "        bundle[\"dataset\"][\"agents\"][\"mec_id\"]   (added column)\n",
    "    \"\"\"\n",
    "    for topo_name, by_ep in pairs_by_topology.items():\n",
    "        for ep_name, by_scen in by_ep.items():\n",
    "            for scen_name, bundle in by_scen.items():\n",
    "\n",
    "                ds = bundle[\"dataset\"]\n",
    "                agents = ds[\"agents\"].copy()\n",
    "                K = int(bundle[\"K\"])\n",
    "\n",
    "                if \"agent_id\" not in agents.columns:\n",
    "                    raise ValueError(f\"[{topo_name}/{ep_name}/{scen_name}] agents.csv missing 'agent_id'.\")\n",
    "\n",
    "                # Ensure agent_id is contiguous & sorted (0..N_agents-1)\n",
    "                agents = agents.sort_values(\"agent_id\").reset_index(drop=True)\n",
    "                expected_n = int(bundle[\"dataset\"][\"episodes\"][\"N_agents\"].iloc[0])\n",
    "                if agents[\"agent_id\"].min() != 0 or agents[\"agent_id\"].max() != expected_n - 1:\n",
    "                    raise ValueError(f\"[{topo_name}/{ep_name}/{scen_name}] agent_id range not 0..N_agents-1.\")\n",
    "\n",
    "                # Mapping\n",
    "                mec_ids = (agents[\"agent_id\"].astype(int) % K).astype(int)\n",
    "                agents[\"mec_id\"] = mec_ids\n",
    "\n",
    "                # Store: dataset copy + Series with index=agent_id\n",
    "                ds[\"agents\"] = agents\n",
    "                bundle[\"agent_to_mec\"] = pd.Series(\n",
    "                    data=mec_ids.values,\n",
    "                    index=agents[\"agent_id\"].values,\n",
    "                    name=\"mec_id\"\n",
    "                )\n",
    "\n",
    "    return pairs_by_topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>f_local</th>\n",
       "      <th>m_local</th>\n",
       "      <th>lam_sec</th>\n",
       "      <th>mec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>0.708673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>0.234989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>0.228174</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>0.310369</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>0.548990</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id       f_local      m_local   lam_sec  mec_id\n",
       "0         0  1.741183e+09  5713.849721  0.708673       0\n",
       "1         1  1.352326e+09  4566.428755  0.234989       1\n",
       "2         2  1.726668e+09  5815.120004  0.228174       2\n",
       "3         3  1.543616e+09  3539.850245  0.310369       3\n",
       "4         4  1.130883e+09  4161.367769  0.548990       4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply mapping\n",
    "pairs_by_topology = assign_agents_to_mecs(pairs_by_topology)\n",
    "\n",
    "# Quick sanity peek\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "pairs_by_topology[\"clustered\"][\"ep_000\"][\"heavy\"][\"dataset\"][\"agents\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.6. Environment Configuration </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we build a unified env_config for each scenario–topology pair.\n",
    "It bundles all required information for the MDP/RL environment—such as compute capacities, the Agent→MEC mapping, connection matrix, initial queue states, and action/state specifications—into a single consistent configuration used by the RL training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_core_from_bundle(bundle: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    required = [\"dataset\", \"topology_data\", \"connection_matrix_df\", \"Delta\", \"K\"]\n",
    "    for k in required:\n",
    "        if k not in bundle:\n",
    "            raise ValueError(f\"Bundle missing required key: '{k}'\")\n",
    "\n",
    "    ds   = bundle[\"dataset\"]\n",
    "    topo = bundle[\"topology_data\"]\n",
    "    Mdf  = bundle[\"connection_matrix_df\"]\n",
    "\n",
    "    private_cpu = np.asarray(topo[\"private_cpu_capacities\"], dtype=float)\n",
    "    public_cpu  = np.asarray(topo[\"public_cpu_capacities\"],  dtype=float)\n",
    "    cloud_cpu   = float(topo[\"cloud_computational_capacity\"])\n",
    "    M           = Mdf.to_numpy(dtype=float)  # (K, K+1), last col MEC→Cloud (MB/slot)\n",
    "\n",
    "    return dict(\n",
    "        Delta=float(bundle[\"Delta\"]),\n",
    "        K=int(bundle[\"K\"]),\n",
    "        episodes=ds[\"episodes\"],\n",
    "        agents=ds[\"agents\"],\n",
    "        arrivals=ds[\"arrivals\"],\n",
    "        tasks=ds[\"tasks\"],\n",
    "        private_cpu=private_cpu,\n",
    "        public_cpu=public_cpu,\n",
    "        cloud_cpu=cloud_cpu,\n",
    "        connection_matrix=M,\n",
    "        topology_type=topo.get(\"topology_type\", \"unknown\"),\n",
    "    )\n",
    "\n",
    "def _build_default_queues(K: int) -> Dict[str, np.ndarray]:\n",
    "    return {\n",
    "        \"mec_local_cycles\":   np.zeros(K, dtype=float),\n",
    "        \"mec_public_cycles\":  np.zeros(K, dtype=float),\n",
    "        \"mec_bytes_in_transit\": np.zeros(K, dtype=float),\n",
    "        \"cloud_cycles\":       np.array([0.0], dtype=float),\n",
    "    }\n",
    "\n",
    "def _derive_action_space() -> Dict[str, Any]:\n",
    "    return {\"type\": \"discrete\", \"n\": 3, \"labels\": {0: \"LOCAL\", 1: \"MEC\", 2: \"CLOUD\"}}\n",
    "\n",
    "def _derive_state_spec(K: int) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"components\": {\n",
    "            \"queues\": {\n",
    "                \"mec_local_cycles\":  {\"shape\": (K,),   \"dtype\": \"float\"},\n",
    "                \"mec_public_cycles\": {\"shape\": (K,),   \"dtype\": \"float\"},\n",
    "                \"cloud_cycles\":      {\"shape\": (1,),   \"dtype\": \"float\"},\n",
    "            },\n",
    "            \"links\": {\n",
    "                \"connection_matrix\": {\"shape\": (K, K+1), \"dtype\": \"float\"},\n",
    "            },\n",
    "            \"capacities\": {\n",
    "                \"private_cpu\": {\"shape\": (K,), \"dtype\": \"float\"},\n",
    "                \"public_cpu\":  {\"shape\": (K,), \"dtype\": \"float\"},\n",
    "                \"cloud_cpu\":   {\"shape\": (1,), \"dtype\": \"float\"},\n",
    "            }\n",
    "        },\n",
    "        \"note\": \"Declarative spec; tensor assembly happens in the Env at each step.\"\n",
    "    }\n",
    "\n",
    "def build_env_config_for_bundle(bundle: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    core = _extract_core_from_bundle(bundle)\n",
    "\n",
    "    if \"agent_to_mec\" not in bundle:\n",
    "        raise ValueError(\"Bundle has no 'agent_to_mec' mapping. Run Stage 5 first.\")\n",
    "\n",
    "    agent_to_mec = bundle[\"agent_to_mec\"]\n",
    "    if isinstance(agent_to_mec, pd.Series):\n",
    "        # reorder by agent_id if needed\n",
    "        if agent_to_mec.index.name != \"agent_id\":\n",
    "            agent_to_mec.index.name = \"agent_id\"\n",
    "        idx = core[\"agents\"].sort_values(\"agent_id\")[\"agent_id\"].to_numpy()\n",
    "        agent_to_mec = agent_to_mec.reindex(idx)\n",
    "        agent_to_mec_arr = agent_to_mec.to_numpy(dtype=int)\n",
    "    else:\n",
    "        agent_to_mec_arr = np.asarray(agent_to_mec, dtype=int)\n",
    "\n",
    "    N_agents = int(core[\"episodes\"][\"N_agents\"].iloc[0])\n",
    "    if len(agent_to_mec_arr) != N_agents:\n",
    "        raise ValueError(f\"agent_to_mec length ({len(agent_to_mec_arr)}) != N_agents ({N_agents}).\")\n",
    "\n",
    "    queues_init  = _build_default_queues(core[\"K\"])\n",
    "    action_space = _derive_action_space()\n",
    "    state_spec   = _derive_state_spec(core[\"K\"])\n",
    "\n",
    "    env_config = {\n",
    "        \"Delta\": core[\"Delta\"],\n",
    "        \"K\": core[\"K\"],\n",
    "        \"topology_type\": core[\"topology_type\"],\n",
    "        \"connection_matrix\": core[\"connection_matrix\"],\n",
    "\n",
    "        \"private_cpu\": core[\"private_cpu\"],\n",
    "        \"public_cpu\":  core[\"public_cpu\"],\n",
    "        \"cloud_cpu\":   core[\"cloud_cpu\"],\n",
    "\n",
    "        \"N_agents\": N_agents,\n",
    "        \"agent_to_mec\": agent_to_mec_arr,\n",
    "\n",
    "        # aligned dataframes\n",
    "        \"episodes\": core[\"episodes\"],\n",
    "        \"agents\":   core[\"agents\"],\n",
    "        \"arrivals\": core[\"arrivals\"],\n",
    "        \"tasks\":    core[\"tasks\"],\n",
    "\n",
    "        \"queues_initial\": queues_init,\n",
    "        \"action_space\": action_space,\n",
    "        \"state_spec\": state_spec,\n",
    "\n",
    "        \"checks\": bundle.get(\"checks\", {\"delta_match\": True, \"message\": \"n/a\"}),\n",
    "    }\n",
    "    return env_config\n",
    "\n",
    "def build_all_env_configs(\n",
    "    pairs_by_topology: Dict[str, Dict[str, Dict[str, Any]]]\n",
    ") -> Dict[str, Dict[str, Dict[str, Dict[str, Any]]]]:\n",
    "    \"\"\"\n",
    "    Build env_config for every (topology / episode / scenario) bundle.\n",
    "\n",
    "    Desired output shape (EPISODE-first):\n",
    "        env_configs[episode][topology][scenario] = env_config\n",
    "\n",
    "    So you can access:\n",
    "        env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"agent_to_mec\"]\n",
    "    \"\"\"\n",
    "    out: Dict[str, Dict[str, Dict[str, Dict[str, Any]]]] = {}\n",
    "    # pairs_by_topology: topo -> ep -> scen -> bundle\n",
    "    for topo_name, by_ep in pairs_by_topology.items():\n",
    "        for ep_name, by_scen in by_ep.items():\n",
    "            # ensure episode level exists\n",
    "            if ep_name not in out:\n",
    "                out[ep_name] = {}\n",
    "            # ensure topology level under this episode exists\n",
    "            if topo_name not in out[ep_name]:\n",
    "                out[ep_name][topo_name] = {}\n",
    "            for scen_name, bundle in by_scen.items():\n",
    "                if \"agent_to_mec\" not in bundle:\n",
    "                    raise RuntimeError(\n",
    "                        f\"[{topo_name}/{ep_name}/{scen_name}] missing 'agent_to_mec'. Run Stage 5 first.\"\n",
    "                    )\n",
    "                env_cfg = build_env_config_for_bundle(bundle)\n",
    "                out[ep_name][topo_name][scen_name] = env_cfg\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build\n",
    "env_configs = build_all_env_configs(pairs_by_topology)\n",
    "\n",
    "# Example access:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"agent_to_mec\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.7. Sanity Checks </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we verify that each env_config is internally consistent (queue shapes, capacities, agent→MEC mapping, and connection matrix are valid and ready for simulation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]   ep_000/clustered/heavy\n",
      "[OK]   ep_000/clustered/light\n",
      "[OK]   ep_000/clustered/moderate\n",
      "[OK]   ep_000/full_mesh/heavy\n",
      "[OK]   ep_000/full_mesh/light\n",
      "[OK]   ep_000/full_mesh/moderate\n",
      "[OK]   ep_000/sparse_ring/heavy\n",
      "[OK]   ep_000/sparse_ring/light\n",
      "[OK]   ep_000/sparse_ring/moderate\n"
     ]
    }
   ],
   "source": [
    "def sanity_check_env_config(env_config):\n",
    "    errors = []\n",
    "\n",
    "    # 1) Agent → MEC alignment\n",
    "    N_agents = env_config[\"N_agents\"]\n",
    "    if len(env_config[\"agent_to_mec\"]) != N_agents:\n",
    "        errors.append(\"Length of agent_to_mec does not match N_agents.\")\n",
    "\n",
    "    # 2) Queue initial state shapes\n",
    "    K = env_config[\"K\"]\n",
    "    q = env_config[\"queues_initial\"]\n",
    "    if q[\"mec_local_cycles\"].shape != (K,):\n",
    "        errors.append(\"mec_local_cycles queue shape mismatch.\")\n",
    "    if q[\"mec_public_cycles\"].shape != (K,):\n",
    "        errors.append(\"mec_public_cycles queue shape mismatch.\")\n",
    "    if q[\"mec_bytes_in_transit\"].shape != (K,):\n",
    "        errors.append(\"mec_bytes_in_transit queue shape mismatch.\")\n",
    "    if q[\"cloud_cycles\"].shape != (1,):\n",
    "        errors.append(\"cloud_cycles shape mismatch (should be (1,)).\")\n",
    "\n",
    "    # 3) Non-negative compute capacities\n",
    "    if (env_config[\"private_cpu\"] < 0).any():\n",
    "        errors.append(\"private_cpu has negative values.\")\n",
    "    if (env_config[\"public_cpu\"] < 0).any():\n",
    "        errors.append(\"public_cpu has negative values.\")\n",
    "    if env_config[\"cloud_cpu\"] < 0:\n",
    "        errors.append(\"cloud_cpu is negative.\")\n",
    "\n",
    "    # 4) Connection matrix dimension (K x K+1)\n",
    "    M = env_config[\"connection_matrix\"]\n",
    "    if M.shape != (K, K+1):\n",
    "        errors.append(\"connection_matrix shape mismatch.\")\n",
    "\n",
    "    # 5) Action space correctness\n",
    "    if env_config[\"action_space\"][\"type\"] != \"discrete\":\n",
    "        errors.append(\"Action space must be discrete (LOCAL/MEC/CLOUD).\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "def sanity_check_all(env_configs):\n",
    "    for topo_name, by_ep in env_configs.items():\n",
    "        for ep_name, by_scen in by_ep.items():\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                errs = sanity_check_env_config(env_cfg)\n",
    "                if errs:\n",
    "                    print(f\"[FAIL] {topo_name}/{ep_name}/{scen_name}:\")\n",
    "                    for e in errs:\n",
    "                        print(\"   -\", e)\n",
    "                else:\n",
    "                    print(f\"[OK]   {topo_name}/{ep_name}/{scen_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ep_000': {'clustered': {'heavy': {'Delta': 1.0,\n",
       "    'K': 18,\n",
       "    'topology_type': 'clustered',\n",
       "    'connection_matrix': array([[  0.        ,   9.79880061,  11.95829539,  11.47040438,\n",
       "              9.98019544,   8.81405007,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  98.91279982],\n",
       "           [  9.79880061,   0.        ,   8.37514324,  11.53560011,\n",
       "             10.70258438,   9.13689312,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 104.60920208],\n",
       "           [ 11.95829539,   8.37514324,   0.        ,   8.81463191,\n",
       "              9.63771407,   9.17070042,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  92.05534806],\n",
       "           [ 11.47040438,  11.53560011,   8.81463191,   0.        ,\n",
       "             10.37705391,  11.92025208,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  84.85166372],\n",
       "           [  9.98019544,  10.70258438,   9.63771407,  10.37705391,\n",
       "              0.        ,   8.10538324,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  99.07630097],\n",
       "           [  8.81405007,   9.13689312,   9.17070042,  11.92025208,\n",
       "              8.10538324,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 115.07927911],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   9.84469022,\n",
       "              9.56656784,  11.01158338,  10.13220601,  11.73176121,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 115.8763706 ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   9.84469022,   0.        ,\n",
       "              8.17265482,  11.31725016,   9.94433007,  11.69899488,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  85.49730491],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   9.56656784,   8.17265482,\n",
       "              0.        ,  11.9192718 ,   9.16293193,  11.22074688,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 104.13111015],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  11.01158338,  11.31725016,\n",
       "             11.9192718 ,   0.        ,  11.8680001 ,  11.39378515,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  87.20532265],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  10.13220601,   9.94433007,\n",
       "              9.16293193,  11.8680001 ,   0.        ,   9.54873479,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  98.89380626],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  11.73176121,  11.69899488,\n",
       "             11.22074688,  11.39378515,   9.54873479,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 100.16242881],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   8.57308973,  10.15563321,  11.20259578,\n",
       "             10.69123291,  11.43912945,  94.68338717],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              8.57308973,   0.        ,  10.79553972,   9.38248576,\n",
       "              8.15651517,  10.10895365,  86.2148807 ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             10.15563321,  10.79553972,   0.        ,   8.18342325,\n",
       "              9.05546058,   8.85786558, 100.51802149],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             11.20259578,   9.38248576,   8.18342325,   0.        ,\n",
       "             10.92203111,   8.7775075 ,  85.56329834],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             10.69123291,   8.15651517,   9.05546058,  10.92203111,\n",
       "              0.        ,  11.48804542, 109.44902762],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             11.43912945,  10.10895365,   8.85786558,   8.7775075 ,\n",
       "             11.48804542,   0.        , 119.21419244]]),\n",
       "    'private_cpu': array([1.41702651e+09, 1.46583552e+09, 1.40029615e+09, 1.21986312e+09,\n",
       "           1.27037663e+09, 1.34801953e+09, 1.78616129e+09, 1.38093201e+09,\n",
       "           1.73968038e+09, 1.60615170e+09, 1.72279202e+09, 1.45211969e+09,\n",
       "           1.57532372e+09, 1.67517605e+09, 1.46526924e+09, 1.56574374e+09,\n",
       "           1.71525983e+09, 1.22583243e+09]),\n",
       "    'public_cpu': array([7.68946447e+08, 7.53418541e+08, 7.02715948e+08, 5.45197669e+08,\n",
       "           6.70994513e+08, 6.80525152e+08, 8.11159072e+08, 7.82943570e+08,\n",
       "           5.01997672e+08, 6.85198792e+08, 8.22519853e+08, 7.16138691e+08,\n",
       "           8.22355072e+08, 5.56428866e+08, 8.05978940e+08, 7.90274918e+08,\n",
       "           6.02437544e+08, 7.09495765e+08]),\n",
       "    'cloud_cpu': 30000000000.0,\n",
       "    'N_agents': 18,\n",
       "    'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17]),\n",
       "    'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "    0    heavy           0    1.0     3600    1.0        18   345,\n",
       "    'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
       "    0          0  1.741183e+09  5713.849721  0.708673       0\n",
       "    1          1  1.352326e+09  4566.428755  0.234989       1\n",
       "    2          2  1.726668e+09  5815.120004  0.228174       2\n",
       "    3          3  1.543616e+09  3539.850245  0.310369       3\n",
       "    4          4  1.130883e+09  4161.367769  0.548990       4\n",
       "    5          5  1.761336e+09  7349.509397  0.427498       5\n",
       "    6          6  1.093196e+09  6389.821853  0.733849       6\n",
       "    7          7  1.022066e+09  5354.805771  0.492160       7\n",
       "    8          8  1.280853e+09  3931.170813  0.647444       8\n",
       "    9          9  1.260889e+09  5133.304392  0.434945       9\n",
       "    10        10  8.077840e+08  6774.364061  0.696332      10\n",
       "    11        11  1.252718e+09  5907.761753  0.250139      11\n",
       "    12        12  1.849537e+09  4251.816941  0.275633      12\n",
       "    13        13  2.013685e+09  3452.486291  0.387815      13\n",
       "    14        14  1.566043e+09  6514.168780  0.410745      14\n",
       "    15        15  1.573528e+09  7018.517023  0.746995      15\n",
       "    16        16  1.386095e+09  6122.347442  0.414992      16\n",
       "    17        17  1.604826e+09  3449.292167  0.516951      17,\n",
       "    'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "    0        heavy           0       0     0.0         0        0\n",
       "    1        heavy           0       0     0.0         1        1\n",
       "    2        heavy           0       0     0.0         4        2\n",
       "    3        heavy           0       0     0.0         7        3\n",
       "    4        heavy           0       0     0.0        10        4\n",
       "    ...        ...         ...     ...     ...       ...      ...\n",
       "    30631    heavy           0    3599  3599.0         5    30631\n",
       "    30632    heavy           0    3599  3599.0         6    30632\n",
       "    30633    heavy           0    3599  3599.0         6    30633\n",
       "    30634    heavy           0    3599  3599.0         7    30634\n",
       "    30635    heavy           0    3599  3599.0         7    30635\n",
       "    \n",
       "    [30636 rows x 6 columns],\n",
       "    'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "    0        heavy           0        0         0               0             0.0   \n",
       "    1        heavy           0        1         1               0             0.0   \n",
       "    2        heavy           0        2         4               0             0.0   \n",
       "    3        heavy           0        3         7               0             0.0   \n",
       "    4        heavy           0        4        10               0             0.0   \n",
       "    ...        ...         ...      ...       ...             ...             ...   \n",
       "    30631    heavy           0    30631         5            3599          3599.0   \n",
       "    30632    heavy           0    30632         6            3599          3599.0   \n",
       "    30633    heavy           0    30633         6            3599          3599.0   \n",
       "    30634    heavy           0    30634         7            3599          3599.0   \n",
       "    30635    heavy           0    30635         7            3599          3599.0   \n",
       "    \n",
       "                b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "    0       7.202096    9.727147e+08  7.005585e+09   66.611010   sensor   \n",
       "    1       5.479984    1.314973e+09  7.206031e+09   77.928800    image   \n",
       "    2       8.421977    2.500222e+09  2.105681e+10   72.966446     text   \n",
       "    3       6.324986    1.779582e+09  1.125583e+10   56.492900   sensor   \n",
       "    4      11.473269    1.087572e+09  1.247800e+10   73.389854   sensor   \n",
       "    ...          ...             ...           ...         ...      ...   \n",
       "    30631   6.238504    1.090296e+09  6.801814e+09   69.218260    video   \n",
       "    30632   3.289880    1.599958e+09  5.263669e+09   39.210260   sensor   \n",
       "    30633   6.192005    8.322764e+08  5.153459e+09   73.052900   sensor   \n",
       "    30634   3.244716    1.627807e+09  5.281771e+09  103.576775    image   \n",
       "    30635   1.736996    2.141823e+09  3.720338e+09   92.836210     text   \n",
       "    \n",
       "           has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "    0                 1    0.800726       0.800726           0     0.000000   \n",
       "    1                 1    0.615113       0.615113           0     0.000000   \n",
       "    2                 1    0.323007       0.323007           1     0.539704   \n",
       "    3                 1    0.481587       0.481587           0     0.000000   \n",
       "    4                 1    0.594564       0.594564           0     0.000000   \n",
       "    ...             ...         ...            ...         ...          ...   \n",
       "    30631             1    0.525271    3599.525400           1     0.605597   \n",
       "    30632             0         NaN            NaN           0     0.000000   \n",
       "    30633             0         NaN            NaN           1     0.566783   \n",
       "    30634             0         NaN            NaN           1     0.706580   \n",
       "    30635             1    0.763454    3599.763400           0     0.000000   \n",
       "    \n",
       "          action_space_hint  \n",
       "    0              discrete  \n",
       "    1              discrete  \n",
       "    2            continuous  \n",
       "    3              discrete  \n",
       "    4              discrete  \n",
       "    ...                 ...  \n",
       "    30631        continuous  \n",
       "    30632          discrete  \n",
       "    30633        continuous  \n",
       "    30634        continuous  \n",
       "    30635          discrete  \n",
       "    \n",
       "    [30636 rows x 17 columns],\n",
       "    'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'cloud_cycles': array([0.])},\n",
       "    'action_space': {'type': 'discrete',\n",
       "     'n': 3,\n",
       "     'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}},\n",
       "    'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,),\n",
       "        'dtype': 'float'},\n",
       "       'mec_public_cycles': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cycles': {'shape': (1,), 'dtype': 'float'}},\n",
       "      'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}},\n",
       "      'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'public_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}},\n",
       "     'note': 'Declarative spec; tensor assembly happens in the Env at each step.'},\n",
       "    'checks': {'delta_match': True, 'message': 'OK'}},\n",
       "   'light': {'Delta': 1.0,\n",
       "    'K': 18,\n",
       "    'topology_type': 'clustered',\n",
       "    'connection_matrix': array([[  0.        ,   9.79880061,  11.95829539,  11.47040438,\n",
       "              9.98019544,   8.81405007,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  98.91279982],\n",
       "           [  9.79880061,   0.        ,   8.37514324,  11.53560011,\n",
       "             10.70258438,   9.13689312,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 104.60920208],\n",
       "           [ 11.95829539,   8.37514324,   0.        ,   8.81463191,\n",
       "              9.63771407,   9.17070042,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  92.05534806],\n",
       "           [ 11.47040438,  11.53560011,   8.81463191,   0.        ,\n",
       "             10.37705391,  11.92025208,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  84.85166372],\n",
       "           [  9.98019544,  10.70258438,   9.63771407,  10.37705391,\n",
       "              0.        ,   8.10538324,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  99.07630097],\n",
       "           [  8.81405007,   9.13689312,   9.17070042,  11.92025208,\n",
       "              8.10538324,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 115.07927911],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   9.84469022,\n",
       "              9.56656784,  11.01158338,  10.13220601,  11.73176121,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 115.8763706 ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   9.84469022,   0.        ,\n",
       "              8.17265482,  11.31725016,   9.94433007,  11.69899488,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  85.49730491],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   9.56656784,   8.17265482,\n",
       "              0.        ,  11.9192718 ,   9.16293193,  11.22074688,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 104.13111015],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  11.01158338,  11.31725016,\n",
       "             11.9192718 ,   0.        ,  11.8680001 ,  11.39378515,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  87.20532265],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  10.13220601,   9.94433007,\n",
       "              9.16293193,  11.8680001 ,   0.        ,   9.54873479,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  98.89380626],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  11.73176121,  11.69899488,\n",
       "             11.22074688,  11.39378515,   9.54873479,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 100.16242881],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   8.57308973,  10.15563321,  11.20259578,\n",
       "             10.69123291,  11.43912945,  94.68338717],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              8.57308973,   0.        ,  10.79553972,   9.38248576,\n",
       "              8.15651517,  10.10895365,  86.2148807 ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             10.15563321,  10.79553972,   0.        ,   8.18342325,\n",
       "              9.05546058,   8.85786558, 100.51802149],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             11.20259578,   9.38248576,   8.18342325,   0.        ,\n",
       "             10.92203111,   8.7775075 ,  85.56329834],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             10.69123291,   8.15651517,   9.05546058,  10.92203111,\n",
       "              0.        ,  11.48804542, 109.44902762],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             11.43912945,  10.10895365,   8.85786558,   8.7775075 ,\n",
       "             11.48804542,   0.        , 119.21419244]]),\n",
       "    'private_cpu': array([1.41702651e+09, 1.46583552e+09, 1.40029615e+09, 1.21986312e+09,\n",
       "           1.27037663e+09, 1.34801953e+09, 1.78616129e+09, 1.38093201e+09,\n",
       "           1.73968038e+09, 1.60615170e+09, 1.72279202e+09, 1.45211969e+09,\n",
       "           1.57532372e+09, 1.67517605e+09, 1.46526924e+09, 1.56574374e+09,\n",
       "           1.71525983e+09, 1.22583243e+09]),\n",
       "    'public_cpu': array([7.68946447e+08, 7.53418541e+08, 7.02715948e+08, 5.45197669e+08,\n",
       "           6.70994513e+08, 6.80525152e+08, 8.11159072e+08, 7.82943570e+08,\n",
       "           5.01997672e+08, 6.85198792e+08, 8.22519853e+08, 7.16138691e+08,\n",
       "           8.22355072e+08, 5.56428866e+08, 8.05978940e+08, 7.90274918e+08,\n",
       "           6.02437544e+08, 7.09495765e+08]),\n",
       "    'cloud_cpu': 30000000000.0,\n",
       "    'N_agents': 18,\n",
       "    'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17]),\n",
       "    'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "    0    light           0    1.0     3600    1.0        18   143,\n",
       "    'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
       "    0          0  9.214683e+08  5152.146294  0.021214       0\n",
       "    1          1  1.988512e+09  4208.470915  0.030254       1\n",
       "    2          2  1.361339e+09  4466.022492  0.028701       2\n",
       "    3          3  2.155303e+09  7570.283244  0.038873       3\n",
       "    4          4  8.727403e+08  6918.455560  0.037506       4\n",
       "    5          5  2.350478e+09  7997.219317  0.013920       5\n",
       "    6          6  1.080474e+09  3611.664818  0.031591       6\n",
       "    7          7  1.483437e+09  5690.301814  0.026184       7\n",
       "    8          8  1.782616e+09  5312.418573  0.040268       8\n",
       "    9          9  2.164538e+09  6264.107462  0.048391       9\n",
       "    10        10  2.381892e+09  5233.485875  0.039955      10\n",
       "    11        11  1.698112e+09  5619.134661  0.037599      11\n",
       "    12        12  1.170523e+09  5302.008006  0.034852      12\n",
       "    13        13  1.004000e+09  6356.746540  0.027640      13\n",
       "    14        14  1.206141e+09  4332.462100  0.038611      14\n",
       "    15        15  2.062918e+09  5181.575792  0.042660      15\n",
       "    16        16  1.493700e+09  6776.846182  0.026377      16\n",
       "    17        17  1.302068e+09  6167.829828  0.025928      17,\n",
       "    'arrivals':      scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "    0       light           0       0     0.0         1        0\n",
       "    1       light           0       0     0.0        17        1\n",
       "    2       light           0       7     7.0        17        2\n",
       "    3       light           0       9     9.0         3        3\n",
       "    4       light           0      13    13.0        15        4\n",
       "    ...       ...         ...     ...     ...       ...      ...\n",
       "    2108    light           0    3594  3594.0        14     2108\n",
       "    2109    light           0    3597  3597.0        11     2109\n",
       "    2110    light           0    3597  3597.0        16     2110\n",
       "    2111    light           0    3598  3598.0        14     2111\n",
       "    2112    light           0    3599  3599.0        17     2112\n",
       "    \n",
       "    [2113 rows x 6 columns],\n",
       "    'tasks':      scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "    0       light           0        0         1               0             0.0   \n",
       "    1       light           0        1        17               0             0.0   \n",
       "    2       light           0        2        17               7             7.0   \n",
       "    3       light           0        3         3               9             9.0   \n",
       "    4       light           0        4        15              13            13.0   \n",
       "    ...       ...         ...      ...       ...             ...             ...   \n",
       "    2108    light           0     2108        14            3594          3594.0   \n",
       "    2109    light           0     2109        11            3597          3597.0   \n",
       "    2110    light           0     2110        16            3597          3597.0   \n",
       "    2111    light           0     2111        14            3598          3598.0   \n",
       "    2112    light           0     2112        17            3599          3599.0   \n",
       "    \n",
       "              b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "    0     2.484967    5.525261e+08  1.373009e+09   62.412148    video   \n",
       "    1     2.509962    1.082130e+09  2.716106e+09   74.606000     text   \n",
       "    2     1.509317    1.757732e+09  2.652974e+09   30.173971     text   \n",
       "    3     2.114311    4.582521e+08  9.688874e+08   52.914295    image   \n",
       "    4     1.707707    6.574788e+08  1.122781e+09   95.441150    image   \n",
       "    ...        ...             ...           ...         ...      ...   \n",
       "    2108  2.306310    1.006178e+09  2.320560e+09   64.688480     text   \n",
       "    2109  3.687047    1.297120e+09  4.782541e+09  106.002625   sensor   \n",
       "    2110  2.407504    9.582727e+08  2.307045e+09   65.863180    image   \n",
       "    2111  1.205960    1.482103e+09  1.787356e+09   65.631966    image   \n",
       "    2112  1.339075    4.337156e+08  5.807776e+08   81.440796    video   \n",
       "    \n",
       "          has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "    0                1    1.339893       1.339893           1     0.424900   \n",
       "    1                0         NaN            NaN           0     0.000000   \n",
       "    2                0         NaN            NaN           1     0.358162   \n",
       "    3                0         NaN            NaN           0     0.000000   \n",
       "    4                0         NaN            NaN           0     0.000000   \n",
       "    ...            ...         ...            ...         ...          ...   \n",
       "    2108             0         NaN            NaN           0     0.000000   \n",
       "    2109             0         NaN            NaN           0     0.000000   \n",
       "    2110             0         NaN            NaN           1     0.393362   \n",
       "    2111             0         NaN            NaN           0     0.000000   \n",
       "    2112             0         NaN            NaN           0     0.000000   \n",
       "    \n",
       "         action_space_hint  \n",
       "    0           continuous  \n",
       "    1             discrete  \n",
       "    2           continuous  \n",
       "    3             discrete  \n",
       "    4             discrete  \n",
       "    ...                ...  \n",
       "    2108          discrete  \n",
       "    2109          discrete  \n",
       "    2110        continuous  \n",
       "    2111          discrete  \n",
       "    2112          discrete  \n",
       "    \n",
       "    [2113 rows x 17 columns],\n",
       "    'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'cloud_cycles': array([0.])},\n",
       "    'action_space': {'type': 'discrete',\n",
       "     'n': 3,\n",
       "     'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}},\n",
       "    'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,),\n",
       "        'dtype': 'float'},\n",
       "       'mec_public_cycles': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cycles': {'shape': (1,), 'dtype': 'float'}},\n",
       "      'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}},\n",
       "      'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'public_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}},\n",
       "     'note': 'Declarative spec; tensor assembly happens in the Env at each step.'},\n",
       "    'checks': {'delta_match': True, 'message': 'OK'}},\n",
       "   'moderate': {'Delta': 1.0,\n",
       "    'K': 18,\n",
       "    'topology_type': 'clustered',\n",
       "    'connection_matrix': array([[  0.        ,   9.79880061,  11.95829539,  11.47040438,\n",
       "              9.98019544,   8.81405007,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  98.91279982],\n",
       "           [  9.79880061,   0.        ,   8.37514324,  11.53560011,\n",
       "             10.70258438,   9.13689312,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 104.60920208],\n",
       "           [ 11.95829539,   8.37514324,   0.        ,   8.81463191,\n",
       "              9.63771407,   9.17070042,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  92.05534806],\n",
       "           [ 11.47040438,  11.53560011,   8.81463191,   0.        ,\n",
       "             10.37705391,  11.92025208,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  84.85166372],\n",
       "           [  9.98019544,  10.70258438,   9.63771407,  10.37705391,\n",
       "              0.        ,   8.10538324,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  99.07630097],\n",
       "           [  8.81405007,   9.13689312,   9.17070042,  11.92025208,\n",
       "              8.10538324,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 115.07927911],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   9.84469022,\n",
       "              9.56656784,  11.01158338,  10.13220601,  11.73176121,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 115.8763706 ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   9.84469022,   0.        ,\n",
       "              8.17265482,  11.31725016,   9.94433007,  11.69899488,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  85.49730491],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   9.56656784,   8.17265482,\n",
       "              0.        ,  11.9192718 ,   9.16293193,  11.22074688,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 104.13111015],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  11.01158338,  11.31725016,\n",
       "             11.9192718 ,   0.        ,  11.8680001 ,  11.39378515,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  87.20532265],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  10.13220601,   9.94433007,\n",
       "              9.16293193,  11.8680001 ,   0.        ,   9.54873479,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  98.89380626],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  11.73176121,  11.69899488,\n",
       "             11.22074688,  11.39378515,   9.54873479,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 100.16242881],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   8.57308973,  10.15563321,  11.20259578,\n",
       "             10.69123291,  11.43912945,  94.68338717],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              8.57308973,   0.        ,  10.79553972,   9.38248576,\n",
       "              8.15651517,  10.10895365,  86.2148807 ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             10.15563321,  10.79553972,   0.        ,   8.18342325,\n",
       "              9.05546058,   8.85786558, 100.51802149],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             11.20259578,   9.38248576,   8.18342325,   0.        ,\n",
       "             10.92203111,   8.7775075 ,  85.56329834],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             10.69123291,   8.15651517,   9.05546058,  10.92203111,\n",
       "              0.        ,  11.48804542, 109.44902762],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             11.43912945,  10.10895365,   8.85786558,   8.7775075 ,\n",
       "             11.48804542,   0.        , 119.21419244]]),\n",
       "    'private_cpu': array([1.41702651e+09, 1.46583552e+09, 1.40029615e+09, 1.21986312e+09,\n",
       "           1.27037663e+09, 1.34801953e+09, 1.78616129e+09, 1.38093201e+09,\n",
       "           1.73968038e+09, 1.60615170e+09, 1.72279202e+09, 1.45211969e+09,\n",
       "           1.57532372e+09, 1.67517605e+09, 1.46526924e+09, 1.56574374e+09,\n",
       "           1.71525983e+09, 1.22583243e+09]),\n",
       "    'public_cpu': array([7.68946447e+08, 7.53418541e+08, 7.02715948e+08, 5.45197669e+08,\n",
       "           6.70994513e+08, 6.80525152e+08, 8.11159072e+08, 7.82943570e+08,\n",
       "           5.01997672e+08, 6.85198792e+08, 8.22519853e+08, 7.16138691e+08,\n",
       "           8.22355072e+08, 5.56428866e+08, 8.05978940e+08, 7.90274918e+08,\n",
       "           6.02437544e+08, 7.09495765e+08]),\n",
       "    'cloud_cpu': 30000000000.0,\n",
       "    'N_agents': 18,\n",
       "    'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17]),\n",
       "    'episodes':    scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "    0  moderate           0    1.0     3600    1.0        18   244,\n",
       "    'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
       "    0          0  2.075234e+09  4177.077472  0.083588       0\n",
       "    1          1  1.845675e+09  4444.750864  0.117454       1\n",
       "    2          2  1.422351e+09  3116.790674  0.190249       2\n",
       "    3          3  8.627662e+08  3819.530831  0.180022       3\n",
       "    4          4  1.576391e+09  4456.416731  0.124874       4\n",
       "    5          5  1.361574e+09  6518.273845  0.093241       5\n",
       "    6          6  1.146421e+09  4031.095267  0.197552       6\n",
       "    7          7  1.093930e+09  5125.594407  0.160180       7\n",
       "    8          8  8.213925e+08  5099.239983  0.089347       8\n",
       "    9          9  1.378500e+09  3320.898803  0.115078       9\n",
       "    10        10  1.967238e+09  3878.558132  0.066943      10\n",
       "    11        11  1.937473e+09  5303.971140  0.051492      11\n",
       "    12        12  1.973373e+09  4718.837422  0.187653      12\n",
       "    13        13  2.334762e+09  4156.023984  0.171413      13\n",
       "    14        14  1.989451e+09  5301.096958  0.169348      14\n",
       "    15        15  2.245627e+09  3973.902321  0.114526      15\n",
       "    16        16  9.699633e+08  5954.812618  0.109306      16\n",
       "    17        17  1.298186e+09  6890.123320  0.106591      17,\n",
       "    'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "    0     moderate           0       1     1.0         3        0\n",
       "    1     moderate           0       1     1.0        12        1\n",
       "    2     moderate           0       1     1.0        13        2\n",
       "    3     moderate           0       1     1.0        13        3\n",
       "    4     moderate           0       3     3.0         5        4\n",
       "    ...        ...         ...     ...     ...       ...      ...\n",
       "    8257  moderate           0    3597  3597.0        13     8257\n",
       "    8258  moderate           0    3597  3597.0        13     8258\n",
       "    8259  moderate           0    3597  3597.0        14     8259\n",
       "    8260  moderate           0    3598  3598.0        13     8260\n",
       "    8261  moderate           0    3599  3599.0         6     8261\n",
       "    \n",
       "    [8262 rows x 6 columns],\n",
       "    'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "    0     moderate           0        0         3               1             1.0   \n",
       "    1     moderate           0        1        12               1             1.0   \n",
       "    2     moderate           0        2        13               1             1.0   \n",
       "    3     moderate           0        3        13               1             1.0   \n",
       "    4     moderate           0        4         5               3             3.0   \n",
       "    ...        ...         ...      ...       ...             ...             ...   \n",
       "    8257  moderate           0     8257        13            3597          3597.0   \n",
       "    8258  moderate           0     8258        13            3597          3597.0   \n",
       "    8259  moderate           0     8259        14            3597          3597.0   \n",
       "    8260  moderate           0     8260        13            3598          3598.0   \n",
       "    8261  moderate           0     8261         6            3599          3599.0   \n",
       "    \n",
       "              b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "    0     4.463301    1.368071e+09  6.106115e+09   59.895400    video   \n",
       "    1     2.032145    1.310597e+09  2.663323e+09   39.163837     text   \n",
       "    2     2.471461    1.423734e+09  3.518704e+09   71.265870    image   \n",
       "    3     2.097559    7.160129e+08  1.501879e+09   73.560420     text   \n",
       "    4     2.683642    9.887779e+08  2.653526e+09  114.356410    video   \n",
       "    ...        ...             ...           ...         ...      ...   \n",
       "    8257  2.391213    5.808735e+08  1.388992e+09   56.940155    video   \n",
       "    8258  2.583749    1.690439e+09  4.367671e+09   67.638040    video   \n",
       "    8259  2.405940    1.218846e+09  2.932471e+09   66.223816   sensor   \n",
       "    8260  2.014641    9.512537e+08  1.916434e+09   36.491844     text   \n",
       "    8261  4.927452    2.140466e+09  1.054704e+10   47.556170    image   \n",
       "    \n",
       "          has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "    0                0         NaN            NaN           0     0.000000   \n",
       "    1                0         NaN            NaN           1     0.619935   \n",
       "    2                0         NaN            NaN           0     0.000000   \n",
       "    3                0         NaN            NaN           1     0.667023   \n",
       "    4                1    0.868840       3.868839           0     0.000000   \n",
       "    ...            ...         ...            ...         ...          ...   \n",
       "    8257             0         NaN            NaN           0     0.000000   \n",
       "    8258             0         NaN            NaN           0     0.000000   \n",
       "    8259             1    1.438337    3598.438200           0     0.000000   \n",
       "    8260             0         NaN            NaN           1     0.493939   \n",
       "    8261             0         NaN            NaN           0     0.000000   \n",
       "    \n",
       "         action_space_hint  \n",
       "    0             discrete  \n",
       "    1           continuous  \n",
       "    2             discrete  \n",
       "    3           continuous  \n",
       "    4             discrete  \n",
       "    ...                ...  \n",
       "    8257          discrete  \n",
       "    8258          discrete  \n",
       "    8259          discrete  \n",
       "    8260        continuous  \n",
       "    8261          discrete  \n",
       "    \n",
       "    [8262 rows x 17 columns],\n",
       "    'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'cloud_cycles': array([0.])},\n",
       "    'action_space': {'type': 'discrete',\n",
       "     'n': 3,\n",
       "     'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}},\n",
       "    'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,),\n",
       "        'dtype': 'float'},\n",
       "       'mec_public_cycles': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cycles': {'shape': (1,), 'dtype': 'float'}},\n",
       "      'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}},\n",
       "      'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'public_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}},\n",
       "     'note': 'Declarative spec; tensor assembly happens in the Env at each step.'},\n",
       "    'checks': {'delta_match': True, 'message': 'OK'}}},\n",
       "  'full_mesh': {'heavy': {'Delta': 1.0,\n",
       "    'K': 18,\n",
       "    'topology_type': 'fully_connected',\n",
       "    'connection_matrix': array([[  0.        ,  11.92281432,  10.47890811,  11.62756381,\n",
       "              9.72588091,   9.91325978,   8.60450808,   9.50115837,\n",
       "             10.91615142,  11.81350974,   8.9852223 ,  10.80194249,\n",
       "              9.73499996,   9.19422365,   8.12723414,  10.69973564,\n",
       "              8.60534515,  11.55299163,  92.53424509],\n",
       "           [ 11.92281432,   0.        ,  11.08031243,  10.34304631,\n",
       "             11.49029507,  10.65127018,   8.33860734,   8.88809786,\n",
       "             11.86786775,   9.25818495,  11.68602726,  10.73935883,\n",
       "              8.71533211,  10.60486084,  11.70825125,   8.60692948,\n",
       "             11.47275338,  10.84320426, 102.77092651],\n",
       "           [ 10.47890811,  11.08031243,   0.        ,  10.64649505,\n",
       "             11.53438988,   8.09132603,   8.86977281,  11.27540672,\n",
       "              9.44013753,  10.61901002,  10.63050405,   8.62482374,\n",
       "             11.93621388,   8.57698697,  11.36443595,   8.97319535,\n",
       "              9.8559768 ,  10.59985665,  90.21900011],\n",
       "           [ 11.62756381,  10.34304631,  10.64649505,   0.        ,\n",
       "             11.20948852,  11.42185288,   8.19203445,  10.17525597,\n",
       "             11.95613397,  11.56506179,   9.13060445,   9.29187176,\n",
       "              8.15166136,   8.23006506,   8.84915373,   8.30343023,\n",
       "             11.2237641 ,  10.82287993, 116.69177743],\n",
       "           [  9.72588091,  11.49029507,  11.53438988,  11.20948852,\n",
       "              0.        ,  11.57957036,  11.22306739,   9.13859261,\n",
       "              8.00416714,   8.11347903,  10.76178584,  11.79952273,\n",
       "              8.36313817,   8.94473855,  11.01157505,  11.20524851,\n",
       "              9.6610549 ,  11.47970717, 113.53515991],\n",
       "           [  9.91325978,  10.65127018,   8.09132603,  11.42185288,\n",
       "             11.57957036,   0.        ,  10.19076132,  11.14913457,\n",
       "              8.01497904,  10.22662375,  11.8880429 ,   8.83572162,\n",
       "              9.62774888,  10.17125276,   8.68627754,   8.58986201,\n",
       "             11.02055036,   8.20195936, 103.1242896 ],\n",
       "           [  8.60450808,   8.33860734,   8.86977281,   8.19203445,\n",
       "             11.22306739,  10.19076132,   0.        ,   9.25823308,\n",
       "              8.59949341,  11.6955161 ,   8.22286692,  11.05960807,\n",
       "              9.26773023,  11.83977492,  10.63031311,  11.21776576,\n",
       "              8.10131787,   9.22655274,  80.31803431],\n",
       "           [  9.50115837,   8.88809786,  11.27540672,  10.17525597,\n",
       "              9.13859261,  11.14913457,   9.25823308,   0.        ,\n",
       "             11.02345357,   8.71314753,  10.66198773,   9.95449414,\n",
       "              8.29711708,   9.56968893,  11.47314045,  11.04922624,\n",
       "             11.36644903,   8.69355859,  84.27804082],\n",
       "           [ 10.91615142,  11.86786775,   9.44013753,  11.95613397,\n",
       "              8.00416714,   8.01497904,   8.59949341,  11.02345357,\n",
       "              0.        ,  10.36649366,   9.01459539,   8.50196981,\n",
       "             10.24199153,   9.01413545,  10.8651746 ,   8.73945359,\n",
       "              9.49328392,  10.95063845, 105.06297613],\n",
       "           [ 11.81350974,   9.25818495,  10.61901002,  11.56506179,\n",
       "              8.11347903,  10.22662375,  11.6955161 ,   8.71314753,\n",
       "             10.36649366,   0.        ,   9.27746018,  11.92108069,\n",
       "              8.63413464,  10.20054372,  11.94518796,   8.47182754,\n",
       "             10.58547852,  10.32572754,  90.45659317],\n",
       "           [  8.9852223 ,  11.68602726,  10.63050405,   9.13060445,\n",
       "             10.76178584,  11.8880429 ,   8.22286692,  10.66198773,\n",
       "              9.01459539,   9.27746018,   0.        ,   8.05666516,\n",
       "             11.04409073,  10.99370358,  11.64886694,  11.83759545,\n",
       "             11.46201003,  10.55497495,  90.49497857],\n",
       "           [ 10.80194249,  10.73935883,   8.62482374,   9.29187176,\n",
       "             11.79952273,   8.83572162,  11.05960807,   9.95449414,\n",
       "              8.50196981,  11.92108069,   8.05666516,   0.        ,\n",
       "              9.58238503,   9.85598834,   8.99850643,  11.94521517,\n",
       "              9.28969472,  10.38872064, 114.97360564],\n",
       "           [  9.73499996,   8.71533211,  11.93621388,   8.15166136,\n",
       "              8.36313817,   9.62774888,   9.26773023,   8.29711708,\n",
       "             10.24199153,   8.63413464,  11.04409073,   9.58238503,\n",
       "              0.        ,  11.27384325,  11.28665671,   8.90522964,\n",
       "             10.41042621,  10.61255726, 106.22071351],\n",
       "           [  9.19422365,  10.60486084,   8.57698697,   8.23006506,\n",
       "              8.94473855,  10.17125276,  11.83977492,   9.56968893,\n",
       "              9.01413545,  10.20054372,  10.99370358,   9.85598834,\n",
       "             11.27384325,   0.        ,   9.54211704,  11.54586854,\n",
       "              8.92633187,  10.4308838 , 114.1328218 ],\n",
       "           [  8.12723414,  11.70825125,  11.36443595,   8.84915373,\n",
       "             11.01157505,   8.68627754,  10.63031311,  11.47314045,\n",
       "             10.8651746 ,  11.94518796,  11.64886694,   8.99850643,\n",
       "             11.28665671,   9.54211704,   0.        ,   9.42280233,\n",
       "             11.65808696,  10.24933329, 100.32308979],\n",
       "           [ 10.69973564,   8.60692948,   8.97319535,   8.30343023,\n",
       "             11.20524851,   8.58986201,  11.21776576,  11.04922624,\n",
       "              8.73945359,   8.47182754,  11.83759545,  11.94521517,\n",
       "              8.90522964,  11.54586854,   9.42280233,   0.        ,\n",
       "             11.44854903,   8.67962924, 101.35876193],\n",
       "           [  8.60534515,  11.47275338,   9.8559768 ,  11.2237641 ,\n",
       "              9.6610549 ,  11.02055036,   8.10131787,  11.36644903,\n",
       "              9.49328392,  10.58547852,  11.46201003,   9.28969472,\n",
       "             10.41042621,   8.92633187,  11.65808696,  11.44854903,\n",
       "              0.        ,  10.51361586,  96.80376159],\n",
       "           [ 11.55299163,  10.84320426,  10.59985665,  10.82287993,\n",
       "             11.47970717,   8.20195936,   9.22655274,   8.69355859,\n",
       "             10.95063845,  10.32572754,  10.55497495,  10.38872064,\n",
       "             10.61255726,  10.4308838 ,  10.24933329,   8.67962924,\n",
       "             10.51361586,   0.        ,  91.90437345]]),\n",
       "    'private_cpu': array([1.52424030e+09, 1.36612999e+09, 1.32985713e+09, 1.75903750e+09,\n",
       "           1.78521529e+09, 1.58565730e+09, 1.36855507e+09, 1.56036396e+09,\n",
       "           1.23146379e+09, 1.28074522e+09, 1.54077462e+09, 1.70275186e+09,\n",
       "           1.42938204e+09, 1.77064224e+09, 1.54900140e+09, 1.34500170e+09,\n",
       "           1.28934975e+09, 1.34111888e+09]),\n",
       "    'public_cpu': array([5.41968088e+08, 7.71454134e+08, 8.41493012e+08, 8.07566257e+08,\n",
       "           8.21473667e+08, 7.11004312e+08, 7.49406606e+08, 5.29752691e+08,\n",
       "           6.66159079e+08, 5.18725393e+08, 8.65619117e+08, 7.79462658e+08,\n",
       "           5.91542663e+08, 8.11924367e+08, 7.42569242e+08, 8.35342189e+08,\n",
       "           7.18293796e+08, 5.95744952e+08]),\n",
       "    'cloud_cpu': 30000000000.0,\n",
       "    'N_agents': 18,\n",
       "    'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17]),\n",
       "    'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "    0    heavy           0    1.0     3600    1.0        18   345,\n",
       "    'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
       "    0          0  1.741183e+09  5713.849721  0.708673       0\n",
       "    1          1  1.352326e+09  4566.428755  0.234989       1\n",
       "    2          2  1.726668e+09  5815.120004  0.228174       2\n",
       "    3          3  1.543616e+09  3539.850245  0.310369       3\n",
       "    4          4  1.130883e+09  4161.367769  0.548990       4\n",
       "    5          5  1.761336e+09  7349.509397  0.427498       5\n",
       "    6          6  1.093196e+09  6389.821853  0.733849       6\n",
       "    7          7  1.022066e+09  5354.805771  0.492160       7\n",
       "    8          8  1.280853e+09  3931.170813  0.647444       8\n",
       "    9          9  1.260889e+09  5133.304392  0.434945       9\n",
       "    10        10  8.077840e+08  6774.364061  0.696332      10\n",
       "    11        11  1.252718e+09  5907.761753  0.250139      11\n",
       "    12        12  1.849537e+09  4251.816941  0.275633      12\n",
       "    13        13  2.013685e+09  3452.486291  0.387815      13\n",
       "    14        14  1.566043e+09  6514.168780  0.410745      14\n",
       "    15        15  1.573528e+09  7018.517023  0.746995      15\n",
       "    16        16  1.386095e+09  6122.347442  0.414992      16\n",
       "    17        17  1.604826e+09  3449.292167  0.516951      17,\n",
       "    'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "    0        heavy           0       0     0.0         0        0\n",
       "    1        heavy           0       0     0.0         1        1\n",
       "    2        heavy           0       0     0.0         4        2\n",
       "    3        heavy           0       0     0.0         7        3\n",
       "    4        heavy           0       0     0.0        10        4\n",
       "    ...        ...         ...     ...     ...       ...      ...\n",
       "    30631    heavy           0    3599  3599.0         5    30631\n",
       "    30632    heavy           0    3599  3599.0         6    30632\n",
       "    30633    heavy           0    3599  3599.0         6    30633\n",
       "    30634    heavy           0    3599  3599.0         7    30634\n",
       "    30635    heavy           0    3599  3599.0         7    30635\n",
       "    \n",
       "    [30636 rows x 6 columns],\n",
       "    'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "    0        heavy           0        0         0               0             0.0   \n",
       "    1        heavy           0        1         1               0             0.0   \n",
       "    2        heavy           0        2         4               0             0.0   \n",
       "    3        heavy           0        3         7               0             0.0   \n",
       "    4        heavy           0        4        10               0             0.0   \n",
       "    ...        ...         ...      ...       ...             ...             ...   \n",
       "    30631    heavy           0    30631         5            3599          3599.0   \n",
       "    30632    heavy           0    30632         6            3599          3599.0   \n",
       "    30633    heavy           0    30633         6            3599          3599.0   \n",
       "    30634    heavy           0    30634         7            3599          3599.0   \n",
       "    30635    heavy           0    30635         7            3599          3599.0   \n",
       "    \n",
       "                b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "    0       7.202096    9.727147e+08  7.005585e+09   66.611010   sensor   \n",
       "    1       5.479984    1.314973e+09  7.206031e+09   77.928800    image   \n",
       "    2       8.421977    2.500222e+09  2.105681e+10   72.966446     text   \n",
       "    3       6.324986    1.779582e+09  1.125583e+10   56.492900   sensor   \n",
       "    4      11.473269    1.087572e+09  1.247800e+10   73.389854   sensor   \n",
       "    ...          ...             ...           ...         ...      ...   \n",
       "    30631   6.238504    1.090296e+09  6.801814e+09   69.218260    video   \n",
       "    30632   3.289880    1.599958e+09  5.263669e+09   39.210260   sensor   \n",
       "    30633   6.192005    8.322764e+08  5.153459e+09   73.052900   sensor   \n",
       "    30634   3.244716    1.627807e+09  5.281771e+09  103.576775    image   \n",
       "    30635   1.736996    2.141823e+09  3.720338e+09   92.836210     text   \n",
       "    \n",
       "           has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "    0                 1    0.800726       0.800726           0     0.000000   \n",
       "    1                 1    0.615113       0.615113           0     0.000000   \n",
       "    2                 1    0.323007       0.323007           1     0.539704   \n",
       "    3                 1    0.481587       0.481587           0     0.000000   \n",
       "    4                 1    0.594564       0.594564           0     0.000000   \n",
       "    ...             ...         ...            ...         ...          ...   \n",
       "    30631             1    0.525271    3599.525400           1     0.605597   \n",
       "    30632             0         NaN            NaN           0     0.000000   \n",
       "    30633             0         NaN            NaN           1     0.566783   \n",
       "    30634             0         NaN            NaN           1     0.706580   \n",
       "    30635             1    0.763454    3599.763400           0     0.000000   \n",
       "    \n",
       "          action_space_hint  \n",
       "    0              discrete  \n",
       "    1              discrete  \n",
       "    2            continuous  \n",
       "    3              discrete  \n",
       "    4              discrete  \n",
       "    ...                 ...  \n",
       "    30631        continuous  \n",
       "    30632          discrete  \n",
       "    30633        continuous  \n",
       "    30634        continuous  \n",
       "    30635          discrete  \n",
       "    \n",
       "    [30636 rows x 17 columns],\n",
       "    'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'cloud_cycles': array([0.])},\n",
       "    'action_space': {'type': 'discrete',\n",
       "     'n': 3,\n",
       "     'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}},\n",
       "    'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,),\n",
       "        'dtype': 'float'},\n",
       "       'mec_public_cycles': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cycles': {'shape': (1,), 'dtype': 'float'}},\n",
       "      'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}},\n",
       "      'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'public_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}},\n",
       "     'note': 'Declarative spec; tensor assembly happens in the Env at each step.'},\n",
       "    'checks': {'delta_match': True, 'message': 'OK'}},\n",
       "   'light': {'Delta': 1.0,\n",
       "    'K': 18,\n",
       "    'topology_type': 'fully_connected',\n",
       "    'connection_matrix': array([[  0.        ,  11.92281432,  10.47890811,  11.62756381,\n",
       "              9.72588091,   9.91325978,   8.60450808,   9.50115837,\n",
       "             10.91615142,  11.81350974,   8.9852223 ,  10.80194249,\n",
       "              9.73499996,   9.19422365,   8.12723414,  10.69973564,\n",
       "              8.60534515,  11.55299163,  92.53424509],\n",
       "           [ 11.92281432,   0.        ,  11.08031243,  10.34304631,\n",
       "             11.49029507,  10.65127018,   8.33860734,   8.88809786,\n",
       "             11.86786775,   9.25818495,  11.68602726,  10.73935883,\n",
       "              8.71533211,  10.60486084,  11.70825125,   8.60692948,\n",
       "             11.47275338,  10.84320426, 102.77092651],\n",
       "           [ 10.47890811,  11.08031243,   0.        ,  10.64649505,\n",
       "             11.53438988,   8.09132603,   8.86977281,  11.27540672,\n",
       "              9.44013753,  10.61901002,  10.63050405,   8.62482374,\n",
       "             11.93621388,   8.57698697,  11.36443595,   8.97319535,\n",
       "              9.8559768 ,  10.59985665,  90.21900011],\n",
       "           [ 11.62756381,  10.34304631,  10.64649505,   0.        ,\n",
       "             11.20948852,  11.42185288,   8.19203445,  10.17525597,\n",
       "             11.95613397,  11.56506179,   9.13060445,   9.29187176,\n",
       "              8.15166136,   8.23006506,   8.84915373,   8.30343023,\n",
       "             11.2237641 ,  10.82287993, 116.69177743],\n",
       "           [  9.72588091,  11.49029507,  11.53438988,  11.20948852,\n",
       "              0.        ,  11.57957036,  11.22306739,   9.13859261,\n",
       "              8.00416714,   8.11347903,  10.76178584,  11.79952273,\n",
       "              8.36313817,   8.94473855,  11.01157505,  11.20524851,\n",
       "              9.6610549 ,  11.47970717, 113.53515991],\n",
       "           [  9.91325978,  10.65127018,   8.09132603,  11.42185288,\n",
       "             11.57957036,   0.        ,  10.19076132,  11.14913457,\n",
       "              8.01497904,  10.22662375,  11.8880429 ,   8.83572162,\n",
       "              9.62774888,  10.17125276,   8.68627754,   8.58986201,\n",
       "             11.02055036,   8.20195936, 103.1242896 ],\n",
       "           [  8.60450808,   8.33860734,   8.86977281,   8.19203445,\n",
       "             11.22306739,  10.19076132,   0.        ,   9.25823308,\n",
       "              8.59949341,  11.6955161 ,   8.22286692,  11.05960807,\n",
       "              9.26773023,  11.83977492,  10.63031311,  11.21776576,\n",
       "              8.10131787,   9.22655274,  80.31803431],\n",
       "           [  9.50115837,   8.88809786,  11.27540672,  10.17525597,\n",
       "              9.13859261,  11.14913457,   9.25823308,   0.        ,\n",
       "             11.02345357,   8.71314753,  10.66198773,   9.95449414,\n",
       "              8.29711708,   9.56968893,  11.47314045,  11.04922624,\n",
       "             11.36644903,   8.69355859,  84.27804082],\n",
       "           [ 10.91615142,  11.86786775,   9.44013753,  11.95613397,\n",
       "              8.00416714,   8.01497904,   8.59949341,  11.02345357,\n",
       "              0.        ,  10.36649366,   9.01459539,   8.50196981,\n",
       "             10.24199153,   9.01413545,  10.8651746 ,   8.73945359,\n",
       "              9.49328392,  10.95063845, 105.06297613],\n",
       "           [ 11.81350974,   9.25818495,  10.61901002,  11.56506179,\n",
       "              8.11347903,  10.22662375,  11.6955161 ,   8.71314753,\n",
       "             10.36649366,   0.        ,   9.27746018,  11.92108069,\n",
       "              8.63413464,  10.20054372,  11.94518796,   8.47182754,\n",
       "             10.58547852,  10.32572754,  90.45659317],\n",
       "           [  8.9852223 ,  11.68602726,  10.63050405,   9.13060445,\n",
       "             10.76178584,  11.8880429 ,   8.22286692,  10.66198773,\n",
       "              9.01459539,   9.27746018,   0.        ,   8.05666516,\n",
       "             11.04409073,  10.99370358,  11.64886694,  11.83759545,\n",
       "             11.46201003,  10.55497495,  90.49497857],\n",
       "           [ 10.80194249,  10.73935883,   8.62482374,   9.29187176,\n",
       "             11.79952273,   8.83572162,  11.05960807,   9.95449414,\n",
       "              8.50196981,  11.92108069,   8.05666516,   0.        ,\n",
       "              9.58238503,   9.85598834,   8.99850643,  11.94521517,\n",
       "              9.28969472,  10.38872064, 114.97360564],\n",
       "           [  9.73499996,   8.71533211,  11.93621388,   8.15166136,\n",
       "              8.36313817,   9.62774888,   9.26773023,   8.29711708,\n",
       "             10.24199153,   8.63413464,  11.04409073,   9.58238503,\n",
       "              0.        ,  11.27384325,  11.28665671,   8.90522964,\n",
       "             10.41042621,  10.61255726, 106.22071351],\n",
       "           [  9.19422365,  10.60486084,   8.57698697,   8.23006506,\n",
       "              8.94473855,  10.17125276,  11.83977492,   9.56968893,\n",
       "              9.01413545,  10.20054372,  10.99370358,   9.85598834,\n",
       "             11.27384325,   0.        ,   9.54211704,  11.54586854,\n",
       "              8.92633187,  10.4308838 , 114.1328218 ],\n",
       "           [  8.12723414,  11.70825125,  11.36443595,   8.84915373,\n",
       "             11.01157505,   8.68627754,  10.63031311,  11.47314045,\n",
       "             10.8651746 ,  11.94518796,  11.64886694,   8.99850643,\n",
       "             11.28665671,   9.54211704,   0.        ,   9.42280233,\n",
       "             11.65808696,  10.24933329, 100.32308979],\n",
       "           [ 10.69973564,   8.60692948,   8.97319535,   8.30343023,\n",
       "             11.20524851,   8.58986201,  11.21776576,  11.04922624,\n",
       "              8.73945359,   8.47182754,  11.83759545,  11.94521517,\n",
       "              8.90522964,  11.54586854,   9.42280233,   0.        ,\n",
       "             11.44854903,   8.67962924, 101.35876193],\n",
       "           [  8.60534515,  11.47275338,   9.8559768 ,  11.2237641 ,\n",
       "              9.6610549 ,  11.02055036,   8.10131787,  11.36644903,\n",
       "              9.49328392,  10.58547852,  11.46201003,   9.28969472,\n",
       "             10.41042621,   8.92633187,  11.65808696,  11.44854903,\n",
       "              0.        ,  10.51361586,  96.80376159],\n",
       "           [ 11.55299163,  10.84320426,  10.59985665,  10.82287993,\n",
       "             11.47970717,   8.20195936,   9.22655274,   8.69355859,\n",
       "             10.95063845,  10.32572754,  10.55497495,  10.38872064,\n",
       "             10.61255726,  10.4308838 ,  10.24933329,   8.67962924,\n",
       "             10.51361586,   0.        ,  91.90437345]]),\n",
       "    'private_cpu': array([1.52424030e+09, 1.36612999e+09, 1.32985713e+09, 1.75903750e+09,\n",
       "           1.78521529e+09, 1.58565730e+09, 1.36855507e+09, 1.56036396e+09,\n",
       "           1.23146379e+09, 1.28074522e+09, 1.54077462e+09, 1.70275186e+09,\n",
       "           1.42938204e+09, 1.77064224e+09, 1.54900140e+09, 1.34500170e+09,\n",
       "           1.28934975e+09, 1.34111888e+09]),\n",
       "    'public_cpu': array([5.41968088e+08, 7.71454134e+08, 8.41493012e+08, 8.07566257e+08,\n",
       "           8.21473667e+08, 7.11004312e+08, 7.49406606e+08, 5.29752691e+08,\n",
       "           6.66159079e+08, 5.18725393e+08, 8.65619117e+08, 7.79462658e+08,\n",
       "           5.91542663e+08, 8.11924367e+08, 7.42569242e+08, 8.35342189e+08,\n",
       "           7.18293796e+08, 5.95744952e+08]),\n",
       "    'cloud_cpu': 30000000000.0,\n",
       "    'N_agents': 18,\n",
       "    'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17]),\n",
       "    'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "    0    light           0    1.0     3600    1.0        18   143,\n",
       "    'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
       "    0          0  9.214683e+08  5152.146294  0.021214       0\n",
       "    1          1  1.988512e+09  4208.470915  0.030254       1\n",
       "    2          2  1.361339e+09  4466.022492  0.028701       2\n",
       "    3          3  2.155303e+09  7570.283244  0.038873       3\n",
       "    4          4  8.727403e+08  6918.455560  0.037506       4\n",
       "    5          5  2.350478e+09  7997.219317  0.013920       5\n",
       "    6          6  1.080474e+09  3611.664818  0.031591       6\n",
       "    7          7  1.483437e+09  5690.301814  0.026184       7\n",
       "    8          8  1.782616e+09  5312.418573  0.040268       8\n",
       "    9          9  2.164538e+09  6264.107462  0.048391       9\n",
       "    10        10  2.381892e+09  5233.485875  0.039955      10\n",
       "    11        11  1.698112e+09  5619.134661  0.037599      11\n",
       "    12        12  1.170523e+09  5302.008006  0.034852      12\n",
       "    13        13  1.004000e+09  6356.746540  0.027640      13\n",
       "    14        14  1.206141e+09  4332.462100  0.038611      14\n",
       "    15        15  2.062918e+09  5181.575792  0.042660      15\n",
       "    16        16  1.493700e+09  6776.846182  0.026377      16\n",
       "    17        17  1.302068e+09  6167.829828  0.025928      17,\n",
       "    'arrivals':      scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "    0       light           0       0     0.0         1        0\n",
       "    1       light           0       0     0.0        17        1\n",
       "    2       light           0       7     7.0        17        2\n",
       "    3       light           0       9     9.0         3        3\n",
       "    4       light           0      13    13.0        15        4\n",
       "    ...       ...         ...     ...     ...       ...      ...\n",
       "    2108    light           0    3594  3594.0        14     2108\n",
       "    2109    light           0    3597  3597.0        11     2109\n",
       "    2110    light           0    3597  3597.0        16     2110\n",
       "    2111    light           0    3598  3598.0        14     2111\n",
       "    2112    light           0    3599  3599.0        17     2112\n",
       "    \n",
       "    [2113 rows x 6 columns],\n",
       "    'tasks':      scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "    0       light           0        0         1               0             0.0   \n",
       "    1       light           0        1        17               0             0.0   \n",
       "    2       light           0        2        17               7             7.0   \n",
       "    3       light           0        3         3               9             9.0   \n",
       "    4       light           0        4        15              13            13.0   \n",
       "    ...       ...         ...      ...       ...             ...             ...   \n",
       "    2108    light           0     2108        14            3594          3594.0   \n",
       "    2109    light           0     2109        11            3597          3597.0   \n",
       "    2110    light           0     2110        16            3597          3597.0   \n",
       "    2111    light           0     2111        14            3598          3598.0   \n",
       "    2112    light           0     2112        17            3599          3599.0   \n",
       "    \n",
       "              b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "    0     2.484967    5.525261e+08  1.373009e+09   62.412148    video   \n",
       "    1     2.509962    1.082130e+09  2.716106e+09   74.606000     text   \n",
       "    2     1.509317    1.757732e+09  2.652974e+09   30.173971     text   \n",
       "    3     2.114311    4.582521e+08  9.688874e+08   52.914295    image   \n",
       "    4     1.707707    6.574788e+08  1.122781e+09   95.441150    image   \n",
       "    ...        ...             ...           ...         ...      ...   \n",
       "    2108  2.306310    1.006178e+09  2.320560e+09   64.688480     text   \n",
       "    2109  3.687047    1.297120e+09  4.782541e+09  106.002625   sensor   \n",
       "    2110  2.407504    9.582727e+08  2.307045e+09   65.863180    image   \n",
       "    2111  1.205960    1.482103e+09  1.787356e+09   65.631966    image   \n",
       "    2112  1.339075    4.337156e+08  5.807776e+08   81.440796    video   \n",
       "    \n",
       "          has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "    0                1    1.339893       1.339893           1     0.424900   \n",
       "    1                0         NaN            NaN           0     0.000000   \n",
       "    2                0         NaN            NaN           1     0.358162   \n",
       "    3                0         NaN            NaN           0     0.000000   \n",
       "    4                0         NaN            NaN           0     0.000000   \n",
       "    ...            ...         ...            ...         ...          ...   \n",
       "    2108             0         NaN            NaN           0     0.000000   \n",
       "    2109             0         NaN            NaN           0     0.000000   \n",
       "    2110             0         NaN            NaN           1     0.393362   \n",
       "    2111             0         NaN            NaN           0     0.000000   \n",
       "    2112             0         NaN            NaN           0     0.000000   \n",
       "    \n",
       "         action_space_hint  \n",
       "    0           continuous  \n",
       "    1             discrete  \n",
       "    2           continuous  \n",
       "    3             discrete  \n",
       "    4             discrete  \n",
       "    ...                ...  \n",
       "    2108          discrete  \n",
       "    2109          discrete  \n",
       "    2110        continuous  \n",
       "    2111          discrete  \n",
       "    2112          discrete  \n",
       "    \n",
       "    [2113 rows x 17 columns],\n",
       "    'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'cloud_cycles': array([0.])},\n",
       "    'action_space': {'type': 'discrete',\n",
       "     'n': 3,\n",
       "     'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}},\n",
       "    'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,),\n",
       "        'dtype': 'float'},\n",
       "       'mec_public_cycles': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cycles': {'shape': (1,), 'dtype': 'float'}},\n",
       "      'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}},\n",
       "      'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'public_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}},\n",
       "     'note': 'Declarative spec; tensor assembly happens in the Env at each step.'},\n",
       "    'checks': {'delta_match': True, 'message': 'OK'}},\n",
       "   'moderate': {'Delta': 1.0,\n",
       "    'K': 18,\n",
       "    'topology_type': 'fully_connected',\n",
       "    'connection_matrix': array([[  0.        ,  11.92281432,  10.47890811,  11.62756381,\n",
       "              9.72588091,   9.91325978,   8.60450808,   9.50115837,\n",
       "             10.91615142,  11.81350974,   8.9852223 ,  10.80194249,\n",
       "              9.73499996,   9.19422365,   8.12723414,  10.69973564,\n",
       "              8.60534515,  11.55299163,  92.53424509],\n",
       "           [ 11.92281432,   0.        ,  11.08031243,  10.34304631,\n",
       "             11.49029507,  10.65127018,   8.33860734,   8.88809786,\n",
       "             11.86786775,   9.25818495,  11.68602726,  10.73935883,\n",
       "              8.71533211,  10.60486084,  11.70825125,   8.60692948,\n",
       "             11.47275338,  10.84320426, 102.77092651],\n",
       "           [ 10.47890811,  11.08031243,   0.        ,  10.64649505,\n",
       "             11.53438988,   8.09132603,   8.86977281,  11.27540672,\n",
       "              9.44013753,  10.61901002,  10.63050405,   8.62482374,\n",
       "             11.93621388,   8.57698697,  11.36443595,   8.97319535,\n",
       "              9.8559768 ,  10.59985665,  90.21900011],\n",
       "           [ 11.62756381,  10.34304631,  10.64649505,   0.        ,\n",
       "             11.20948852,  11.42185288,   8.19203445,  10.17525597,\n",
       "             11.95613397,  11.56506179,   9.13060445,   9.29187176,\n",
       "              8.15166136,   8.23006506,   8.84915373,   8.30343023,\n",
       "             11.2237641 ,  10.82287993, 116.69177743],\n",
       "           [  9.72588091,  11.49029507,  11.53438988,  11.20948852,\n",
       "              0.        ,  11.57957036,  11.22306739,   9.13859261,\n",
       "              8.00416714,   8.11347903,  10.76178584,  11.79952273,\n",
       "              8.36313817,   8.94473855,  11.01157505,  11.20524851,\n",
       "              9.6610549 ,  11.47970717, 113.53515991],\n",
       "           [  9.91325978,  10.65127018,   8.09132603,  11.42185288,\n",
       "             11.57957036,   0.        ,  10.19076132,  11.14913457,\n",
       "              8.01497904,  10.22662375,  11.8880429 ,   8.83572162,\n",
       "              9.62774888,  10.17125276,   8.68627754,   8.58986201,\n",
       "             11.02055036,   8.20195936, 103.1242896 ],\n",
       "           [  8.60450808,   8.33860734,   8.86977281,   8.19203445,\n",
       "             11.22306739,  10.19076132,   0.        ,   9.25823308,\n",
       "              8.59949341,  11.6955161 ,   8.22286692,  11.05960807,\n",
       "              9.26773023,  11.83977492,  10.63031311,  11.21776576,\n",
       "              8.10131787,   9.22655274,  80.31803431],\n",
       "           [  9.50115837,   8.88809786,  11.27540672,  10.17525597,\n",
       "              9.13859261,  11.14913457,   9.25823308,   0.        ,\n",
       "             11.02345357,   8.71314753,  10.66198773,   9.95449414,\n",
       "              8.29711708,   9.56968893,  11.47314045,  11.04922624,\n",
       "             11.36644903,   8.69355859,  84.27804082],\n",
       "           [ 10.91615142,  11.86786775,   9.44013753,  11.95613397,\n",
       "              8.00416714,   8.01497904,   8.59949341,  11.02345357,\n",
       "              0.        ,  10.36649366,   9.01459539,   8.50196981,\n",
       "             10.24199153,   9.01413545,  10.8651746 ,   8.73945359,\n",
       "              9.49328392,  10.95063845, 105.06297613],\n",
       "           [ 11.81350974,   9.25818495,  10.61901002,  11.56506179,\n",
       "              8.11347903,  10.22662375,  11.6955161 ,   8.71314753,\n",
       "             10.36649366,   0.        ,   9.27746018,  11.92108069,\n",
       "              8.63413464,  10.20054372,  11.94518796,   8.47182754,\n",
       "             10.58547852,  10.32572754,  90.45659317],\n",
       "           [  8.9852223 ,  11.68602726,  10.63050405,   9.13060445,\n",
       "             10.76178584,  11.8880429 ,   8.22286692,  10.66198773,\n",
       "              9.01459539,   9.27746018,   0.        ,   8.05666516,\n",
       "             11.04409073,  10.99370358,  11.64886694,  11.83759545,\n",
       "             11.46201003,  10.55497495,  90.49497857],\n",
       "           [ 10.80194249,  10.73935883,   8.62482374,   9.29187176,\n",
       "             11.79952273,   8.83572162,  11.05960807,   9.95449414,\n",
       "              8.50196981,  11.92108069,   8.05666516,   0.        ,\n",
       "              9.58238503,   9.85598834,   8.99850643,  11.94521517,\n",
       "              9.28969472,  10.38872064, 114.97360564],\n",
       "           [  9.73499996,   8.71533211,  11.93621388,   8.15166136,\n",
       "              8.36313817,   9.62774888,   9.26773023,   8.29711708,\n",
       "             10.24199153,   8.63413464,  11.04409073,   9.58238503,\n",
       "              0.        ,  11.27384325,  11.28665671,   8.90522964,\n",
       "             10.41042621,  10.61255726, 106.22071351],\n",
       "           [  9.19422365,  10.60486084,   8.57698697,   8.23006506,\n",
       "              8.94473855,  10.17125276,  11.83977492,   9.56968893,\n",
       "              9.01413545,  10.20054372,  10.99370358,   9.85598834,\n",
       "             11.27384325,   0.        ,   9.54211704,  11.54586854,\n",
       "              8.92633187,  10.4308838 , 114.1328218 ],\n",
       "           [  8.12723414,  11.70825125,  11.36443595,   8.84915373,\n",
       "             11.01157505,   8.68627754,  10.63031311,  11.47314045,\n",
       "             10.8651746 ,  11.94518796,  11.64886694,   8.99850643,\n",
       "             11.28665671,   9.54211704,   0.        ,   9.42280233,\n",
       "             11.65808696,  10.24933329, 100.32308979],\n",
       "           [ 10.69973564,   8.60692948,   8.97319535,   8.30343023,\n",
       "             11.20524851,   8.58986201,  11.21776576,  11.04922624,\n",
       "              8.73945359,   8.47182754,  11.83759545,  11.94521517,\n",
       "              8.90522964,  11.54586854,   9.42280233,   0.        ,\n",
       "             11.44854903,   8.67962924, 101.35876193],\n",
       "           [  8.60534515,  11.47275338,   9.8559768 ,  11.2237641 ,\n",
       "              9.6610549 ,  11.02055036,   8.10131787,  11.36644903,\n",
       "              9.49328392,  10.58547852,  11.46201003,   9.28969472,\n",
       "             10.41042621,   8.92633187,  11.65808696,  11.44854903,\n",
       "              0.        ,  10.51361586,  96.80376159],\n",
       "           [ 11.55299163,  10.84320426,  10.59985665,  10.82287993,\n",
       "             11.47970717,   8.20195936,   9.22655274,   8.69355859,\n",
       "             10.95063845,  10.32572754,  10.55497495,  10.38872064,\n",
       "             10.61255726,  10.4308838 ,  10.24933329,   8.67962924,\n",
       "             10.51361586,   0.        ,  91.90437345]]),\n",
       "    'private_cpu': array([1.52424030e+09, 1.36612999e+09, 1.32985713e+09, 1.75903750e+09,\n",
       "           1.78521529e+09, 1.58565730e+09, 1.36855507e+09, 1.56036396e+09,\n",
       "           1.23146379e+09, 1.28074522e+09, 1.54077462e+09, 1.70275186e+09,\n",
       "           1.42938204e+09, 1.77064224e+09, 1.54900140e+09, 1.34500170e+09,\n",
       "           1.28934975e+09, 1.34111888e+09]),\n",
       "    'public_cpu': array([5.41968088e+08, 7.71454134e+08, 8.41493012e+08, 8.07566257e+08,\n",
       "           8.21473667e+08, 7.11004312e+08, 7.49406606e+08, 5.29752691e+08,\n",
       "           6.66159079e+08, 5.18725393e+08, 8.65619117e+08, 7.79462658e+08,\n",
       "           5.91542663e+08, 8.11924367e+08, 7.42569242e+08, 8.35342189e+08,\n",
       "           7.18293796e+08, 5.95744952e+08]),\n",
       "    'cloud_cpu': 30000000000.0,\n",
       "    'N_agents': 18,\n",
       "    'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17]),\n",
       "    'episodes':    scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "    0  moderate           0    1.0     3600    1.0        18   244,\n",
       "    'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
       "    0          0  2.075234e+09  4177.077472  0.083588       0\n",
       "    1          1  1.845675e+09  4444.750864  0.117454       1\n",
       "    2          2  1.422351e+09  3116.790674  0.190249       2\n",
       "    3          3  8.627662e+08  3819.530831  0.180022       3\n",
       "    4          4  1.576391e+09  4456.416731  0.124874       4\n",
       "    5          5  1.361574e+09  6518.273845  0.093241       5\n",
       "    6          6  1.146421e+09  4031.095267  0.197552       6\n",
       "    7          7  1.093930e+09  5125.594407  0.160180       7\n",
       "    8          8  8.213925e+08  5099.239983  0.089347       8\n",
       "    9          9  1.378500e+09  3320.898803  0.115078       9\n",
       "    10        10  1.967238e+09  3878.558132  0.066943      10\n",
       "    11        11  1.937473e+09  5303.971140  0.051492      11\n",
       "    12        12  1.973373e+09  4718.837422  0.187653      12\n",
       "    13        13  2.334762e+09  4156.023984  0.171413      13\n",
       "    14        14  1.989451e+09  5301.096958  0.169348      14\n",
       "    15        15  2.245627e+09  3973.902321  0.114526      15\n",
       "    16        16  9.699633e+08  5954.812618  0.109306      16\n",
       "    17        17  1.298186e+09  6890.123320  0.106591      17,\n",
       "    'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "    0     moderate           0       1     1.0         3        0\n",
       "    1     moderate           0       1     1.0        12        1\n",
       "    2     moderate           0       1     1.0        13        2\n",
       "    3     moderate           0       1     1.0        13        3\n",
       "    4     moderate           0       3     3.0         5        4\n",
       "    ...        ...         ...     ...     ...       ...      ...\n",
       "    8257  moderate           0    3597  3597.0        13     8257\n",
       "    8258  moderate           0    3597  3597.0        13     8258\n",
       "    8259  moderate           0    3597  3597.0        14     8259\n",
       "    8260  moderate           0    3598  3598.0        13     8260\n",
       "    8261  moderate           0    3599  3599.0         6     8261\n",
       "    \n",
       "    [8262 rows x 6 columns],\n",
       "    'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "    0     moderate           0        0         3               1             1.0   \n",
       "    1     moderate           0        1        12               1             1.0   \n",
       "    2     moderate           0        2        13               1             1.0   \n",
       "    3     moderate           0        3        13               1             1.0   \n",
       "    4     moderate           0        4         5               3             3.0   \n",
       "    ...        ...         ...      ...       ...             ...             ...   \n",
       "    8257  moderate           0     8257        13            3597          3597.0   \n",
       "    8258  moderate           0     8258        13            3597          3597.0   \n",
       "    8259  moderate           0     8259        14            3597          3597.0   \n",
       "    8260  moderate           0     8260        13            3598          3598.0   \n",
       "    8261  moderate           0     8261         6            3599          3599.0   \n",
       "    \n",
       "              b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "    0     4.463301    1.368071e+09  6.106115e+09   59.895400    video   \n",
       "    1     2.032145    1.310597e+09  2.663323e+09   39.163837     text   \n",
       "    2     2.471461    1.423734e+09  3.518704e+09   71.265870    image   \n",
       "    3     2.097559    7.160129e+08  1.501879e+09   73.560420     text   \n",
       "    4     2.683642    9.887779e+08  2.653526e+09  114.356410    video   \n",
       "    ...        ...             ...           ...         ...      ...   \n",
       "    8257  2.391213    5.808735e+08  1.388992e+09   56.940155    video   \n",
       "    8258  2.583749    1.690439e+09  4.367671e+09   67.638040    video   \n",
       "    8259  2.405940    1.218846e+09  2.932471e+09   66.223816   sensor   \n",
       "    8260  2.014641    9.512537e+08  1.916434e+09   36.491844     text   \n",
       "    8261  4.927452    2.140466e+09  1.054704e+10   47.556170    image   \n",
       "    \n",
       "          has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "    0                0         NaN            NaN           0     0.000000   \n",
       "    1                0         NaN            NaN           1     0.619935   \n",
       "    2                0         NaN            NaN           0     0.000000   \n",
       "    3                0         NaN            NaN           1     0.667023   \n",
       "    4                1    0.868840       3.868839           0     0.000000   \n",
       "    ...            ...         ...            ...         ...          ...   \n",
       "    8257             0         NaN            NaN           0     0.000000   \n",
       "    8258             0         NaN            NaN           0     0.000000   \n",
       "    8259             1    1.438337    3598.438200           0     0.000000   \n",
       "    8260             0         NaN            NaN           1     0.493939   \n",
       "    8261             0         NaN            NaN           0     0.000000   \n",
       "    \n",
       "         action_space_hint  \n",
       "    0             discrete  \n",
       "    1           continuous  \n",
       "    2             discrete  \n",
       "    3           continuous  \n",
       "    4             discrete  \n",
       "    ...                ...  \n",
       "    8257          discrete  \n",
       "    8258          discrete  \n",
       "    8259          discrete  \n",
       "    8260        continuous  \n",
       "    8261          discrete  \n",
       "    \n",
       "    [8262 rows x 17 columns],\n",
       "    'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'cloud_cycles': array([0.])},\n",
       "    'action_space': {'type': 'discrete',\n",
       "     'n': 3,\n",
       "     'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}},\n",
       "    'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,),\n",
       "        'dtype': 'float'},\n",
       "       'mec_public_cycles': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cycles': {'shape': (1,), 'dtype': 'float'}},\n",
       "      'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}},\n",
       "      'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'public_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}},\n",
       "     'note': 'Declarative spec; tensor assembly happens in the Env at each step.'},\n",
       "    'checks': {'delta_match': True, 'message': 'OK'}}},\n",
       "  'sparse_ring': {'heavy': {'Delta': 1.0,\n",
       "    'K': 18,\n",
       "    'topology_type': 'skip_connections',\n",
       "    'connection_matrix': array([[  0.        ,   8.84365721,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   9.998233  , 110.67630067],\n",
       "           [  8.84365721,   0.        ,   9.97505999,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  92.76931356],\n",
       "           [  0.        ,   9.97505999,   0.        ,  11.95310224,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  96.02627731],\n",
       "           [  0.        ,   0.        ,  11.95310224,   0.        ,\n",
       "              9.13794468,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 119.09298037],\n",
       "           [  0.        ,   0.        ,   0.        ,   9.13794468,\n",
       "              0.        ,   8.87531982,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 116.41878804],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              8.87531982,   0.        ,   8.11860408,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 114.89278573],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   8.11860408,   0.        ,  11.80494832,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  84.22860842],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  11.80494832,   0.        ,\n",
       "             11.88844246,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  83.35489123],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,  11.88844246,\n",
       "              0.        ,  10.68030026,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 113.406384  ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             10.68030026,   0.        ,   8.33085549,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 102.93150158],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   8.33085549,   0.        ,   9.0219371 ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 117.12846943],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   9.0219371 ,   0.        ,\n",
       "              8.72814871,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  81.9905366 ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   8.72814871,\n",
       "              0.        ,   9.92346512,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  89.09483645],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              9.92346512,   0.        ,   9.77172384,   0.        ,\n",
       "              0.        ,   0.        ,  86.80566083],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   9.77172384,   0.        ,  10.16870053,\n",
       "              0.        ,   0.        ,  86.54990281],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  10.16870053,   0.        ,\n",
       "              9.18678203,   0.        , 119.58805212],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   9.18678203,\n",
       "              0.        ,  11.135163  ,  83.69352674],\n",
       "           [  9.998233  ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             11.135163  ,   0.        , 117.90994977]]),\n",
       "    'private_cpu': array([1.33775622e+09, 1.49393054e+09, 1.43997791e+09, 1.21062439e+09,\n",
       "           1.76267552e+09, 1.31132161e+09, 1.38049135e+09, 1.44709927e+09,\n",
       "           1.42518832e+09, 1.49771021e+09, 1.22897323e+09, 1.55137334e+09,\n",
       "           1.68413918e+09, 1.34491629e+09, 1.32974180e+09, 1.25644994e+09,\n",
       "           1.39636453e+09, 1.24796862e+09]),\n",
       "    'public_cpu': array([6.34923798e+08, 8.09092790e+08, 7.02435778e+08, 7.93630196e+08,\n",
       "           8.95631390e+08, 8.85066767e+08, 8.47527275e+08, 6.08503977e+08,\n",
       "           8.50440640e+08, 5.84627600e+08, 7.79588586e+08, 6.35569109e+08,\n",
       "           8.83065611e+08, 6.63393658e+08, 8.79030498e+08, 6.69585169e+08,\n",
       "           6.25279054e+08, 6.38664453e+08]),\n",
       "    'cloud_cpu': 30000000000.0,\n",
       "    'N_agents': 18,\n",
       "    'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17]),\n",
       "    'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "    0    heavy           0    1.0     3600    1.0        18   345,\n",
       "    'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
       "    0          0  1.741183e+09  5713.849721  0.708673       0\n",
       "    1          1  1.352326e+09  4566.428755  0.234989       1\n",
       "    2          2  1.726668e+09  5815.120004  0.228174       2\n",
       "    3          3  1.543616e+09  3539.850245  0.310369       3\n",
       "    4          4  1.130883e+09  4161.367769  0.548990       4\n",
       "    5          5  1.761336e+09  7349.509397  0.427498       5\n",
       "    6          6  1.093196e+09  6389.821853  0.733849       6\n",
       "    7          7  1.022066e+09  5354.805771  0.492160       7\n",
       "    8          8  1.280853e+09  3931.170813  0.647444       8\n",
       "    9          9  1.260889e+09  5133.304392  0.434945       9\n",
       "    10        10  8.077840e+08  6774.364061  0.696332      10\n",
       "    11        11  1.252718e+09  5907.761753  0.250139      11\n",
       "    12        12  1.849537e+09  4251.816941  0.275633      12\n",
       "    13        13  2.013685e+09  3452.486291  0.387815      13\n",
       "    14        14  1.566043e+09  6514.168780  0.410745      14\n",
       "    15        15  1.573528e+09  7018.517023  0.746995      15\n",
       "    16        16  1.386095e+09  6122.347442  0.414992      16\n",
       "    17        17  1.604826e+09  3449.292167  0.516951      17,\n",
       "    'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "    0        heavy           0       0     0.0         0        0\n",
       "    1        heavy           0       0     0.0         1        1\n",
       "    2        heavy           0       0     0.0         4        2\n",
       "    3        heavy           0       0     0.0         7        3\n",
       "    4        heavy           0       0     0.0        10        4\n",
       "    ...        ...         ...     ...     ...       ...      ...\n",
       "    30631    heavy           0    3599  3599.0         5    30631\n",
       "    30632    heavy           0    3599  3599.0         6    30632\n",
       "    30633    heavy           0    3599  3599.0         6    30633\n",
       "    30634    heavy           0    3599  3599.0         7    30634\n",
       "    30635    heavy           0    3599  3599.0         7    30635\n",
       "    \n",
       "    [30636 rows x 6 columns],\n",
       "    'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "    0        heavy           0        0         0               0             0.0   \n",
       "    1        heavy           0        1         1               0             0.0   \n",
       "    2        heavy           0        2         4               0             0.0   \n",
       "    3        heavy           0        3         7               0             0.0   \n",
       "    4        heavy           0        4        10               0             0.0   \n",
       "    ...        ...         ...      ...       ...             ...             ...   \n",
       "    30631    heavy           0    30631         5            3599          3599.0   \n",
       "    30632    heavy           0    30632         6            3599          3599.0   \n",
       "    30633    heavy           0    30633         6            3599          3599.0   \n",
       "    30634    heavy           0    30634         7            3599          3599.0   \n",
       "    30635    heavy           0    30635         7            3599          3599.0   \n",
       "    \n",
       "                b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "    0       7.202096    9.727147e+08  7.005585e+09   66.611010   sensor   \n",
       "    1       5.479984    1.314973e+09  7.206031e+09   77.928800    image   \n",
       "    2       8.421977    2.500222e+09  2.105681e+10   72.966446     text   \n",
       "    3       6.324986    1.779582e+09  1.125583e+10   56.492900   sensor   \n",
       "    4      11.473269    1.087572e+09  1.247800e+10   73.389854   sensor   \n",
       "    ...          ...             ...           ...         ...      ...   \n",
       "    30631   6.238504    1.090296e+09  6.801814e+09   69.218260    video   \n",
       "    30632   3.289880    1.599958e+09  5.263669e+09   39.210260   sensor   \n",
       "    30633   6.192005    8.322764e+08  5.153459e+09   73.052900   sensor   \n",
       "    30634   3.244716    1.627807e+09  5.281771e+09  103.576775    image   \n",
       "    30635   1.736996    2.141823e+09  3.720338e+09   92.836210     text   \n",
       "    \n",
       "           has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "    0                 1    0.800726       0.800726           0     0.000000   \n",
       "    1                 1    0.615113       0.615113           0     0.000000   \n",
       "    2                 1    0.323007       0.323007           1     0.539704   \n",
       "    3                 1    0.481587       0.481587           0     0.000000   \n",
       "    4                 1    0.594564       0.594564           0     0.000000   \n",
       "    ...             ...         ...            ...         ...          ...   \n",
       "    30631             1    0.525271    3599.525400           1     0.605597   \n",
       "    30632             0         NaN            NaN           0     0.000000   \n",
       "    30633             0         NaN            NaN           1     0.566783   \n",
       "    30634             0         NaN            NaN           1     0.706580   \n",
       "    30635             1    0.763454    3599.763400           0     0.000000   \n",
       "    \n",
       "          action_space_hint  \n",
       "    0              discrete  \n",
       "    1              discrete  \n",
       "    2            continuous  \n",
       "    3              discrete  \n",
       "    4              discrete  \n",
       "    ...                 ...  \n",
       "    30631        continuous  \n",
       "    30632          discrete  \n",
       "    30633        continuous  \n",
       "    30634        continuous  \n",
       "    30635          discrete  \n",
       "    \n",
       "    [30636 rows x 17 columns],\n",
       "    'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'cloud_cycles': array([0.])},\n",
       "    'action_space': {'type': 'discrete',\n",
       "     'n': 3,\n",
       "     'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}},\n",
       "    'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,),\n",
       "        'dtype': 'float'},\n",
       "       'mec_public_cycles': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cycles': {'shape': (1,), 'dtype': 'float'}},\n",
       "      'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}},\n",
       "      'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'public_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}},\n",
       "     'note': 'Declarative spec; tensor assembly happens in the Env at each step.'},\n",
       "    'checks': {'delta_match': True, 'message': 'OK'}},\n",
       "   'light': {'Delta': 1.0,\n",
       "    'K': 18,\n",
       "    'topology_type': 'skip_connections',\n",
       "    'connection_matrix': array([[  0.        ,   8.84365721,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   9.998233  , 110.67630067],\n",
       "           [  8.84365721,   0.        ,   9.97505999,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  92.76931356],\n",
       "           [  0.        ,   9.97505999,   0.        ,  11.95310224,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  96.02627731],\n",
       "           [  0.        ,   0.        ,  11.95310224,   0.        ,\n",
       "              9.13794468,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 119.09298037],\n",
       "           [  0.        ,   0.        ,   0.        ,   9.13794468,\n",
       "              0.        ,   8.87531982,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 116.41878804],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              8.87531982,   0.        ,   8.11860408,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 114.89278573],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   8.11860408,   0.        ,  11.80494832,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  84.22860842],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  11.80494832,   0.        ,\n",
       "             11.88844246,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  83.35489123],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,  11.88844246,\n",
       "              0.        ,  10.68030026,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 113.406384  ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             10.68030026,   0.        ,   8.33085549,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 102.93150158],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   8.33085549,   0.        ,   9.0219371 ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 117.12846943],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   9.0219371 ,   0.        ,\n",
       "              8.72814871,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  81.9905366 ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   8.72814871,\n",
       "              0.        ,   9.92346512,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  89.09483645],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              9.92346512,   0.        ,   9.77172384,   0.        ,\n",
       "              0.        ,   0.        ,  86.80566083],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   9.77172384,   0.        ,  10.16870053,\n",
       "              0.        ,   0.        ,  86.54990281],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  10.16870053,   0.        ,\n",
       "              9.18678203,   0.        , 119.58805212],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   9.18678203,\n",
       "              0.        ,  11.135163  ,  83.69352674],\n",
       "           [  9.998233  ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             11.135163  ,   0.        , 117.90994977]]),\n",
       "    'private_cpu': array([1.33775622e+09, 1.49393054e+09, 1.43997791e+09, 1.21062439e+09,\n",
       "           1.76267552e+09, 1.31132161e+09, 1.38049135e+09, 1.44709927e+09,\n",
       "           1.42518832e+09, 1.49771021e+09, 1.22897323e+09, 1.55137334e+09,\n",
       "           1.68413918e+09, 1.34491629e+09, 1.32974180e+09, 1.25644994e+09,\n",
       "           1.39636453e+09, 1.24796862e+09]),\n",
       "    'public_cpu': array([6.34923798e+08, 8.09092790e+08, 7.02435778e+08, 7.93630196e+08,\n",
       "           8.95631390e+08, 8.85066767e+08, 8.47527275e+08, 6.08503977e+08,\n",
       "           8.50440640e+08, 5.84627600e+08, 7.79588586e+08, 6.35569109e+08,\n",
       "           8.83065611e+08, 6.63393658e+08, 8.79030498e+08, 6.69585169e+08,\n",
       "           6.25279054e+08, 6.38664453e+08]),\n",
       "    'cloud_cpu': 30000000000.0,\n",
       "    'N_agents': 18,\n",
       "    'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17]),\n",
       "    'episodes':   scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "    0    light           0    1.0     3600    1.0        18   143,\n",
       "    'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
       "    0          0  9.214683e+08  5152.146294  0.021214       0\n",
       "    1          1  1.988512e+09  4208.470915  0.030254       1\n",
       "    2          2  1.361339e+09  4466.022492  0.028701       2\n",
       "    3          3  2.155303e+09  7570.283244  0.038873       3\n",
       "    4          4  8.727403e+08  6918.455560  0.037506       4\n",
       "    5          5  2.350478e+09  7997.219317  0.013920       5\n",
       "    6          6  1.080474e+09  3611.664818  0.031591       6\n",
       "    7          7  1.483437e+09  5690.301814  0.026184       7\n",
       "    8          8  1.782616e+09  5312.418573  0.040268       8\n",
       "    9          9  2.164538e+09  6264.107462  0.048391       9\n",
       "    10        10  2.381892e+09  5233.485875  0.039955      10\n",
       "    11        11  1.698112e+09  5619.134661  0.037599      11\n",
       "    12        12  1.170523e+09  5302.008006  0.034852      12\n",
       "    13        13  1.004000e+09  6356.746540  0.027640      13\n",
       "    14        14  1.206141e+09  4332.462100  0.038611      14\n",
       "    15        15  2.062918e+09  5181.575792  0.042660      15\n",
       "    16        16  1.493700e+09  6776.846182  0.026377      16\n",
       "    17        17  1.302068e+09  6167.829828  0.025928      17,\n",
       "    'arrivals':      scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "    0       light           0       0     0.0         1        0\n",
       "    1       light           0       0     0.0        17        1\n",
       "    2       light           0       7     7.0        17        2\n",
       "    3       light           0       9     9.0         3        3\n",
       "    4       light           0      13    13.0        15        4\n",
       "    ...       ...         ...     ...     ...       ...      ...\n",
       "    2108    light           0    3594  3594.0        14     2108\n",
       "    2109    light           0    3597  3597.0        11     2109\n",
       "    2110    light           0    3597  3597.0        16     2110\n",
       "    2111    light           0    3598  3598.0        14     2111\n",
       "    2112    light           0    3599  3599.0        17     2112\n",
       "    \n",
       "    [2113 rows x 6 columns],\n",
       "    'tasks':      scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "    0       light           0        0         1               0             0.0   \n",
       "    1       light           0        1        17               0             0.0   \n",
       "    2       light           0        2        17               7             7.0   \n",
       "    3       light           0        3         3               9             9.0   \n",
       "    4       light           0        4        15              13            13.0   \n",
       "    ...       ...         ...      ...       ...             ...             ...   \n",
       "    2108    light           0     2108        14            3594          3594.0   \n",
       "    2109    light           0     2109        11            3597          3597.0   \n",
       "    2110    light           0     2110        16            3597          3597.0   \n",
       "    2111    light           0     2111        14            3598          3598.0   \n",
       "    2112    light           0     2112        17            3599          3599.0   \n",
       "    \n",
       "              b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "    0     2.484967    5.525261e+08  1.373009e+09   62.412148    video   \n",
       "    1     2.509962    1.082130e+09  2.716106e+09   74.606000     text   \n",
       "    2     1.509317    1.757732e+09  2.652974e+09   30.173971     text   \n",
       "    3     2.114311    4.582521e+08  9.688874e+08   52.914295    image   \n",
       "    4     1.707707    6.574788e+08  1.122781e+09   95.441150    image   \n",
       "    ...        ...             ...           ...         ...      ...   \n",
       "    2108  2.306310    1.006178e+09  2.320560e+09   64.688480     text   \n",
       "    2109  3.687047    1.297120e+09  4.782541e+09  106.002625   sensor   \n",
       "    2110  2.407504    9.582727e+08  2.307045e+09   65.863180    image   \n",
       "    2111  1.205960    1.482103e+09  1.787356e+09   65.631966    image   \n",
       "    2112  1.339075    4.337156e+08  5.807776e+08   81.440796    video   \n",
       "    \n",
       "          has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "    0                1    1.339893       1.339893           1     0.424900   \n",
       "    1                0         NaN            NaN           0     0.000000   \n",
       "    2                0         NaN            NaN           1     0.358162   \n",
       "    3                0         NaN            NaN           0     0.000000   \n",
       "    4                0         NaN            NaN           0     0.000000   \n",
       "    ...            ...         ...            ...         ...          ...   \n",
       "    2108             0         NaN            NaN           0     0.000000   \n",
       "    2109             0         NaN            NaN           0     0.000000   \n",
       "    2110             0         NaN            NaN           1     0.393362   \n",
       "    2111             0         NaN            NaN           0     0.000000   \n",
       "    2112             0         NaN            NaN           0     0.000000   \n",
       "    \n",
       "         action_space_hint  \n",
       "    0           continuous  \n",
       "    1             discrete  \n",
       "    2           continuous  \n",
       "    3             discrete  \n",
       "    4             discrete  \n",
       "    ...                ...  \n",
       "    2108          discrete  \n",
       "    2109          discrete  \n",
       "    2110        continuous  \n",
       "    2111          discrete  \n",
       "    2112          discrete  \n",
       "    \n",
       "    [2113 rows x 17 columns],\n",
       "    'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'cloud_cycles': array([0.])},\n",
       "    'action_space': {'type': 'discrete',\n",
       "     'n': 3,\n",
       "     'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}},\n",
       "    'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,),\n",
       "        'dtype': 'float'},\n",
       "       'mec_public_cycles': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cycles': {'shape': (1,), 'dtype': 'float'}},\n",
       "      'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}},\n",
       "      'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'public_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}},\n",
       "     'note': 'Declarative spec; tensor assembly happens in the Env at each step.'},\n",
       "    'checks': {'delta_match': True, 'message': 'OK'}},\n",
       "   'moderate': {'Delta': 1.0,\n",
       "    'K': 18,\n",
       "    'topology_type': 'skip_connections',\n",
       "    'connection_matrix': array([[  0.        ,   8.84365721,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   9.998233  , 110.67630067],\n",
       "           [  8.84365721,   0.        ,   9.97505999,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  92.76931356],\n",
       "           [  0.        ,   9.97505999,   0.        ,  11.95310224,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  96.02627731],\n",
       "           [  0.        ,   0.        ,  11.95310224,   0.        ,\n",
       "              9.13794468,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 119.09298037],\n",
       "           [  0.        ,   0.        ,   0.        ,   9.13794468,\n",
       "              0.        ,   8.87531982,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 116.41878804],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              8.87531982,   0.        ,   8.11860408,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 114.89278573],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   8.11860408,   0.        ,  11.80494832,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  84.22860842],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  11.80494832,   0.        ,\n",
       "             11.88844246,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  83.35489123],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,  11.88844246,\n",
       "              0.        ,  10.68030026,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 113.406384  ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             10.68030026,   0.        ,   8.33085549,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 102.93150158],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   8.33085549,   0.        ,   9.0219371 ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        , 117.12846943],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   9.0219371 ,   0.        ,\n",
       "              8.72814871,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  81.9905366 ],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   8.72814871,\n",
       "              0.        ,   9.92346512,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  89.09483645],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              9.92346512,   0.        ,   9.77172384,   0.        ,\n",
       "              0.        ,   0.        ,  86.80566083],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   9.77172384,   0.        ,  10.16870053,\n",
       "              0.        ,   0.        ,  86.54990281],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,  10.16870053,   0.        ,\n",
       "              9.18678203,   0.        , 119.58805212],\n",
       "           [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   9.18678203,\n",
       "              0.        ,  11.135163  ,  83.69352674],\n",
       "           [  9.998233  ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "              0.        ,   0.        ,   0.        ,   0.        ,\n",
       "             11.135163  ,   0.        , 117.90994977]]),\n",
       "    'private_cpu': array([1.33775622e+09, 1.49393054e+09, 1.43997791e+09, 1.21062439e+09,\n",
       "           1.76267552e+09, 1.31132161e+09, 1.38049135e+09, 1.44709927e+09,\n",
       "           1.42518832e+09, 1.49771021e+09, 1.22897323e+09, 1.55137334e+09,\n",
       "           1.68413918e+09, 1.34491629e+09, 1.32974180e+09, 1.25644994e+09,\n",
       "           1.39636453e+09, 1.24796862e+09]),\n",
       "    'public_cpu': array([6.34923798e+08, 8.09092790e+08, 7.02435778e+08, 7.93630196e+08,\n",
       "           8.95631390e+08, 8.85066767e+08, 8.47527275e+08, 6.08503977e+08,\n",
       "           8.50440640e+08, 5.84627600e+08, 7.79588586e+08, 6.35569109e+08,\n",
       "           8.83065611e+08, 6.63393658e+08, 8.79030498e+08, 6.69585169e+08,\n",
       "           6.25279054e+08, 6.38664453e+08]),\n",
       "    'cloud_cpu': 30000000000.0,\n",
       "    'N_agents': 18,\n",
       "    'agent_to_mec': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "           17]),\n",
       "    'episodes':    scenario  episode_id  Delta  T_slots  hours  N_agents  seed\n",
       "    0  moderate           0    1.0     3600    1.0        18   244,\n",
       "    'agents':     agent_id       f_local      m_local   lam_sec  mec_id\n",
       "    0          0  2.075234e+09  4177.077472  0.083588       0\n",
       "    1          1  1.845675e+09  4444.750864  0.117454       1\n",
       "    2          2  1.422351e+09  3116.790674  0.190249       2\n",
       "    3          3  8.627662e+08  3819.530831  0.180022       3\n",
       "    4          4  1.576391e+09  4456.416731  0.124874       4\n",
       "    5          5  1.361574e+09  6518.273845  0.093241       5\n",
       "    6          6  1.146421e+09  4031.095267  0.197552       6\n",
       "    7          7  1.093930e+09  5125.594407  0.160180       7\n",
       "    8          8  8.213925e+08  5099.239983  0.089347       8\n",
       "    9          9  1.378500e+09  3320.898803  0.115078       9\n",
       "    10        10  1.967238e+09  3878.558132  0.066943      10\n",
       "    11        11  1.937473e+09  5303.971140  0.051492      11\n",
       "    12        12  1.973373e+09  4718.837422  0.187653      12\n",
       "    13        13  2.334762e+09  4156.023984  0.171413      13\n",
       "    14        14  1.989451e+09  5301.096958  0.169348      14\n",
       "    15        15  2.245627e+09  3973.902321  0.114526      15\n",
       "    16        16  9.699633e+08  5954.812618  0.109306      16\n",
       "    17        17  1.298186e+09  6890.123320  0.106591      17,\n",
       "    'arrivals':       scenario  episode_id  t_slot  t_time  agent_id  task_id\n",
       "    0     moderate           0       1     1.0         3        0\n",
       "    1     moderate           0       1     1.0        12        1\n",
       "    2     moderate           0       1     1.0        13        2\n",
       "    3     moderate           0       1     1.0        13        3\n",
       "    4     moderate           0       3     3.0         5        4\n",
       "    ...        ...         ...     ...     ...       ...      ...\n",
       "    8257  moderate           0    3597  3597.0        13     8257\n",
       "    8258  moderate           0    3597  3597.0        13     8258\n",
       "    8259  moderate           0    3597  3597.0        14     8259\n",
       "    8260  moderate           0    3598  3598.0        13     8260\n",
       "    8261  moderate           0    3599  3599.0         6     8261\n",
       "    \n",
       "    [8262 rows x 6 columns],\n",
       "    'tasks':       scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "    0     moderate           0        0         3               1             1.0   \n",
       "    1     moderate           0        1        12               1             1.0   \n",
       "    2     moderate           0        2        13               1             1.0   \n",
       "    3     moderate           0        3        13               1             1.0   \n",
       "    4     moderate           0        4         5               3             3.0   \n",
       "    ...        ...         ...      ...       ...             ...             ...   \n",
       "    8257  moderate           0     8257        13            3597          3597.0   \n",
       "    8258  moderate           0     8258        13            3597          3597.0   \n",
       "    8259  moderate           0     8259        14            3597          3597.0   \n",
       "    8260  moderate           0     8260        13            3598          3598.0   \n",
       "    8261  moderate           0     8261         6            3599          3599.0   \n",
       "    \n",
       "              b_mb  rho_cyc_per_mb      c_cycles      mem_mb modality  \\\n",
       "    0     4.463301    1.368071e+09  6.106115e+09   59.895400    video   \n",
       "    1     2.032145    1.310597e+09  2.663323e+09   39.163837     text   \n",
       "    2     2.471461    1.423734e+09  3.518704e+09   71.265870    image   \n",
       "    3     2.097559    7.160129e+08  1.501879e+09   73.560420     text   \n",
       "    4     2.683642    9.887779e+08  2.653526e+09  114.356410    video   \n",
       "    ...        ...             ...           ...         ...      ...   \n",
       "    8257  2.391213    5.808735e+08  1.388992e+09   56.940155    video   \n",
       "    8258  2.583749    1.690439e+09  4.367671e+09   67.638040    video   \n",
       "    8259  2.405940    1.218846e+09  2.932471e+09   66.223816   sensor   \n",
       "    8260  2.014641    9.512537e+08  1.916434e+09   36.491844     text   \n",
       "    8261  4.927452    2.140466e+09  1.054704e+10   47.556170    image   \n",
       "    \n",
       "          has_deadline  deadline_s  deadline_time  non_atomic  split_ratio  \\\n",
       "    0                0         NaN            NaN           0     0.000000   \n",
       "    1                0         NaN            NaN           1     0.619935   \n",
       "    2                0         NaN            NaN           0     0.000000   \n",
       "    3                0         NaN            NaN           1     0.667023   \n",
       "    4                1    0.868840       3.868839           0     0.000000   \n",
       "    ...            ...         ...            ...         ...          ...   \n",
       "    8257             0         NaN            NaN           0     0.000000   \n",
       "    8258             0         NaN            NaN           0     0.000000   \n",
       "    8259             1    1.438337    3598.438200           0     0.000000   \n",
       "    8260             0         NaN            NaN           1     0.493939   \n",
       "    8261             0         NaN            NaN           0     0.000000   \n",
       "    \n",
       "         action_space_hint  \n",
       "    0             discrete  \n",
       "    1           continuous  \n",
       "    2             discrete  \n",
       "    3           continuous  \n",
       "    4             discrete  \n",
       "    ...                ...  \n",
       "    8257          discrete  \n",
       "    8258          discrete  \n",
       "    8259          discrete  \n",
       "    8260        continuous  \n",
       "    8261          discrete  \n",
       "    \n",
       "    [8262 rows x 17 columns],\n",
       "    'queues_initial': {'mec_local_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_public_cycles': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'mec_bytes_in_transit': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0.]),\n",
       "     'cloud_cycles': array([0.])},\n",
       "    'action_space': {'type': 'discrete',\n",
       "     'n': 3,\n",
       "     'labels': {0: 'LOCAL', 1: 'MEC', 2: 'CLOUD'}},\n",
       "    'state_spec': {'components': {'queues': {'mec_local_cycles': {'shape': (18,),\n",
       "        'dtype': 'float'},\n",
       "       'mec_public_cycles': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cycles': {'shape': (1,), 'dtype': 'float'}},\n",
       "      'links': {'connection_matrix': {'shape': (18, 19), 'dtype': 'float'}},\n",
       "      'capacities': {'private_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'public_cpu': {'shape': (18,), 'dtype': 'float'},\n",
       "       'cloud_cpu': {'shape': (1,), 'dtype': 'float'}}},\n",
       "     'note': 'Declarative spec; tensor assembly happens in the Env at each step.'},\n",
       "    'checks': {'delta_match': True, 'message': 'OK'}}}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run all sanity checks\n",
    "sanity_check_all(env_configs)\n",
    "\n",
    "print(\"env_configs: \\n\", env_configs)\n",
    "\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "display(env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] env_configs summary → ./artifacts/env_configs_summary.txt\n"
     ]
    }
   ],
   "source": [
    "def _summarize_array(arr, max_items=6):\n",
    "    \"\"\"Return a short, readable summary string for numpy arrays.\"\"\"\n",
    "    try:\n",
    "        arr = np.asarray(arr)\n",
    "        base = f\"ndarray shape={arr.shape}, dtype={arr.dtype}\"\n",
    "        if arr.size == 0:\n",
    "            return base + \" | empty\"\n",
    "        # Show a few values only if it's 1D or small\n",
    "        if arr.ndim == 1 and arr.size <= max_items:\n",
    "            return base + f\" | values={arr.tolist()}\"\n",
    "        # Stats if numeric\n",
    "        if np.issubdtype(arr.dtype, np.number):\n",
    "            return base + f\" | min={np.nanmin(arr):.4g}, max={np.nanmax(arr):.4g}, mean={np.nanmean(arr):.4g}\"\n",
    "        return base\n",
    "    except Exception as e:\n",
    "        return f\"(array summary failed: {e})\"\n",
    "\n",
    "def _summarize_df(df: pd.DataFrame, max_cols=10):\n",
    "    \"\"\"Return a short summary string for DataFrames.\"\"\"\n",
    "    try:\n",
    "        cols = df.columns.tolist()\n",
    "        cols_show = cols[:max_cols] + ([\"...\"] if len(cols) > max_cols else [])\n",
    "        return f\"DataFrame shape={df.shape}, columns={cols_show}\"\n",
    "    except Exception as e:\n",
    "        return f\"(dataframe summary failed: {e})\"\n",
    "\n",
    "def _summarize_any(name, obj, indent=\"    \"):\n",
    "    \"\"\"Create a few readable lines summarizing an object by type.\"\"\"\n",
    "    lines = []\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        lines.append(f\"{indent}{name}: {_summarize_df(obj)}\")\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        lines.append(f\"{indent}{name}: {_summarize_array(obj)}\")\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        preview = obj[:6] if len(obj) > 6 else obj\n",
    "        lines.append(f\"{indent}{name}: list len={len(obj)}, preview={preview}\")\n",
    "    elif isinstance(obj, dict):\n",
    "        lines.append(f\"{indent}{name}: dict keys={list(obj.keys())}\")\n",
    "        # If it's the queues dict or small dict, briefly dive one level\n",
    "        if name == \"queues_initial\" or len(obj) <= 6:\n",
    "            for k, v in obj.items():\n",
    "                sub = _summarize_any(k, v, indent=indent + \"  \")\n",
    "                lines.extend(sub if isinstance(sub, list) else [sub])\n",
    "    elif isinstance(obj, (int, float, str, bool, type(None))):\n",
    "        lines.append(f\"{indent}{name}: {repr(obj)}\")\n",
    "    else:\n",
    "        # Try numpy conversion\n",
    "        try:\n",
    "            arr = np.asarray(obj)\n",
    "            lines.append(f\"{indent}{name}: {_summarize_array(arr)}\")\n",
    "        except Exception:\n",
    "            lines.append(f\"{indent}{name}: ({type(obj).__name__})\")\n",
    "    return lines\n",
    "\n",
    "def save_env_configs_text(env_configs, out_path=\"./artifacts/env_configs_summary.txt\"):\n",
    "    \"\"\"\n",
    "    Save a human-readable summary of env_configs (episode → topology → scenario) to a text file.\n",
    "    Includes shapes of DataFrames, key columns, array shapes/stats, and key scalar parameters.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    lines = []\n",
    "    lines.append(\"=== ENV CONFIGS SUMMARY (episode → topology → scenario) ===\\n\")\n",
    "\n",
    "    # Iterate deterministic order for reproducibility\n",
    "    for ep_name in sorted(env_configs.keys()):\n",
    "        lines.append(f\"[EPISODE] {ep_name}\")\n",
    "        by_topo = env_configs[ep_name]\n",
    "        for topo_name in sorted(by_topo.keys()):\n",
    "            lines.append(f\"  [TOPOLOGY] {topo_name}\")\n",
    "            by_scen = by_topo[topo_name]\n",
    "            for scen_name in sorted(by_scen.keys()):\n",
    "                env_cfg = by_scen[scen_name]\n",
    "                lines.append(f\"    [SCENARIO] {scen_name}\")\n",
    "\n",
    "                # Highlight most relevant scalars first if present\n",
    "                for key in [\"Delta\", \"K\", \"N_agents\", \"topology_type\"]:\n",
    "                    if key in env_cfg:\n",
    "                        lines.extend(_summarize_any(key, env_cfg[key], indent=\"      \"))\n",
    "\n",
    "                # Then summarize major tensors/arrays\n",
    "                for key in [\"connection_matrix\", \"private_cpu\", \"public_cpu\", \"cloud_cpu\", \"agent_to_mec\"]:\n",
    "                    if key in env_cfg:\n",
    "                        lines.extend(_summarize_any(key, env_cfg[key], indent=\"      \"))\n",
    "\n",
    "                # Then summarize DataFrames (episodes, agents, arrivals, tasks)\n",
    "                for key in [\"episodes\", \"agents\", \"arrivals\", \"tasks\"]:\n",
    "                    if key in env_cfg:\n",
    "                        lines.extend(_summarize_any(key, env_cfg[key], indent=\"      \"))\n",
    "\n",
    "                # Queues + RL descriptors (optional)\n",
    "                for key in [\"queues_initial\", \"action_space\", \"state_spec\", \"checks\"]:\n",
    "                    if key in env_cfg:\n",
    "                        lines.extend(_summarize_any(key, env_cfg[key], indent=\"      \"))\n",
    "\n",
    "                lines.append(\"\")  # blank line between scenarios\n",
    "\n",
    "            lines.append(\"\")  # blank line between topologies\n",
    "        lines.append(\"\")      # blank line between episodes\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(f\"[saved] env_configs summary → {out_path}\")\n",
    "\n",
    "# ---- usage ----\n",
    "save_env_configs_text(env_configs, out_path=\"./artifacts/env_configs_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Step 1, we have loaded the data, aligned the units, assigned agents to MECs, and prepared the environment configuration. Finally, we have performed consistency checks to ensure the data is correct. Next, we can move on to task labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Step 2: Task Labeling </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.1. Basic Task Labeling (buckets, urgency, atomicity, ...) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- helpers: quantile-based cut points ----------\n",
    "def _quantile_cutpoints(s: pd.Series, q_low=0.33, q_high=0.66) -> Tuple[float, float]:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "    if len(s) == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    return (float(s.quantile(q_low)), float(s.quantile(q_high)))\n",
    "\n",
    "def _bucketize(value: float, q1: float, q2: float) -> str:\n",
    "    # Returns 'S', 'M', 'L' based on two cut points (q1<=q2)\n",
    "    if not np.isfinite(value) or not np.isfinite(q1) or not np.isfinite(q2):\n",
    "        return \"U\"  # Unknown\n",
    "    if value <= q1: return \"S\"\n",
    "    if value <= q2: return \"M\"\n",
    "    return \"L\"\n",
    "\n",
    "# ---------- threshold builder (adaptive to each tasks DF) ----------\n",
    "def build_task_label_thresholds(tasks_df: pd.DataFrame,\n",
    "                                q_low=0.33, q_high=0.66,\n",
    "                                urgent_slots_cap: int = 2) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build adaptive thresholds from the data itself (per-episode/senario),\n",
    "    so 'light/moderate/heavy' are handled robustly.\n",
    "    \"\"\"\n",
    "    q_b_mb   = _quantile_cutpoints(tasks_df[\"b_mb\"], q_low, q_high) if \"b_mb\" in tasks_df else (np.nan, np.nan)\n",
    "    q_rho    = _quantile_cutpoints(tasks_df[\"rho_cyc_per_mb\"], q_low, q_high) if \"rho_cyc_per_mb\" in tasks_df else (np.nan, np.nan)\n",
    "    q_mem    = _quantile_cutpoints(tasks_df[\"mem_mb\"], q_low, q_high) if \"mem_mb\" in tasks_df else (np.nan, np.nan)\n",
    "    q_split  = _quantile_cutpoints(tasks_df.loc[tasks_df.get(\"non_atomic\", 0)==1, \"split_ratio\"], q_low, q_high) \\\n",
    "               if \"split_ratio\" in tasks_df else (np.nan, np.nan)\n",
    "\n",
    "    return {\n",
    "        \"b_mb\":   {\"q1\": q_b_mb[0],  \"q2\": q_b_mb[1]},\n",
    "        \"rho\":    {\"q1\": q_rho[0],   \"q2\": q_rho[1]},\n",
    "        \"mem\":    {\"q1\": q_mem[0],   \"q2\": q_mem[1]},\n",
    "        \"split\":  {\"q1\": q_split[0], \"q2\": q_split[1]},\n",
    "        # If deadline_slots ≤ urgent_slots_cap → 'hard' (latency sensitive)\n",
    "        \"urgent_slots_cap\": int(urgent_slots_cap),\n",
    "    }\n",
    "\n",
    "# ---------- main labeling for a single tasks DF ----------\n",
    "def label_tasks_df(tasks_df: pd.DataFrame, Delta: float, thresholds: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add label columns to tasks_df (returns a COPY).\n",
    "    Columns added:\n",
    "      - size_bucket, compute_bucket, mem_bucket\n",
    "      - deadline_slots (if missing), urgency (none/soft/hard)\n",
    "      - atomicity, split_bucket\n",
    "      - latency_sensitive, compute_heavy, io_heavy, memory_heavy (bools)\n",
    "      - routing_hint (LOCAL/MEC/CLOUD)\n",
    "    \"\"\"\n",
    "    df = tasks_df.copy()\n",
    "\n",
    "    # --- ensure numeric types\n",
    "    for col in [\"b_mb\", \"rho_cyc_per_mb\", \"c_cycles\", \"mem_mb\", \"deadline_s\", \"split_ratio\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # --- deadline_slots (if not precomputed in Units Alignment)\n",
    "    if \"deadline_slots\" not in df.columns:\n",
    "        if \"has_deadline\" in df.columns and \"deadline_s\" in df.columns:\n",
    "            df[\"deadline_slots\"] = np.where(\n",
    "                (df[\"has_deadline\"] == 1) & np.isfinite(df[\"deadline_s\"]),\n",
    "                np.ceil(df[\"deadline_s\"] / float(Delta)).astype(\"float\"),\n",
    "                np.nan\n",
    "            )\n",
    "        else:\n",
    "            df[\"deadline_slots\"] = np.nan\n",
    "\n",
    "    # --- bucketize size/compute/memory\n",
    "    b_q1, b_q2   = thresholds[\"b_mb\"][\"q1\"], thresholds[\"b_mb\"][\"q2\"]\n",
    "    rho_q1, rho_q2 = thresholds[\"rho\"][\"q1\"], thresholds[\"rho\"][\"q2\"]\n",
    "    mem_q1, mem_q2 = thresholds[\"mem\"][\"q1\"], thresholds[\"mem\"][\"q2\"]\n",
    "\n",
    "    df[\"size_bucket\"]    = df[\"b_mb\"].apply(lambda x: _bucketize(x, b_q1, b_q2)) if \"b_mb\" in df else \"U\"\n",
    "    df[\"compute_bucket\"] = df[\"rho_cyc_per_mb\"].apply(lambda x: _bucketize(x, rho_q1, rho_q2)) if \"rho_cyc_per_mb\" in df else \"U\"\n",
    "    df[\"mem_bucket\"]     = df[\"mem_mb\"].apply(lambda x: _bucketize(x, mem_q1, mem_q2)) if \"mem_mb\" in df else \"U\"\n",
    "\n",
    "    # --- atomicity & split buckets\n",
    "    if \"non_atomic\" in df.columns:\n",
    "        df[\"atomicity\"] = np.where(df[\"non_atomic\"] == 1, \"splittable\", \"atomic\")\n",
    "    else:\n",
    "        df[\"atomicity\"] = \"atomic\"\n",
    "\n",
    "    if \"split_ratio\" in df.columns:\n",
    "        sp_q1, sp_q2 = thresholds[\"split\"][\"q1\"], thresholds[\"split\"][\"q2\"]\n",
    "        df[\"split_bucket\"] = np.where(\n",
    "            df[\"atomicity\"] == \"splittable\",\n",
    "            df[\"split_ratio\"].apply(lambda v: _bucketize(v, sp_q1, sp_q2)),\n",
    "            \"NA\"\n",
    "        )\n",
    "    else:\n",
    "        df[\"split_bucket\"] = \"NA\"\n",
    "\n",
    "    # --- urgency levels\n",
    "    urgent_cap = int(thresholds.get(\"urgent_slots_cap\", 2))\n",
    "    def _urg(row):\n",
    "        if int(row.get(\"has_deadline\", 0)) != 1 or not np.isfinite(row.get(\"deadline_slots\", np.nan)):\n",
    "            return \"none\"\n",
    "        slots = int(row[\"deadline_slots\"])\n",
    "        if slots <= urgent_cap:  # very tight deadline\n",
    "            return \"hard\"\n",
    "        return \"soft\"\n",
    "    df[\"urgency\"] = df.apply(_urg, axis=1)\n",
    "\n",
    "    # --- boolean convenience labels\n",
    "    df[\"latency_sensitive\"] = (df[\"urgency\"] == \"hard\")\n",
    "    df[\"compute_heavy\"]     = (df[\"compute_bucket\"] == \"L\")\n",
    "    df[\"io_heavy\"]          = (df[\"size_bucket\"] == \"L\")\n",
    "    df[\"memory_heavy\"]      = (df[\"mem_bucket\"] == \"L\")\n",
    "\n",
    "    # --- a very simple routing hint (only for debugging/EDA; not used by the RL policy)\n",
    "    def _hint(row):\n",
    "        if row[\"compute_heavy\"] or row[\"memory_heavy\"]:\n",
    "            return \"CLOUD\"\n",
    "        if row[\"latency_sensitive\"]:\n",
    "            return \"MEC\"\n",
    "        return \"LOCAL\"\n",
    "    df[\"routing_hint\"] = df.apply(_hint, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------- batch apply to env_configs (topology → episode → scenario) ----------\n",
    "def label_all_tasks_in_env_configs(env_configs: Dict[str, Dict[str, Dict[str, Any]]],\n",
    "                                   q_low=0.33, q_high=0.66, urgent_slots_cap=2,\n",
    "                                   verbose=True) -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    For each env_config:\n",
    "      - build thresholds from its own tasks DF\n",
    "      - label tasks\n",
    "      - put labeled DF back into env_config[\"tasks\"]\n",
    "      - return a concise summary per bundle\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "\n",
    "    for topo_name, by_ep in env_configs.items():\n",
    "        summary[topo_name] = {}\n",
    "        for ep_name, by_scen in by_ep.items():\n",
    "            summary[topo_name][ep_name] = {}\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                tasks = env_cfg[\"tasks\"]\n",
    "                Delta = float(env_cfg[\"Delta\"])\n",
    "\n",
    "                # thresholds adaptive to this bundle\n",
    "                th = build_task_label_thresholds(tasks, q_low=q_low, q_high=q_high,\n",
    "                                                 urgent_slots_cap=urgent_slots_cap)\n",
    "                labeled = label_tasks_df(tasks, Delta=Delta, thresholds=th)\n",
    "                env_cfg[\"tasks\"] = labeled  # write back\n",
    "\n",
    "                # tiny summary\n",
    "                cnt = {\n",
    "                    \"n\": len(labeled),\n",
    "                    \"urg_hard\": int((labeled[\"urgency\"] == \"hard\").sum()),\n",
    "                    \"splittable\": int((labeled[\"atomicity\"] == \"splittable\").sum()),\n",
    "                    \"size_L\": int((labeled[\"size_bucket\"] == \"L\").sum()),\n",
    "                    \"compute_L\": int((labeled[\"compute_bucket\"] == \"L\").sum()),\n",
    "                    \"mem_L\": int((labeled[\"mem_bucket\"] == \"L\").sum()),\n",
    "                }\n",
    "                summary[topo_name][ep_name][scen_name] = cnt\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"[label] {topo_name}/{ep_name}/{scen_name} -> \"\n",
    "                          f\"n={cnt['n']}, hard={cnt['urg_hard']}, split={cnt['splittable']}, \"\n",
    "                          f\"sizeL={cnt['size_L']}, compL={cnt['compute_L']}, memL={cnt['mem_L']}\")\n",
    "\n",
    "    return env_configs, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[label] ep_000/clustered/heavy -> n=30636, hard=10673, split=13766, sizeL=10416, compL=10416, memL=10416\n",
      "[label] ep_000/clustered/light -> n=2113, hard=322, split=539, sizeL=719, compL=719, memL=719\n",
      "[label] ep_000/clustered/moderate -> n=8262, hard=2117, split=2890, sizeL=2809, compL=2809, memL=2809\n",
      "[label] ep_000/full_mesh/heavy -> n=30636, hard=10673, split=13766, sizeL=10416, compL=10416, memL=10416\n",
      "[label] ep_000/full_mesh/light -> n=2113, hard=322, split=539, sizeL=719, compL=719, memL=719\n",
      "[label] ep_000/full_mesh/moderate -> n=8262, hard=2117, split=2890, sizeL=2809, compL=2809, memL=2809\n",
      "[label] ep_000/sparse_ring/heavy -> n=30636, hard=10673, split=13766, sizeL=10416, compL=10416, memL=10416\n",
      "[label] ep_000/sparse_ring/light -> n=2113, hard=322, split=539, sizeL=719, compL=719, memL=719\n",
      "[label] ep_000/sparse_ring/moderate -> n=8262, hard=2117, split=2890, sizeL=2809, compL=2809, memL=2809\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>t_arrival_slot</th>\n",
       "      <th>t_arrival_time</th>\n",
       "      <th>b_mb</th>\n",
       "      <th>rho_cyc_per_mb</th>\n",
       "      <th>c_cycles</th>\n",
       "      <th>mem_mb</th>\n",
       "      <th>...</th>\n",
       "      <th>compute_bucket</th>\n",
       "      <th>mem_bucket</th>\n",
       "      <th>atomicity</th>\n",
       "      <th>split_bucket</th>\n",
       "      <th>urgency</th>\n",
       "      <th>latency_sensitive</th>\n",
       "      <th>compute_heavy</th>\n",
       "      <th>io_heavy</th>\n",
       "      <th>memory_heavy</th>\n",
       "      <th>routing_hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.202096</td>\n",
       "      <td>9.727147e+08</td>\n",
       "      <td>7.005585e+09</td>\n",
       "      <td>66.611010</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>atomic</td>\n",
       "      <td>NA</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.479984</td>\n",
       "      <td>1.314973e+09</td>\n",
       "      <td>7.206031e+09</td>\n",
       "      <td>77.928800</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>L</td>\n",
       "      <td>atomic</td>\n",
       "      <td>NA</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>CLOUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.421977</td>\n",
       "      <td>2.500222e+09</td>\n",
       "      <td>2.105681e+10</td>\n",
       "      <td>72.966446</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>M</td>\n",
       "      <td>splittable</td>\n",
       "      <td>S</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CLOUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.324986</td>\n",
       "      <td>1.779582e+09</td>\n",
       "      <td>1.125583e+10</td>\n",
       "      <td>56.492900</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>atomic</td>\n",
       "      <td>NA</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heavy</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.473269</td>\n",
       "      <td>1.087572e+09</td>\n",
       "      <td>1.247800e+10</td>\n",
       "      <td>73.389854</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>atomic</td>\n",
       "      <td>NA</td>\n",
       "      <td>hard</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  episode_id  task_id  agent_id  t_arrival_slot  t_arrival_time  \\\n",
       "0    heavy           0        0         0               0             0.0   \n",
       "1    heavy           0        1         1               0             0.0   \n",
       "2    heavy           0        2         4               0             0.0   \n",
       "3    heavy           0        3         7               0             0.0   \n",
       "4    heavy           0        4        10               0             0.0   \n",
       "\n",
       "        b_mb  rho_cyc_per_mb      c_cycles     mem_mb  ... compute_bucket  \\\n",
       "0   7.202096    9.727147e+08  7.005585e+09  66.611010  ...              S   \n",
       "1   5.479984    1.314973e+09  7.206031e+09  77.928800  ...              M   \n",
       "2   8.421977    2.500222e+09  2.105681e+10  72.966446  ...              L   \n",
       "3   6.324986    1.779582e+09  1.125583e+10  56.492900  ...              M   \n",
       "4  11.473269    1.087572e+09  1.247800e+10  73.389854  ...              S   \n",
       "\n",
       "   mem_bucket   atomicity  split_bucket  urgency  latency_sensitive  \\\n",
       "0           M      atomic            NA     hard               True   \n",
       "1           L      atomic            NA     hard               True   \n",
       "2           M  splittable             S     hard               True   \n",
       "3           M      atomic            NA     hard               True   \n",
       "4           M      atomic            NA     hard               True   \n",
       "\n",
       "  compute_heavy  io_heavy memory_heavy routing_hint  \n",
       "0         False      True        False          MEC  \n",
       "1         False     False         True        CLOUD  \n",
       "2          True      True        False        CLOUD  \n",
       "3         False      True        False          MEC  \n",
       "4         False      True        False          MEC  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env_configs: Produced in Step 6 (structure: episode → topology → scenario)\n",
    "env_configs, label_summary = label_all_tasks_in_env_configs(\n",
    "    env_configs,\n",
    "    q_low=0.33, q_high=0.66, urgent_slots_cap=2,  # tunable thresholds\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Example access:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "labeled_tasks = env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"]\n",
    "display(labeled_tasks.head())\n",
    "print(labeled_tasks.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.2. Task Type Classification </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-req: tasks already labeled by your previous step: \n",
    "#   size_bucket, compute_bucket, mem_bucket, urgency, atomicity, split_bucket, routing_hint, etc.\n",
    "\n",
    "def _derive_task_type_row(row: pd.Series) -> tuple[str, str, str, list]:\n",
    "    \"\"\"\n",
    "    Returns (task_type, task_subtype, type_reason, multi_flags)\n",
    "      task_type   ∈ {\"deadline_hard\",\"latency_sensitive\",\"compute_intensive\",\"data_intensive\",\"general\"}\n",
    "      task_subtype: finer note (e.g., \"deadline_hard\", \"deadline_soft\", ...)\n",
    "      type_reason: short human-readable reason\n",
    "      multi_flags: list of boolean tags that were true (for auditing)\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect boolean flags consistent with your earlier labeling:\n",
    "    urgency        = str(row.get(\"urgency\", \"none\"))         # \"hard\" | \"soft\" | \"none\"\n",
    "    latency_flag   = (urgency == \"hard\") or (urgency == \"soft\")\n",
    "    hard_deadline  = (urgency == \"hard\")\n",
    "\n",
    "    compute_heavy  = bool(row.get(\"compute_heavy\", False))   # compute_bucket == \"L\"\n",
    "    memory_heavy   = bool(row.get(\"memory_heavy\", False))    # mem_bucket == \"L\"\n",
    "    io_heavy       = bool(row.get(\"io_heavy\", False))        # size_bucket == \"L\"\n",
    "    non_atomic     = bool(row.get(\"atomicity\", \"atomic\") == \"splittable\")\n",
    "\n",
    "    # Keep all active signals for audit:\n",
    "    multi_flags = []\n",
    "    if hard_deadline:  multi_flags.append(\"deadline_hard\")\n",
    "    elif latency_flag: multi_flags.append(\"deadline_soft\")\n",
    "    if compute_heavy:  multi_flags.append(\"compute_heavy\")\n",
    "    if memory_heavy:   multi_flags.append(\"memory_heavy\")\n",
    "    if io_heavy:       multi_flags.append(\"io_heavy\")\n",
    "    if non_atomic:     multi_flags.append(\"splittable\")\n",
    "\n",
    "    # --- Priority resolution (Chapter 4) ---\n",
    "    # 1) Hard deadline dominates everything\n",
    "    if hard_deadline:\n",
    "        return (\"deadline_hard\", \"deadline_hard\", \"hard deadline (tight slots)\", multi_flags)\n",
    "\n",
    "    # 2) Latency-sensitive (soft deadlines / delay-sensitive)\n",
    "    if latency_flag:\n",
    "        return (\"latency_sensitive\", \"deadline_soft\", \"delay-sensitive (soft deadline)\", multi_flags)\n",
    "\n",
    "    # 3) Compute-intensive (c or rho or mem heavy)\n",
    "    #    You may decide whether memory_heavy alone pushes to compute_intensive or creates a separate class.\n",
    "    #    Based on Chapter 4 text we map memory_heavy into compute_intensive family.\n",
    "    if compute_heavy or memory_heavy:\n",
    "        return (\"compute_intensive\", \"compute_or_memory_heavy\", \"high compute/memory demand\", multi_flags)\n",
    "\n",
    "    # 4) Data-intensive (mainly large input size / high IO pressure)\n",
    "    if io_heavy:\n",
    "        return (\"data_intensive\", \"large_input_bandwidth\", \"large data volume / IO heavy\", multi_flags)\n",
    "\n",
    "    # 5) Otherwise general\n",
    "    return (\"general\", \"general\", \"no dominant constraint\", multi_flags)\n",
    "\n",
    "def apply_ch4_task_typing(tasks_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds Chapter-4 level task classes with priority rules into tasks_df (returns a COPY).\n",
    "    Columns added:\n",
    "      - task_type            (5-way class)\n",
    "      - task_subtype         (finer descriptor)\n",
    "      - type_reason          (short textual rationale)\n",
    "      - multi_flags          (list of all active boolean traits)\n",
    "    \"\"\"\n",
    "    df = tasks_df.copy()\n",
    "\n",
    "    # Ensure the expected helper columns exist (created in your previous labeling step).\n",
    "    required_cols = [\"urgency\", \"compute_heavy\", \"memory_heavy\", \"io_heavy\", \"atomicity\"]\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"apply_ch4_task_typing: missing label columns: {missing}\")\n",
    "\n",
    "    out_type, out_sub, out_reason, out_flags = [], [], [], []\n",
    "    for _, r in df.iterrows():\n",
    "        t, s, msg, flags = _derive_task_type_row(r)\n",
    "        out_type.append(t)\n",
    "        out_sub.append(s)\n",
    "        out_reason.append(msg)\n",
    "        out_flags.append(flags)\n",
    "\n",
    "    df[\"task_type\"]   = out_type\n",
    "    df[\"task_subtype\"]= out_sub\n",
    "    df[\"type_reason\"] = out_reason\n",
    "    df[\"multi_flags\"] = out_flags\n",
    "    # For convenience: one-hot view (optional)\n",
    "    df[\"is_general\"]            = (df[\"task_type\"] == \"general\")\n",
    "    df[\"is_deadline_hard\"]      = (df[\"task_type\"] == \"deadline_hard\")\n",
    "    df[\"is_latency_sensitive\"]  = (df[\"task_type\"] == \"latency_sensitive\")\n",
    "    df[\"is_compute_intensive\"]  = (df[\"task_type\"] == \"compute_intensive\")\n",
    "    df[\"is_data_intensive\"]     = (df[\"task_type\"] == \"data_intensive\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def apply_task_typing_in_env_configs(env_configs: Dict[str, Dict[str, Dict[str, Any]]],\n",
    "                                     verbose: bool = True) -> Dict[str, Dict[str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    env_configs structure (as we fixed earlier):\n",
    "      env_configs[ep_name][topology_name][scenario_name][\"tasks\"] -> DataFrame\n",
    "\n",
    "    This function:\n",
    "      - applies Chapter-4 task typing to every tasks DF\n",
    "      - writes back the enriched DataFrame\n",
    "      - prints a short summary if verbose=True\n",
    "    \"\"\"\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                tasks = env_cfg[\"tasks\"]\n",
    "                enriched = apply_ch4_task_typing(tasks)\n",
    "                env_cfg[\"tasks\"] = enriched\n",
    "\n",
    "                if verbose:\n",
    "                    n = len(enriched)\n",
    "                    counts = enriched[\"task_type\"].value_counts().to_dict()\n",
    "                    print(f\"[typing] {ep_name}/{topo_name}/{scen_name}  n={n}  → {counts}\")\n",
    "    return env_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[typing] ep_000/clustered/heavy  n=30636  → {'compute_intensive': 11370, 'deadline_hard': 10673, 'general': 5671, 'data_intensive': 2922}\n",
      "[typing] ep_000/clustered/light  n=2113  → {'compute_intensive': 1009, 'general': 502, 'deadline_hard': 322, 'data_intensive': 280}\n",
      "[typing] ep_000/clustered/moderate  n=8262  → {'compute_intensive': 3395, 'deadline_hard': 2117, 'general': 1829, 'data_intensive': 921}\n",
      "[typing] ep_000/full_mesh/heavy  n=30636  → {'compute_intensive': 11370, 'deadline_hard': 10673, 'general': 5671, 'data_intensive': 2922}\n",
      "[typing] ep_000/full_mesh/light  n=2113  → {'compute_intensive': 1009, 'general': 502, 'deadline_hard': 322, 'data_intensive': 280}\n",
      "[typing] ep_000/full_mesh/moderate  n=8262  → {'compute_intensive': 3395, 'deadline_hard': 2117, 'general': 1829, 'data_intensive': 921}\n",
      "[typing] ep_000/sparse_ring/heavy  n=30636  → {'compute_intensive': 11370, 'deadline_hard': 10673, 'general': 5671, 'data_intensive': 2922}\n",
      "[typing] ep_000/sparse_ring/light  n=2113  → {'compute_intensive': 1009, 'general': 502, 'deadline_hard': 322, 'data_intensive': 280}\n",
      "[typing] ep_000/sparse_ring/moderate  n=8262  → {'compute_intensive': 3395, 'deadline_hard': 2117, 'general': 1829, 'data_intensive': 921}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_subtype</th>\n",
       "      <th>type_reason</th>\n",
       "      <th>multi_flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, memory_heavy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, compute_heavy, io_heavy, split...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>deadline_hard</td>\n",
       "      <td>hard deadline (tight slots)</td>\n",
       "      <td>[deadline_hard, io_heavy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_id      task_type   task_subtype                  type_reason  \\\n",
       "0        0  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "1        1  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "2        2  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "3        3  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "4        4  deadline_hard  deadline_hard  hard deadline (tight slots)   \n",
       "\n",
       "                                         multi_flags  \n",
       "0                          [deadline_hard, io_heavy]  \n",
       "1                      [deadline_hard, memory_heavy]  \n",
       "2  [deadline_hard, compute_heavy, io_heavy, split...  \n",
       "3                          [deadline_hard, io_heavy]  \n",
       "4                          [deadline_hard, io_heavy]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Run typing on your current env_configs (episode → topology → scenario) ----\n",
    "env_configs = apply_task_typing_in_env_configs(env_configs, verbose=True)\n",
    "\n",
    "# Example access:\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"][[\"task_id\",\"task_type\",\"task_subtype\",\"type_reason\",\"multi_flags\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urgency\n",
      "none    19963\n",
      "hard    10673\n",
      "Name: count, dtype: int64\n",
      "\n",
      " task_type\n",
      "compute_intensive    11370\n",
      "deadline_hard        10673\n",
      "general               5671\n",
      "data_intensive        2922\n",
      "Name: count, dtype: int64\n",
      "\n",
      "                        b_mb  rho_cyc_per_mb     mem_mb\n",
      "task_type                                             \n",
      "compute_intensive  4.946632    1.933898e+09  80.518150\n",
      "data_intensive     8.263339    1.230034e+09  53.342833\n",
      "deadline_hard      4.971393    1.496501e+09  63.870583\n",
      "general            3.954205    1.223997e+09  53.340660\n"
     ]
    }
   ],
   "source": [
    "df = env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"]\n",
    "print(df[\"urgency\"].value_counts())\n",
    "print(\"\\n\", df[\"task_type\"].value_counts())\n",
    "print(\"\\n\", df.groupby(\"task_type\")[[\"b_mb\",\"rho_cyc_per_mb\",\"mem_mb\"]].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "none → Tasks that we intend to do but do not have a specific deadline or time sensitivity </br>\n",
    "hard → Tasks that have a very limited deadline and delay is very important to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30636 entries, 0 to 30635\n",
      "Data columns (total 38 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   scenario              30636 non-null  object \n",
      " 1   episode_id            30636 non-null  int64  \n",
      " 2   task_id               30636 non-null  int64  \n",
      " 3   agent_id              30636 non-null  int64  \n",
      " 4   t_arrival_slot        30636 non-null  int64  \n",
      " 5   t_arrival_time        30636 non-null  float64\n",
      " 6   b_mb                  30636 non-null  float64\n",
      " 7   rho_cyc_per_mb        30636 non-null  float64\n",
      " 8   c_cycles              30636 non-null  float64\n",
      " 9   mem_mb                30636 non-null  float64\n",
      " 10  modality              30636 non-null  object \n",
      " 11  has_deadline          30636 non-null  int64  \n",
      " 12  deadline_s            10673 non-null  float64\n",
      " 13  deadline_time         10673 non-null  float64\n",
      " 14  non_atomic            30636 non-null  int64  \n",
      " 15  split_ratio           30636 non-null  float64\n",
      " 16  action_space_hint     30636 non-null  object \n",
      " 17  deadline_slots        10673 non-null  float64\n",
      " 18  size_bucket           30636 non-null  object \n",
      " 19  compute_bucket        30636 non-null  object \n",
      " 20  mem_bucket            30636 non-null  object \n",
      " 21  atomicity             30636 non-null  object \n",
      " 22  split_bucket          30636 non-null  object \n",
      " 23  urgency               30636 non-null  object \n",
      " 24  latency_sensitive     30636 non-null  bool   \n",
      " 25  compute_heavy         30636 non-null  bool   \n",
      " 26  io_heavy              30636 non-null  bool   \n",
      " 27  memory_heavy          30636 non-null  bool   \n",
      " 28  routing_hint          30636 non-null  object \n",
      " 29  task_type             30636 non-null  object \n",
      " 30  task_subtype          30636 non-null  object \n",
      " 31  type_reason           30636 non-null  object \n",
      " 32  multi_flags           30636 non-null  object \n",
      " 33  is_general            30636 non-null  bool   \n",
      " 34  is_deadline_hard      30636 non-null  bool   \n",
      " 35  is_latency_sensitive  30636 non-null  bool   \n",
      " 36  is_compute_intensive  30636 non-null  bool   \n",
      " 37  is_data_intensive     30636 non-null  bool   \n",
      "dtypes: bool(9), float64(9), int64(6), object(14)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Example access:\n",
    "labeled_tasks_completed = env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"tasks\"]\n",
    "labeled_tasks_completed.head()\n",
    "labeled_tasks_completed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\heavy\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\heavy\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\heavy\\arrivals_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\heavy\\tasks_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\light\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\light\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\light\\arrivals_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\light\\tasks_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\moderate\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\moderate\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\moderate\\arrivals_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\clustered\\moderate\\tasks_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\heavy\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\heavy\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\heavy\\arrivals_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\heavy\\tasks_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\light\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\light\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\light\\arrivals_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\light\\tasks_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\moderate\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\moderate\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\moderate\\arrivals_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\full_mesh\\moderate\\tasks_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\heavy\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\heavy\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\heavy\\arrivals_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\heavy\\tasks_env_config.csv  (rows=30636)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\light\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\light\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\light\\arrivals_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\light\\tasks_env_config.csv  (rows=2113)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\moderate\\episodes_env_config.csv  (rows=1)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\moderate\\agents_env_config.csv  (rows=18)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\moderate\\arrivals_env_config.csv  (rows=8262)\n",
      "[saved] ./artifacts/env_configs\\ep_000\\sparse_ring\\moderate\\tasks_env_config.csv  (rows=8262)\n",
      "Done. Saved 36 dataframes for env_configs (episode, topology, scenario).\n"
     ]
    }
   ],
   "source": [
    "def _ensure_dir(path: str):\n",
    "    \"\"\"Create folder if it doesn't exist.\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def save_all_env_configs(env_configs, out_root: str = \"./artifacts/env_configs\"):\n",
    "    \"\"\"\n",
    "    Walk through env_configs (episode → topology → scenario) and save all data (tasks, agents, etc.) as CSV.\n",
    "    Example output: ./artifacts/env_configs/ep_000/clustered/heavy/env_config.csv\n",
    "    \"\"\"\n",
    "    n_saved = 0\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                out_dir = os.path.join(out_root, ep_name, topo_name, scen_name)\n",
    "                _ensure_dir(out_dir)\n",
    "\n",
    "                # Save tasks, agents, arrivals, and other components\n",
    "                for df_name, df in env_cfg.items():\n",
    "                    if isinstance(df, pd.DataFrame):\n",
    "                        file_path_csv = os.path.join(out_dir, f\"{df_name}_env_config.csv\")\n",
    "                        # file_path_pq = os.path.join(out_dir, f\"{df_name}_env_config.parquet\")\n",
    "\n",
    "                        df.to_csv(file_path_csv, index=False)\n",
    "                        # try:\n",
    "                        #     df.to_parquet(file_path_pq, index=False)  # optional\n",
    "                        # except Exception:\n",
    "                        #     pass\n",
    "\n",
    "                        print(f\"[saved] {file_path_csv}  (rows={len(df)})\")\n",
    "                        n_saved += 1\n",
    "\n",
    "    print(f\"Done. Saved {n_saved} dataframes for env_configs (episode, topology, scenario).\")\n",
    "\n",
    "# Save ALL env_configs\n",
    "save_all_env_configs(env_configs, out_root=\"./artifacts/env_configs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Step 3: Agent Profiling </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we construct a behavioral profile for each agent, capturing its local compute resources, task arrival rate, and the distribution of task types it generates. These profiles are later used for clustering agents and assigning suitable reinforcement learning strategies to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Helper 1: per-agent per-slot arrival counts ----\n",
    "def _per_agent_slot_counts(arrivals_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count how many tasks each agent generates in each time slot.\n",
    "    This is used to estimate lambda (arrival rate) statistics.\n",
    "    \"\"\"\n",
    "    if not {\"agent_id\", \"t_slot\"}.issubset(arrivals_df.columns):\n",
    "        raise ValueError(\"arrivals must contain 'agent_id' and 't_slot'.\")\n",
    "    grp = arrivals_df.groupby([\"agent_id\", \"t_slot\"], as_index=False).size()\n",
    "    grp.rename(columns={\"size\": \"count\"}, inplace=True)\n",
    "    return grp\n",
    "\n",
    "# ---- Helper 2: estimate λ-mean and λ-variance per agent (tight dtypes) ----\n",
    "def _lambda_stats_from_counts(counts_df: pd.DataFrame, Delta: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert per-slot counts to rate statistics:\n",
    "        lambda_mean = mean(count_per_slot) / Delta\n",
    "        lambda_var  = var(count_per_slot)  / Delta^2\n",
    "    \"\"\"\n",
    "    if counts_df.empty:\n",
    "        return pd.DataFrame(columns=[\"agent_id\", \"lambda_mean\", \"lambda_var\", \"slots_observed\"])\n",
    "\n",
    "    agg = counts_df.groupby(\"agent_id\")[\"count\"].agg(\n",
    "        lambda_mean_slot=\"mean\",\n",
    "        lambda_var_slot=\"var\",\n",
    "        slots_observed=\"count\"\n",
    "    ).reset_index()\n",
    "\n",
    "    # If only one observation exists, variance becomes NaN → treat as zero.\n",
    "    agg[\"lambda_var_slot\"] = agg[\"lambda_var_slot\"].fillna(0.0).astype(float)\n",
    "\n",
    "    # Convert to per-second rates\n",
    "    agg[\"lambda_mean\"] = (agg[\"lambda_mean_slot\"] / float(Delta)).astype(float)\n",
    "    agg[\"lambda_var\"]  = (agg[\"lambda_var_slot\"]  / float(Delta**2)).astype(float)\n",
    "\n",
    "    return agg[[\"agent_id\", \"lambda_mean\", \"lambda_var\", \"slots_observed\"]]\n",
    "\n",
    "# ---- Helper 3: task-type distribution per agent (robust + extra stats) ----\n",
    "_TASK_TYPES = [\"general\", \"latency_sensitive\", \"deadline_hard\", \"data_intensive\", \"compute_intensive\"]\n",
    "\n",
    "def _task_distribution_per_agent(tasks_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute distribution of task types per agent (probabilities sum to 1 for agents with tasks).\n",
    "    Also adds light median features useful for clustering: b_mb_med, rho_med, mem_med, hard_share.\n",
    "    \"\"\"\n",
    "    if not {\"agent_id\", \"task_type\"}.issubset(tasks_df.columns):\n",
    "        raise ValueError(\"tasks must contain 'agent_id' and 'task_type'.\")\n",
    "\n",
    "    # Raw counts per (agent_id, task_type)\n",
    "    cnt = tasks_df.groupby([\"agent_id\", \"task_type\"], as_index=False).size()\n",
    "    piv = cnt.pivot(index=\"agent_id\", columns=\"task_type\", values=\"size\").fillna(0.0)\n",
    "\n",
    "    # Ensure all expected classes exist\n",
    "    for t in _TASK_TYPES:\n",
    "        if t not in piv.columns:\n",
    "            piv[t] = 0.0\n",
    "\n",
    "    # True count across all seen labels\n",
    "    piv[\"n_tasks_agent\"] = piv[_TASK_TYPES].sum(axis=1).astype(float)\n",
    "\n",
    "    # Probabilities\n",
    "    for t in _TASK_TYPES:\n",
    "        piv[f\"P_{t}\"] = np.where(piv[\"n_tasks_agent\"] > 0, piv[t] / piv[\"n_tasks_agent\"], 0.0).astype(float)\n",
    "\n",
    "    # Optional extra features for clustering (guard on availability)\n",
    "    feats = {}\n",
    "    have_feats = {\"b_mb\", \"rho_cyc_per_mb\", \"mem_mb\", \"urgency\"}\n",
    "    if have_feats.issubset(tasks_df.columns):\n",
    "        agg = tasks_df.groupby(\"agent_id\").agg(\n",
    "            b_mb_med=(\"b_mb\", \"median\"),\n",
    "            rho_med=(\"rho_cyc_per_mb\", \"median\"),\n",
    "            mem_med=(\"mem_mb\", \"median\"),\n",
    "            hard_share=(\"urgency\", lambda s: float((s == \"hard\").mean()))\n",
    "        ).reset_index()\n",
    "        feats = agg.set_index(\"agent_id\")\n",
    "\n",
    "    # Join extra features (if any)\n",
    "    piv = piv.join(feats, how=\"left\")\n",
    "    for c in [\"b_mb_med\", \"rho_med\", \"mem_med\", \"hard_share\"]:\n",
    "        if c in piv.columns:\n",
    "            piv[c] = piv[c].fillna(0.0).astype(float)\n",
    "        else:\n",
    "            piv[c] = 0.0\n",
    "\n",
    "    # Probability mass sum (diagnostic)\n",
    "    prob_cols = [f\"P_{t}\" for t in _TASK_TYPES]\n",
    "    piv[\"TaskDist_sum\"] = piv[prob_cols].sum(axis=1).astype(float)\n",
    "\n",
    "    keep = [\"n_tasks_agent\", \"TaskDist_sum\", \"b_mb_med\", \"rho_med\", \"mem_med\", \"hard_share\"] + prob_cols\n",
    "    return piv[keep].reset_index()\n",
    "\n",
    "# ---- Helper 4: fraction of non-atomic (splittable) tasks ----\n",
    "def _non_atomic_share_per_agent(tasks_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the share of splittable (non-atomic) tasks per agent.\n",
    "    \"\"\"\n",
    "    if not {\"agent_id\", \"non_atomic\"}.issubset(tasks_df.columns):\n",
    "        # If missing, assume zero for all agents that exist in tasks\n",
    "        agents = tasks_df.get(\"agent_id\")\n",
    "        if agents is None or len(agents) == 0:\n",
    "            return pd.DataFrame(columns=[\"agent_id\", \"non_atomic_share\"])\n",
    "        return pd.DataFrame({\"agent_id\": agents.unique(), \"non_atomic_share\": 0.0})\n",
    "\n",
    "    grp = tasks_df.groupby(\"agent_id\")[\"non_atomic\"].agg(\n",
    "        non_atomic_share=lambda s: float((s == 1).mean())\n",
    "    ).reset_index()\n",
    "    return grp\n",
    "\n",
    "# ---- Build agent profiles for ONE env_config ----\n",
    "def build_agent_profiles_for_env(env_cfg: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construct per-agent profiles combining:\n",
    "      - Local resource capacity (f_local, m_local, f_local_slot)\n",
    "      - Arrival rate statistics (lambda_mean, lambda_var)\n",
    "      - Task type distribution (P_general, P_latency_sensitive, P_deadline_hard, P_data_intensive, P_compute_intensive)\n",
    "      - Splittability share (non_atomic_share)\n",
    "      - MEC mapping if available (mec_id)\n",
    "    \"\"\"\n",
    "    agents   = env_cfg[\"agents\"].copy()\n",
    "    arrivals = env_cfg[\"arrivals\"]\n",
    "    tasks    = env_cfg[\"tasks\"]\n",
    "    Delta    = float(env_cfg[\"Delta\"])\n",
    "\n",
    "    # Ensure cycles/slot exists\n",
    "    if \"f_local_slot\" not in agents.columns and \"f_local\" in agents.columns:\n",
    "        agents[\"f_local_slot\"] = agents[\"f_local\"].astype(float) * Delta\n",
    "\n",
    "    # 1) Arrival statistics\n",
    "    counts_df = _per_agent_slot_counts(arrivals)\n",
    "    lam_df    = _lambda_stats_from_counts(counts_df, Delta=Delta)\n",
    "\n",
    "    # 2) Task-type distribution (+ medians & hard_share)\n",
    "    dist_df   = _task_distribution_per_agent(tasks)\n",
    "\n",
    "    # 3) Splittable-task share\n",
    "    na_df     = _non_atomic_share_per_agent(tasks)\n",
    "\n",
    "    # 4) Agent→MEC mapping (optional)\n",
    "    mec_map = None\n",
    "    if \"agent_to_mec\" in env_cfg:\n",
    "        a2m = env_cfg[\"agent_to_mec\"]\n",
    "        if isinstance(a2m, pd.Series):\n",
    "            mec_map = a2m.rename(\"mec_id\").reset_index()\n",
    "            # if the index column name is lost, normalize it\n",
    "            if mec_map.columns.tolist() == [\"index\", \"mec_id\"]:\n",
    "                mec_map.rename(columns={\"index\": \"agent_id\"}, inplace=True)\n",
    "        else:\n",
    "            mec_map = pd.DataFrame({\n",
    "                \"agent_id\": np.arange(len(a2m), dtype=int),\n",
    "                \"mec_id\": np.asarray(a2m, dtype=int)\n",
    "            })\n",
    "\n",
    "    # Merge all components\n",
    "    base = agents[[\"agent_id\", \"f_local\", \"f_local_slot\", \"m_local\"]].copy()\n",
    "    base[[\"f_local\", \"f_local_slot\", \"m_local\"]] = base[[\"f_local\", \"f_local_slot\", \"m_local\"]].astype(float)\n",
    "\n",
    "    prof = (base\n",
    "            .merge(lam_df,  on=\"agent_id\", how=\"left\")\n",
    "            .merge(dist_df, on=\"agent_id\", how=\"left\")\n",
    "            .merge(na_df,   on=\"agent_id\", how=\"left\"))\n",
    "\n",
    "    if mec_map is not None:\n",
    "        prof = prof.merge(mec_map, on=\"agent_id\", how=\"left\")\n",
    "\n",
    "    # Fill missing for agents with no arrivals/tasks\n",
    "    fill_zero = [\n",
    "        \"lambda_mean\", \"lambda_var\", \"slots_observed\",\n",
    "        \"n_tasks_agent\", \"non_atomic_share\",\n",
    "        \"TaskDist_sum\", \"b_mb_med\", \"rho_med\", \"mem_med\", \"hard_share\"\n",
    "    ] + [f\"P_{t}\" for t in _TASK_TYPES]\n",
    "    for c in fill_zero:\n",
    "        if c in prof.columns:\n",
    "            prof[c] = prof[c].fillna(0.0).astype(float)\n",
    "\n",
    "    # Soft warning if probabilities don't sum to ~1 for agents with tasks\n",
    "    if \"n_tasks_agent\" in prof.columns and \"TaskDist_sum\" in prof.columns:\n",
    "        mask = (prof[\"n_tasks_agent\"] > 0) & (~np.isclose(prof[\"TaskDist_sum\"], 1.0, atol=1e-6))\n",
    "        if mask.any():\n",
    "            n_bad = int(mask.sum())\n",
    "            print(f\"[warn] TaskDist_sum != 1.0 for {n_bad} agent(s). (tolerance 1e-6)\")\n",
    "\n",
    "    return prof\n",
    "\n",
    "# ---- Batch profiling for ALL env_configs ----\n",
    "def build_all_agent_profiles(env_configs: Dict[str, Dict[str, Dict[str, Any]]]):\n",
    "    \"\"\"\n",
    "    Compute profiles for every (episode → topology → scenario) environment.\n",
    "    Stores result both in return dict AND env_configs[...] for convenience.\n",
    "    Output:\n",
    "      profiles[ep_name][topology_name][scen_name] = DataFrame\n",
    "    Also writes back to: env_configs[ep_name][topology_name][scen_name][\"agent_profiles\"]\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for ep_name, by_topo in env_configs.items():\n",
    "        out[ep_name] = {}\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            out[ep_name][topo_name] = {}\n",
    "            for scen_name, env_cfg in by_scen.items():\n",
    "                prof = build_agent_profiles_for_env(env_cfg)\n",
    "                out[ep_name][topo_name][scen_name] = prof\n",
    "                env_cfg[\"agent_profiles\"] = prof  # attach for direct access\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>f_local</th>\n",
       "      <th>f_local_slot</th>\n",
       "      <th>m_local</th>\n",
       "      <th>lambda_mean</th>\n",
       "      <th>lambda_var</th>\n",
       "      <th>slots_observed</th>\n",
       "      <th>n_tasks_agent</th>\n",
       "      <th>TaskDist_sum</th>\n",
       "      <th>b_mb_med</th>\n",
       "      <th>rho_med</th>\n",
       "      <th>mem_med</th>\n",
       "      <th>hard_share</th>\n",
       "      <th>P_general</th>\n",
       "      <th>P_latency_sensitive</th>\n",
       "      <th>P_deadline_hard</th>\n",
       "      <th>P_data_intensive</th>\n",
       "      <th>P_compute_intensive</th>\n",
       "      <th>non_atomic_share</th>\n",
       "      <th>mec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>1.400325</td>\n",
       "      <td>0.474341</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.975150</td>\n",
       "      <td>1.496395e+09</td>\n",
       "      <td>64.062160</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.182592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.379884</td>\n",
       "      <td>0.467311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>1.125348</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>718.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.903463</td>\n",
       "      <td>1.542846e+09</td>\n",
       "      <td>64.020492</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.169554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.092822</td>\n",
       "      <td>0.383663</td>\n",
       "      <td>0.433168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>1.134063</td>\n",
       "      <td>0.138167</td>\n",
       "      <td>731.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.910049</td>\n",
       "      <td>1.540341e+09</td>\n",
       "      <td>66.006420</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.184560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.086852</td>\n",
       "      <td>0.394451</td>\n",
       "      <td>0.434258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>1.139918</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>972.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.067142</td>\n",
       "      <td>1.470254e+09</td>\n",
       "      <td>64.517043</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.182310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.359206</td>\n",
       "      <td>0.435921</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>1.277666</td>\n",
       "      <td>0.287951</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.031714</td>\n",
       "      <td>1.515057e+09</td>\n",
       "      <td>64.294464</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.095538</td>\n",
       "      <td>0.374278</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id       f_local  f_local_slot      m_local  lambda_mean  lambda_var  \\\n",
       "0         0  1.741183e+09  1.741183e+09  5713.849721     1.400325    0.474341   \n",
       "1         1  1.352326e+09  1.352326e+09  4566.428755     1.125348    0.140472   \n",
       "2         2  1.726668e+09  1.726668e+09  5815.120004     1.134063    0.138167   \n",
       "3         3  1.543616e+09  1.543616e+09  3539.850245     1.139918    0.147241   \n",
       "4         4  1.130883e+09  1.130883e+09  4161.367769     1.277666    0.287951   \n",
       "\n",
       "   slots_observed  n_tasks_agent  TaskDist_sum  b_mb_med       rho_med  \\\n",
       "0          1846.0         2585.0           1.0  4.975150  1.496395e+09   \n",
       "1           718.0          808.0           1.0  4.903463  1.542846e+09   \n",
       "2           731.0          829.0           1.0  4.910049  1.540341e+09   \n",
       "3           972.0         1108.0           1.0  5.067142  1.470254e+09   \n",
       "4          1491.0         1905.0           1.0  5.031714  1.515057e+09   \n",
       "\n",
       "     mem_med  hard_share  P_general  P_latency_sensitive  P_deadline_hard  \\\n",
       "0  64.062160    0.343907   0.182592                  0.0         0.343907   \n",
       "1  64.020492    0.353960   0.169554                  0.0         0.353960   \n",
       "2  66.006420    0.334138   0.184560                  0.0         0.334138   \n",
       "3  64.517043    0.371841   0.182310                  0.0         0.371841   \n",
       "4  64.294464    0.344882   0.185302                  0.0         0.344882   \n",
       "\n",
       "   P_data_intensive  P_compute_intensive  non_atomic_share  mec_id  \n",
       "0          0.093617             0.379884          0.467311       0  \n",
       "1          0.092822             0.383663          0.433168       1  \n",
       "2          0.086852             0.394451          0.434258       2  \n",
       "3          0.086643             0.359206          0.435921       3  \n",
       "4          0.095538             0.374278          0.440945       4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>f_local</th>\n",
       "      <th>f_local_slot</th>\n",
       "      <th>m_local</th>\n",
       "      <th>lambda_mean</th>\n",
       "      <th>lambda_var</th>\n",
       "      <th>slots_observed</th>\n",
       "      <th>n_tasks_agent</th>\n",
       "      <th>TaskDist_sum</th>\n",
       "      <th>b_mb_med</th>\n",
       "      <th>rho_med</th>\n",
       "      <th>mem_med</th>\n",
       "      <th>hard_share</th>\n",
       "      <th>P_general</th>\n",
       "      <th>P_latency_sensitive</th>\n",
       "      <th>P_deadline_hard</th>\n",
       "      <th>P_data_intensive</th>\n",
       "      <th>P_compute_intensive</th>\n",
       "      <th>non_atomic_share</th>\n",
       "      <th>mec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>1.400325</td>\n",
       "      <td>0.474341</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.975150</td>\n",
       "      <td>1.496395e+09</td>\n",
       "      <td>64.062160</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.182592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.379884</td>\n",
       "      <td>0.467311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>1.125348</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>718.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.903463</td>\n",
       "      <td>1.542846e+09</td>\n",
       "      <td>64.020492</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.169554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.092822</td>\n",
       "      <td>0.383663</td>\n",
       "      <td>0.433168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>1.134063</td>\n",
       "      <td>0.138167</td>\n",
       "      <td>731.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.910049</td>\n",
       "      <td>1.540341e+09</td>\n",
       "      <td>66.006420</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.184560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.086852</td>\n",
       "      <td>0.394451</td>\n",
       "      <td>0.434258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>1.139918</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>972.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.067142</td>\n",
       "      <td>1.470254e+09</td>\n",
       "      <td>64.517043</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.182310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.359206</td>\n",
       "      <td>0.435921</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>1.277666</td>\n",
       "      <td>0.287951</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.031714</td>\n",
       "      <td>1.515057e+09</td>\n",
       "      <td>64.294464</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.095538</td>\n",
       "      <td>0.374278</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id       f_local  f_local_slot      m_local  lambda_mean  lambda_var  \\\n",
       "0         0  1.741183e+09  1.741183e+09  5713.849721     1.400325    0.474341   \n",
       "1         1  1.352326e+09  1.352326e+09  4566.428755     1.125348    0.140472   \n",
       "2         2  1.726668e+09  1.726668e+09  5815.120004     1.134063    0.138167   \n",
       "3         3  1.543616e+09  1.543616e+09  3539.850245     1.139918    0.147241   \n",
       "4         4  1.130883e+09  1.130883e+09  4161.367769     1.277666    0.287951   \n",
       "\n",
       "   slots_observed  n_tasks_agent  TaskDist_sum  b_mb_med       rho_med  \\\n",
       "0          1846.0         2585.0           1.0  4.975150  1.496395e+09   \n",
       "1           718.0          808.0           1.0  4.903463  1.542846e+09   \n",
       "2           731.0          829.0           1.0  4.910049  1.540341e+09   \n",
       "3           972.0         1108.0           1.0  5.067142  1.470254e+09   \n",
       "4          1491.0         1905.0           1.0  5.031714  1.515057e+09   \n",
       "\n",
       "     mem_med  hard_share  P_general  P_latency_sensitive  P_deadline_hard  \\\n",
       "0  64.062160    0.343907   0.182592                  0.0         0.343907   \n",
       "1  64.020492    0.353960   0.169554                  0.0         0.353960   \n",
       "2  66.006420    0.334138   0.184560                  0.0         0.334138   \n",
       "3  64.517043    0.371841   0.182310                  0.0         0.371841   \n",
       "4  64.294464    0.344882   0.185302                  0.0         0.344882   \n",
       "\n",
       "   P_data_intensive  P_compute_intensive  non_atomic_share  mec_id  \n",
       "0          0.093617             0.379884          0.467311       0  \n",
       "1          0.092822             0.383663          0.433168       1  \n",
       "2          0.086852             0.394451          0.434258       2  \n",
       "3          0.086643             0.359206          0.435921       3  \n",
       "4          0.095538             0.374278          0.440945       4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- Build + quick peek (optional) ----\n",
    "agent_profiles = build_all_agent_profiles(env_configs)\n",
    "\n",
    "# Example: Access the profile table for a specific episode / topology / scenario\n",
    "print(\"\\n ===EXAMPLE===\")\n",
    "display(agent_profiles[\"ep_000\"][\"clustered\"][\"heavy\"].head())\n",
    "\n",
    "# Alternatively, read directly from env_configs:\n",
    "display(env_configs[\"ep_000\"][\"clustered\"][\"heavy\"][\"agent_profiles\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Step 4: Clustering Agents </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.1. Feature Matrix </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform clustering, the characteristics of each agent must first be stored in a feature matrix. These characteristics include:\n",
    "\n",
    "1) Local resources\n",
    "2) task generation pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این باگ داره\n",
    "برای همه اون کاری که باید و نمیکنه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract feature matrix for all agents across episodes, topologies, and scenarios\n",
    "def build_agent_feature_matrix(agent_profiles):\n",
    "    \"\"\"\n",
    "    Build the feature matrix for agents based on the columns available in agent_profiles.\n",
    "    Iterates over all episodes, topologies, and scenarios to construct the matrix.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "\n",
    "    for ep_name, by_topo in agent_profiles.items():\n",
    "        for topo_name, by_scen in by_topo.items():\n",
    "            for scen_name, agent_df in by_scen.items():\n",
    "                # We want to extract the feature columns for each agent\n",
    "                feature_columns = ['lambda_mean', 'lambda_var', 'P_general', 'P_latency_sensitive', \n",
    "                                   'P_deadline_hard', 'P_data_intensive', 'P_compute_intensive', \n",
    "                                   'non_atomic_share', 'f_local', 'm_local', 'b_mb_med', 'rho_med', \n",
    "                                   'mem_med', 'hard_share']\n",
    "                # Ensure we are using the correct subset of columns and handle missing values\n",
    "                agent_df = agent_df[feature_columns].fillna(0.0)  # Filling missing values with zero\n",
    "                \n",
    "                # Append the agent features to the list\n",
    "                all_features.append(agent_df)\n",
    "\n",
    "    # Concatenate all agent feature matrices into a single DataFrame\n",
    "    feature_matrix = pd.concat(all_features, ignore_index=True)\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.2. Optimal Number of Clusters </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the optimal number of clusters (K), we use a hybrid method that combines evaluation indices such as WCSS, Silhouette, DBI, and CH Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Select optimal K (number of clusters)\n",
    "def compute_clustering_scores(feature_matrix, K_range):\n",
    "    \"\"\"\n",
    "    Compute clustering scores (WCSS, Silhouette, DBI, CH) for a range of K values.\n",
    "    This function returns a DataFrame with the scores for each K.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for K in K_range:\n",
    "        kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "        kmeans.fit(feature_matrix)\n",
    "\n",
    "        # Calculate WCSS (within-cluster sum of squares)\n",
    "        wcss = np.sum((feature_matrix - kmeans.cluster_centers_[kmeans.labels_])**2)\n",
    "\n",
    "        # Calculate Silhouette Score\n",
    "        sil_score = silhouette_score(feature_matrix, kmeans.labels_)\n",
    "\n",
    "        # Calculate Davies-Bouldin Index (DBI)\n",
    "        dbi = davies_bouldin_score(feature_matrix, kmeans.labels_)\n",
    "\n",
    "        # Calculate Calinski-Harabasz Index (CH)\n",
    "        ch_score = calinski_harabasz_score(feature_matrix, kmeans.labels_)\n",
    "\n",
    "        # Store the scores for this K\n",
    "        scores.append({\n",
    "            'K': K,\n",
    "            'WCSS': wcss,\n",
    "            'Silhouette': sil_score,\n",
    "            'DBI': dbi,\n",
    "            'CH': ch_score\n",
    "        })\n",
    "\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.3. Implementing K-Means Clustering </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting the optimal number of clusters (K_opt), we use the K-Means algorithm for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Run KMeans with the optimal number of clusters (K_opt)\n",
    "def run_kmeans(feature_matrix, K_opt):\n",
    "    \"\"\"\n",
    "    Run KMeans clustering with the optimal number of clusters (K_opt) on the feature matrix.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=K_opt, random_state=42)\n",
    "    kmeans.fit(feature_matrix)\n",
    "\n",
    "    # Return the cluster labels and the cluster centers\n",
    "    return kmeans.labels_, kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.4. Store cluster labels </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Store cluster labels in agent profiles\n",
    "def store_cluster_labels_in_profiles(agent_profiles, labels, ep_name=\"ep_000\", topo_name=\"clustered\", scen_name=\"heavy\"):\n",
    "    \"\"\"\n",
    "    Store the cluster labels back in the agent profiles.\n",
    "    \"\"\"\n",
    "    agent_profiles[ep_name][topo_name][scen_name][\"cluster_labels\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step-by-step implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_mean</th>\n",
       "      <th>lambda_var</th>\n",
       "      <th>P_general</th>\n",
       "      <th>P_latency_sensitive</th>\n",
       "      <th>P_deadline_hard</th>\n",
       "      <th>P_data_intensive</th>\n",
       "      <th>P_compute_intensive</th>\n",
       "      <th>non_atomic_share</th>\n",
       "      <th>f_local</th>\n",
       "      <th>m_local</th>\n",
       "      <th>b_mb_med</th>\n",
       "      <th>rho_med</th>\n",
       "      <th>mem_med</th>\n",
       "      <th>hard_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.400325</td>\n",
       "      <td>0.474341</td>\n",
       "      <td>0.182592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.379884</td>\n",
       "      <td>0.467311</td>\n",
       "      <td>1.741183e+09</td>\n",
       "      <td>5713.849721</td>\n",
       "      <td>4.975150</td>\n",
       "      <td>1.496395e+09</td>\n",
       "      <td>64.062160</td>\n",
       "      <td>0.343907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.125348</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>0.169554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353960</td>\n",
       "      <td>0.092822</td>\n",
       "      <td>0.383663</td>\n",
       "      <td>0.433168</td>\n",
       "      <td>1.352326e+09</td>\n",
       "      <td>4566.428755</td>\n",
       "      <td>4.903463</td>\n",
       "      <td>1.542846e+09</td>\n",
       "      <td>64.020492</td>\n",
       "      <td>0.353960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.134063</td>\n",
       "      <td>0.138167</td>\n",
       "      <td>0.184560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.086852</td>\n",
       "      <td>0.394451</td>\n",
       "      <td>0.434258</td>\n",
       "      <td>1.726668e+09</td>\n",
       "      <td>5815.120004</td>\n",
       "      <td>4.910049</td>\n",
       "      <td>1.540341e+09</td>\n",
       "      <td>66.006420</td>\n",
       "      <td>0.334138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.139918</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>0.182310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.359206</td>\n",
       "      <td>0.435921</td>\n",
       "      <td>1.543616e+09</td>\n",
       "      <td>3539.850245</td>\n",
       "      <td>5.067142</td>\n",
       "      <td>1.470254e+09</td>\n",
       "      <td>64.517043</td>\n",
       "      <td>0.371841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.277666</td>\n",
       "      <td>0.287951</td>\n",
       "      <td>0.185302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344882</td>\n",
       "      <td>0.095538</td>\n",
       "      <td>0.374278</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>1.130883e+09</td>\n",
       "      <td>4161.367769</td>\n",
       "      <td>5.031714</td>\n",
       "      <td>1.515057e+09</td>\n",
       "      <td>64.294464</td>\n",
       "      <td>0.344882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.106419</td>\n",
       "      <td>0.112175</td>\n",
       "      <td>0.232061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241221</td>\n",
       "      <td>0.114504</td>\n",
       "      <td>0.412214</td>\n",
       "      <td>0.316031</td>\n",
       "      <td>2.334762e+09</td>\n",
       "      <td>4156.023984</td>\n",
       "      <td>2.971737</td>\n",
       "      <td>1.209705e+09</td>\n",
       "      <td>64.873310</td>\n",
       "      <td>0.241221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.077477</td>\n",
       "      <td>0.075214</td>\n",
       "      <td>0.232441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279264</td>\n",
       "      <td>0.107023</td>\n",
       "      <td>0.381271</td>\n",
       "      <td>0.357860</td>\n",
       "      <td>1.989451e+09</td>\n",
       "      <td>5301.096958</td>\n",
       "      <td>2.971286</td>\n",
       "      <td>1.207869e+09</td>\n",
       "      <td>63.704429</td>\n",
       "      <td>0.279264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.052770</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.208020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278195</td>\n",
       "      <td>0.112782</td>\n",
       "      <td>0.401003</td>\n",
       "      <td>0.401003</td>\n",
       "      <td>2.245627e+09</td>\n",
       "      <td>3973.902321</td>\n",
       "      <td>2.963276</td>\n",
       "      <td>1.188409e+09</td>\n",
       "      <td>66.241550</td>\n",
       "      <td>0.278195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.058824</td>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.182540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288360</td>\n",
       "      <td>0.084656</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.699633e+08</td>\n",
       "      <td>5954.812618</td>\n",
       "      <td>3.016342</td>\n",
       "      <td>1.233261e+09</td>\n",
       "      <td>67.249938</td>\n",
       "      <td>0.288360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.059659</td>\n",
       "      <td>0.067656</td>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265416</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>0.319035</td>\n",
       "      <td>1.298186e+09</td>\n",
       "      <td>6890.123320</td>\n",
       "      <td>2.970310</td>\n",
       "      <td>1.160207e+09</td>\n",
       "      <td>63.950405</td>\n",
       "      <td>0.265416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lambda_mean  lambda_var  P_general  P_latency_sensitive  P_deadline_hard  \\\n",
       "0       1.400325    0.474341   0.182592                  0.0         0.343907   \n",
       "1       1.125348    0.140472   0.169554                  0.0         0.353960   \n",
       "2       1.134063    0.138167   0.184560                  0.0         0.334138   \n",
       "3       1.139918    0.147241   0.182310                  0.0         0.371841   \n",
       "4       1.277666    0.287951   0.185302                  0.0         0.344882   \n",
       "..           ...         ...        ...                  ...              ...   \n",
       "157     1.106419    0.112175   0.232061                  0.0         0.241221   \n",
       "158     1.077477    0.075214   0.232441                  0.0         0.279264   \n",
       "159     1.052770    0.050118   0.208020                  0.0         0.278195   \n",
       "160     1.058824    0.061137   0.182540                  0.0         0.288360   \n",
       "161     1.059659    0.067656   0.225201                  0.0         0.265416   \n",
       "\n",
       "     P_data_intensive  P_compute_intensive  non_atomic_share       f_local  \\\n",
       "0            0.093617             0.379884          0.467311  1.741183e+09   \n",
       "1            0.092822             0.383663          0.433168  1.352326e+09   \n",
       "2            0.086852             0.394451          0.434258  1.726668e+09   \n",
       "3            0.086643             0.359206          0.435921  1.543616e+09   \n",
       "4            0.095538             0.374278          0.440945  1.130883e+09   \n",
       "..                ...                  ...               ...           ...   \n",
       "157          0.114504             0.412214          0.316031  2.334762e+09   \n",
       "158          0.107023             0.381271          0.357860  1.989451e+09   \n",
       "159          0.112782             0.401003          0.401003  2.245627e+09   \n",
       "160          0.084656             0.444444          0.333333  9.699633e+08   \n",
       "161          0.107239             0.402145          0.319035  1.298186e+09   \n",
       "\n",
       "         m_local  b_mb_med       rho_med    mem_med  hard_share  \n",
       "0    5713.849721  4.975150  1.496395e+09  64.062160    0.343907  \n",
       "1    4566.428755  4.903463  1.542846e+09  64.020492    0.353960  \n",
       "2    5815.120004  4.910049  1.540341e+09  66.006420    0.334138  \n",
       "3    3539.850245  5.067142  1.470254e+09  64.517043    0.371841  \n",
       "4    4161.367769  5.031714  1.515057e+09  64.294464    0.344882  \n",
       "..           ...       ...           ...        ...         ...  \n",
       "157  4156.023984  2.971737  1.209705e+09  64.873310    0.241221  \n",
       "158  5301.096958  2.971286  1.207869e+09  63.704429    0.279264  \n",
       "159  3973.902321  2.963276  1.188409e+09  66.241550    0.278195  \n",
       "160  5954.812618  3.016342  1.233261e+09  67.249938    0.288360  \n",
       "161  6890.123320  2.970310  1.160207e+09  63.950405    0.265416  \n",
       "\n",
       "[162 rows x 14 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build agent feature matrix for all agents across all environments\n",
    "feature_matrix = build_agent_feature_matrix(agent_profiles)\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>WCSS</th>\n",
       "      <th>Silhouette</th>\n",
       "      <th>DBI</th>\n",
       "      <th>CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>lambda_mean            2.212910e+00\n",
       "lambda_var...</td>\n",
       "      <td>0.503401</td>\n",
       "      <td>0.718692</td>\n",
       "      <td>242.256593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>lambda_mean            1.890184e+00\n",
       "lambda_var...</td>\n",
       "      <td>0.426744</td>\n",
       "      <td>0.877513</td>\n",
       "      <td>225.246795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>lambda_mean            1.317319e+00\n",
       "lambda_var...</td>\n",
       "      <td>0.454365</td>\n",
       "      <td>0.791397</td>\n",
       "      <td>220.105261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>lambda_mean            6.699701e-01\n",
       "lambda_var...</td>\n",
       "      <td>0.488596</td>\n",
       "      <td>0.693764</td>\n",
       "      <td>242.255108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>lambda_mean            8.355879e-01\n",
       "lambda_var...</td>\n",
       "      <td>0.462404</td>\n",
       "      <td>0.808251</td>\n",
       "      <td>253.707415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>lambda_mean            8.908844e-01\n",
       "lambda_var...</td>\n",
       "      <td>0.461836</td>\n",
       "      <td>0.788474</td>\n",
       "      <td>254.987462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>lambda_mean            9.231353e-01\n",
       "lambda_var...</td>\n",
       "      <td>0.472806</td>\n",
       "      <td>0.756262</td>\n",
       "      <td>253.348308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>lambda_mean            8.686128e-01\n",
       "lambda_var...</td>\n",
       "      <td>0.496988</td>\n",
       "      <td>0.745153</td>\n",
       "      <td>264.854731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   K                                               WCSS  Silhouette       DBI  \\\n",
       "0  2  lambda_mean            2.212910e+00\n",
       "lambda_var...    0.503401  0.718692   \n",
       "1  3  lambda_mean            1.890184e+00\n",
       "lambda_var...    0.426744  0.877513   \n",
       "2  4  lambda_mean            1.317319e+00\n",
       "lambda_var...    0.454365  0.791397   \n",
       "3  5  lambda_mean            6.699701e-01\n",
       "lambda_var...    0.488596  0.693764   \n",
       "4  6  lambda_mean            8.355879e-01\n",
       "lambda_var...    0.462404  0.808251   \n",
       "5  7  lambda_mean            8.908844e-01\n",
       "lambda_var...    0.461836  0.788474   \n",
       "6  8  lambda_mean            9.231353e-01\n",
       "lambda_var...    0.472806  0.756262   \n",
       "7  9  lambda_mean            8.686128e-01\n",
       "lambda_var...    0.496988  0.745153   \n",
       "\n",
       "           CH  \n",
       "0  242.256593  \n",
       "1  225.246795  \n",
       "2  220.105261  \n",
       "3  242.255108  \n",
       "4  253.707415  \n",
       "5  254.987462  \n",
       "6  253.348308  \n",
       "7  264.854731  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Compute clustering scores for a range of K values\n",
    "K_range = range(2, 10)  # Testing K values from 2 to 9\n",
    "scores_df = compute_clustering_scores(feature_matrix, K_range)\n",
    "display(scores_df)\n",
    "\n",
    "# Select optimal K (highest combined score)\n",
    "K_opt = scores_df.loc[scores_df['Silhouette'].idxmax(), 'K']  # Select K with highest Silhouette score\n",
    "print(K_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\niush\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (162) does not match length of index (18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m labels, centers \u001b[38;5;241m=\u001b[39m run_kmeans(feature_matrix, K_opt)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Store the cluster labels in the agent profiles\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mstore_cluster_labels_in_profiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_profiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Display the resulting cluster labels and centers\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCluster Labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, labels)\n",
      "Cell \u001b[1;32mIn[47], line 6\u001b[0m, in \u001b[0;36mstore_cluster_labels_in_profiles\u001b[1;34m(agent_profiles, labels, ep_name, topo_name, scen_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstore_cluster_labels_in_profiles\u001b[39m(agent_profiles, labels, ep_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mep_000\u001b[39m\u001b[38;5;124m\"\u001b[39m, topo_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclustered\u001b[39m\u001b[38;5;124m\"\u001b[39m, scen_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheavy\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Store the cluster labels back in the agent profiles.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     agent_profiles[ep_name][topo_name][scen_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m labels\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4298\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4512\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4504\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4505\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4510\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4511\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4512\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4515\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4516\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4517\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4518\u001b[0m     ):\n\u001b[0;32m   4519\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4520\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:5253\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5253\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5254\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5256\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5261\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (162) does not match length of index (18)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Run KMeans with the optimal K\n",
    "labels, centers = run_kmeans(feature_matrix, K_opt)\n",
    "\n",
    "# Store the cluster labels in the agent profiles\n",
    "store_cluster_labels_in_profiles(agent_profiles, labels)\n",
    "\n",
    "# Display the resulting cluster labels and centers\n",
    "print(\"Cluster Labels:\", labels)\n",
    "print(\"Cluster Centers:\", centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels, centers\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Step 1: Construct agent feature matrix\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m feature_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_agent_feature_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_profiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Step 2: Select optimal K (number of clusters)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m K_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Testing K values from 2 to 9\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[40], line 13\u001b[0m, in \u001b[0;36mbuild_agent_feature_matrix\u001b[1;34m(agent_profiles)\u001b[0m\n\u001b[0;32m      8\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_var\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_general\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_latency_sensitive\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      9\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_deadline_hard\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_data_intensive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_compute_intensive\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     10\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon_atomic_share\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf_local\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm_local\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Ensure we are using the correct subset of columns and handle missing values\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m feature_matrix \u001b[38;5;241m=\u001b[39m \u001b[43magent_profiles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0.0\u001b[39m)  \u001b[38;5;66;03m# Filling missing values with zero\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_matrix\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Step 2: Select optimal K (number of clusters)\n",
    "K_range = range(2, 10)  # Testing K values from 2 to 9\n",
    "scores_df = compute_clustering_scores(feature_matrix, K_range)\n",
    "\n",
    "# Visualize the score table (optional)\n",
    "print(scores_df)\n",
    "\n",
    "# Step 3: Run KMeans with the optimal number of clusters (K_opt)\n",
    "K_opt = scores_df.loc[scores_df['Score'].idxmax(), 'K']  # Select K with highest combined score\n",
    "labels, centers = run_kmeans(feature_matrix, K_opt)\n",
    "\n",
    "# Step 4: Construct profiles for each cluster center\n",
    "cluster_centers_profiles = pd.DataFrame(centers, columns=feature_matrix.columns)\n",
    "cluster_centers_profiles[\"cluster_label\"] = range(K_opt)  # Add cluster label for each center\n",
    "\n",
    "# Optional: Visualize the cluster centers\n",
    "plt.scatter(feature_matrix['lambda_mean'], feature_matrix['lambda_var'], c=labels, cmap='viridis')\n",
    "plt.scatter(cluster_centers_profiles['lambda_mean'], cluster_centers_profiles['lambda_var'], c='red', marker='x', label='Cluster Centers')\n",
    "plt.xlabel('Lambda Mean')\n",
    "plt.ylabel('Lambda Variance')\n",
    "plt.title(f'Clustering with K={K_opt}')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Display the cluster centers\n",
    "display(cluster_centers_profiles)\n",
    "\n",
    "# Final output\n",
    "display(agent_profiles.head())\n",
    "\n",
    "# Save the centers profiles for later use\n",
    "cluster_centers_profiles.to_csv('cluster_centers_profiles.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
