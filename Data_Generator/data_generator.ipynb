{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"light\": {\n",
      "    \"ep0_episodes_csv\": \"./datasets\\\\light\\\\ep_000\\\\episodes.csv\",\n",
      "    \"ep0_agents_csv\": \"./datasets\\\\light\\\\ep_000\\\\agents.csv\",\n",
      "    \"ep0_arrivals_csv\": \"./datasets\\\\light\\\\ep_000\\\\arrivals.csv\",\n",
      "    \"ep0_tasks_csv\": \"./datasets\\\\light\\\\ep_000\\\\tasks.csv\",\n",
      "    \"meta\": \"./datasets\\\\light\\\\dataset_meta.json\"\n",
      "  },\n",
      "  \"moderate\": {\n",
      "    \"ep0_episodes_csv\": \"./datasets\\\\moderate\\\\ep_000\\\\episodes.csv\",\n",
      "    \"ep0_agents_csv\": \"./datasets\\\\moderate\\\\ep_000\\\\agents.csv\",\n",
      "    \"ep0_arrivals_csv\": \"./datasets\\\\moderate\\\\ep_000\\\\arrivals.csv\",\n",
      "    \"ep0_tasks_csv\": \"./datasets\\\\moderate\\\\ep_000\\\\tasks.csv\",\n",
      "    \"meta\": \"./datasets\\\\moderate\\\\dataset_meta.json\"\n",
      "  },\n",
      "  \"heavy\": {\n",
      "    \"ep0_episodes_csv\": \"./datasets\\\\heavy\\\\ep_000\\\\episodes.csv\",\n",
      "    \"ep0_agents_csv\": \"./datasets\\\\heavy\\\\ep_000\\\\agents.csv\",\n",
      "    \"ep0_arrivals_csv\": \"./datasets\\\\heavy\\\\ep_000\\\\arrivals.csv\",\n",
      "    \"ep0_tasks_csv\": \"./datasets\\\\heavy\\\\ep_000\\\\tasks.csv\",\n",
      "    \"meta\": \"./datasets\\\\heavy\\\\dataset_meta.json\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Data generator for Edge–MEC–Cloud with Poisson arrivals (per-second),\n",
    "lognormal task features (parameterized by median & sigma_g), and policy-agnostic outputs.\n",
    "\n",
    "Now supports THREE SCENARIOS (light / moderate / heavy) similar to HOODIE experiments.\n",
    "For each scenario we:\n",
    "  - synthesize time-stamped arrivals and task features for one or more episodes\n",
    "  - save CSV + a dataset_meta.json\n",
    "  - plot distribution figures (PNG) for key variables\n",
    "  - export a summary_stats.csv with quantiles/means\n",
    "\n",
    "Fixes/Improvements:\n",
    "- Per-episode subfolders (avoid overwrite) → ./datasets/<scenario>/ep_XXX/\n",
    "- Flexible lognormal quantile with small z-table + clamp\n",
    "- Parameter asserts & unit consistency\n",
    "- Richer summary (p90/p99, modality dist, tasks/hour)\n",
    "- Optional modality probabilities in TaskFeatureDist\n",
    "- Dtype optimization for large datasets\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, asdict, replace\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, math, os, json\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib, time, platform, getpass\n",
    "\n",
    "# -------------------------\n",
    "# reproducibility\n",
    "# -------------------------\n",
    "GLOBAL_SEED = 42\n",
    "rng_global = np.random.default_rng(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "\n",
    "# -------------------------\n",
    "# configuration dataclasses\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class EpisodeConf:\n",
    "    Delta: float      # seconds per slot\n",
    "    T_slots: int      # number of slots in the episode\n",
    "    seed: int\n",
    "\n",
    "@dataclass\n",
    "class AgentRanges:\n",
    "    # arrival rate per SECOND (will be multiplied by Delta per slot)\n",
    "    lam_sec_min: float\n",
    "    lam_sec_max: float\n",
    "    # optional local capacities (kept as meta for later)\n",
    "    f_local_min: float\n",
    "    f_local_max: float\n",
    "    m_local_min: float\n",
    "    m_local_max: float\n",
    "\n",
    "@dataclass\n",
    "class TaskFeatureDist:\n",
    "    # Lognormal parameterization via median and sigma_g (geometric std).\n",
    "    b_median: float = 3.0          # MB\n",
    "    b_sigma_g: float = 0.6\n",
    "\n",
    "    rho_median: float = 1.2e9      # cycles / MB\n",
    "    rho_sigma_g: float = 0.5\n",
    "\n",
    "    mem_median: float = 64.0       # MB\n",
    "    mem_sigma_g: float = 0.5\n",
    "\n",
    "    p_deadline: float = 0.25\n",
    "    deadline_min: float = 0.3      # seconds (relative)\n",
    "    deadline_max: float = 1.5\n",
    "\n",
    "    p_non_atomic: float = 0.35\n",
    "    split_ratio_min: float = 0.30  # fraction of task size that CAN be split\n",
    "    split_ratio_max: float = 0.80\n",
    "\n",
    "    # Optional modality probabilities (image, video, text, sensor)\n",
    "    modality_probs: Optional[List[float]] = None\n",
    "    modality_labels: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class GlobalConfig:\n",
    "    name: str\n",
    "    N_agents: int\n",
    "    Episode: EpisodeConf\n",
    "    AgentRanges: AgentRanges\n",
    "    TaskDist: TaskFeatureDist\n",
    "\n",
    "# -------------------------\n",
    "# asserts / validation\n",
    "# -------------------------\n",
    "def _validate_cfg(cfg: GlobalConfig) -> None:\n",
    "    assert cfg.N_agents > 0\n",
    "    assert cfg.Episode.Delta > 0 and cfg.Episode.T_slots > 0\n",
    "    ar = cfg.AgentRanges\n",
    "    assert ar.lam_sec_min >= 0 and ar.lam_sec_max >= ar.lam_sec_min\n",
    "    td = cfg.TaskDist\n",
    "    assert td.split_ratio_min > 0 and td.split_ratio_max <= 1.0 and td.split_ratio_max >= td.split_ratio_min\n",
    "    assert td.deadline_min <= td.deadline_max\n",
    "    # geometric std must be >= 1.0 (clamped later, but assert for awareness)\n",
    "    assert td.b_sigma_g >= 1.0 and td.rho_sigma_g >= 1.0 and td.mem_sigma_g >= 1.0\n",
    "\n",
    "# -------------------------\n",
    "# helpers\n",
    "# -------------------------\n",
    "_Z_TABLE = {\n",
    "    0.90: 1.2815515655446004,\n",
    "    0.95: 1.6448536269514722,\n",
    "    0.975: 1.959963984540054,\n",
    "    0.99: 2.3263478740408408,\n",
    "    0.995: 2.5758293035489004,\n",
    "    0.999: 3.090232306167813\n",
    "}\n",
    "\n",
    "def _z_from_p(p: float) -> float:\n",
    "    # Use small table + nearest clamp (no SciPy dependency)\n",
    "    if p in _Z_TABLE: return _Z_TABLE[p]\n",
    "    # clamp to nearest key\n",
    "    return _Z_TABLE[min(_Z_TABLE.keys(), key=lambda k: abs(k - p))]\n",
    "\n",
    "def lognormal_quantile(median: float, sigma_g: float, p: float) -> float:\n",
    "    # X ~ LogNormal(mu, sigma) with median=exp(mu), sigma_g=exp(sigma)\n",
    "    # quantile(p) = median * exp( z_p * ln(sigma_g) )\n",
    "    z = _z_from_p(p)\n",
    "    return median * math.exp(z * math.log(max(sigma_g, 1.0 + 1e-6)))\n",
    "\n",
    "def lognormal_from_median_sigma_g(rng, median: float, sigma_g: float, qcap: float | None = 0.99) -> float:\n",
    "    \"\"\"\n",
    "    Draw from LogNormal with given median and geometric std:\n",
    "      X ~ LogNormal(mu, sigma) where median = exp(mu), sigma_g = exp(sigma).\n",
    "      => mu = ln(median), sigma = ln(sigma_g)\n",
    "    \"\"\"\n",
    "    mu = math.log(max(median, 1e-12))\n",
    "    sigma = math.log(max(sigma_g, 1.0 + 1e-6))\n",
    "    x = float(rng.lognormal(mean=mu, sigma=sigma))\n",
    "    if qcap is not None:\n",
    "        cap = lognormal_quantile(median, sigma_g, qcap)\n",
    "        x = min(x, cap)\n",
    "    return x\n",
    "\n",
    "# -------------------------\n",
    "# entities\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class Agent:\n",
    "    agent_id: int\n",
    "    f_local: float\n",
    "    m_local: float\n",
    "    lam_sec: float   # Poisson rate per second (not per-slot)\n",
    "\n",
    "def build_agents(cfg: GlobalConfig, rng: np.random.Generator) -> List[Agent]:\n",
    "    agents: List[Agent] = []\n",
    "    for i in range(cfg.N_agents):\n",
    "        lam_sec = rng.uniform(cfg.AgentRanges.lam_sec_min, cfg.AgentRanges.lam_sec_max)\n",
    "        f_loc   = rng.uniform(cfg.AgentRanges.f_local_min, cfg.AgentRanges.f_local_max)\n",
    "        m_loc   = rng.uniform(cfg.AgentRanges.m_local_min, cfg.AgentRanges.m_local_max)\n",
    "        agents.append(Agent(agent_id=i, f_local=f_loc, m_local=m_loc, lam_sec=lam_sec))\n",
    "    return agents\n",
    "\n",
    "# -------------------------\n",
    "# task features\n",
    "# -------------------------\n",
    "def _modality_choice(rng: np.random.Generator, d: TaskFeatureDist) -> str:\n",
    "    labels = d.modality_labels or [\"image\",\"video\",\"text\",\"sensor\"]\n",
    "    if d.modality_probs is None:\n",
    "        probs = [0.3, 0.2, 0.3, 0.2]\n",
    "    else:\n",
    "        probs = d.modality_probs\n",
    "        assert abs(sum(probs) - 1.0) < 1e-6 and len(probs) == len(labels)\n",
    "    return rng.choice(labels, p=probs)\n",
    "\n",
    "def sample_task_features(cfg: GlobalConfig, rng: np.random.Generator, qcap: float = 0.99) -> Dict[str, float]:\n",
    "    d = cfg.TaskDist\n",
    "    b_mb   = lognormal_from_median_sigma_g(rng, d.b_median,   d.b_sigma_g,   qcap=qcap)\n",
    "    rho    = lognormal_from_median_sigma_g(rng, d.rho_median, d.rho_sigma_g, qcap=qcap)\n",
    "    c      = b_mb * rho                              # total cycles\n",
    "    mem_mb = lognormal_from_median_sigma_g(rng, d.mem_median, d.mem_sigma_g, qcap=qcap)\n",
    "    modality = _modality_choice(rng, d)\n",
    "    has_deadline = int(rng.random() < d.p_deadline)\n",
    "    deadline_s   = np.nan\n",
    "    if has_deadline:\n",
    "        deadline_s = float(rng.uniform(d.deadline_min, d.deadline_max))\n",
    "    non_atomic = int(rng.random() < d.p_non_atomic)\n",
    "    split_ratio = float(rng.uniform(d.split_ratio_min, d.split_ratio_max)) if non_atomic else 0.0\n",
    "    \n",
    "    return dict(\n",
    "        b_mb=b_mb, rho=rho, c_cycles=c, mem_mb=mem_mb, modality=modality,\n",
    "        has_deadline=has_deadline, deadline_s=deadline_s, non_atomic=non_atomic, split_ratio=split_ratio\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# episode generator (arrivals only)\n",
    "# -------------------------\n",
    "def run_episode(cfg: GlobalConfig, agents: List[Agent], episode_id: int = 0, qcap: float = 0.99) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate time-stamped arrivals and task features for one episode.\n",
    "    \"\"\"\n",
    "    _validate_cfg(cfg)\n",
    "    rng_local = np.random.default_rng(cfg.Episode.seed + episode_id)\n",
    "\n",
    "    rows_episodes: List[Dict] = []\n",
    "    rows_agents:   List[Dict] = [asdict(a) for a in agents]\n",
    "    rows_arrivals: List[Dict] = []\n",
    "    rows_tasks:    List[Dict] = []\n",
    "\n",
    "    Delta   = cfg.Episode.Delta\n",
    "    T_slots = cfg.Episode.T_slots\n",
    "\n",
    "    task_id_counter = 0\n",
    "\n",
    "    for t in range(T_slots):\n",
    "        t_time = t * Delta\n",
    "        for a in agents:\n",
    "            # per-slot rate from per-second rate:\n",
    "            lam_slot = a.lam_sec * Delta\n",
    "            n_new = rng_local.poisson(lam=lam_slot)\n",
    "            if n_new <= 0:\n",
    "                continue\n",
    "            for _ in range(n_new):\n",
    "                feat = sample_task_features(cfg, rng_local, qcap=qcap)\n",
    "\n",
    "                # absolute deadline time (NaN if none)\n",
    "                if np.isnan(feat[\"deadline_s\"]):\n",
    "                    deadline_time = np.nan\n",
    "                else:\n",
    "                    deadline_time = t_time + feat[\"deadline_s\"]\n",
    "\n",
    "                action_space_hint = \"continuous\" if feat[\"non_atomic\"] == 1 else \"discrete\"\n",
    "\n",
    "                rows_arrivals.append({\n",
    "                    \"scenario\": cfg.name,\n",
    "                    \"episode_id\": episode_id,\n",
    "                    \"t_slot\": t,\n",
    "                    \"t_time\": t_time,\n",
    "                    \"agent_id\": a.agent_id,\n",
    "                    \"task_id\": task_id_counter\n",
    "                })\n",
    "\n",
    "                rows_tasks.append({\n",
    "                    \"scenario\": cfg.name,\n",
    "                    \"episode_id\": episode_id,\n",
    "                    \"task_id\": task_id_counter,\n",
    "                    \"agent_id\": a.agent_id,\n",
    "                    \"t_arrival_slot\": t,\n",
    "                    \"t_arrival_time\": t_time,\n",
    "                    \"b_mb\": feat[\"b_mb\"],\n",
    "                    \"rho_cyc_per_mb\": feat[\"rho\"],\n",
    "                    \"c_cycles\": feat[\"c_cycles\"],\n",
    "                    \"mem_mb\": feat[\"mem_mb\"],\n",
    "                    \"modality\": feat[\"modality\"],\n",
    "                    \"has_deadline\": feat[\"has_deadline\"],\n",
    "                    \"deadline_s\": feat[\"deadline_s\"],\n",
    "                    \"deadline_time\": deadline_time,\n",
    "                    \"non_atomic\": feat[\"non_atomic\"],\n",
    "                    \"split_ratio\": feat[\"split_ratio\"],\n",
    "                    \"action_space_hint\": action_space_hint\n",
    "                })\n",
    "\n",
    "                task_id_counter += 1\n",
    "\n",
    "    rows_episodes.append({\n",
    "        \"scenario\": cfg.name,\n",
    "        \"episode_id\": episode_id,\n",
    "        \"Delta\": Delta,\n",
    "        \"T_slots\": T_slots,\n",
    "        \"hours\": T_slots * Delta / 3600.0,\n",
    "        \"N_agents\": len(agents),\n",
    "        \"seed\": cfg.Episode.seed + episode_id\n",
    "    })\n",
    "\n",
    "    episodes_df = pd.DataFrame(rows_episodes)\n",
    "    agents_df   = pd.DataFrame(rows_agents)\n",
    "    arrivals_df = pd.DataFrame(rows_arrivals)\n",
    "    tasks_df    = pd.DataFrame(rows_tasks)\n",
    "\n",
    "    # Optimize dtypes (optional but useful)\n",
    "    if len(tasks_df):\n",
    "        tasks_df[\"modality\"] = tasks_df[\"modality\"].astype(\"category\")\n",
    "        tasks_df[\"action_space_hint\"] = tasks_df[\"action_space_hint\"].astype(\"category\")\n",
    "        # ints\n",
    "        for col in [\"episode_id\",\"task_id\",\"agent_id\",\"t_arrival_slot\",\"has_deadline\",\"non_atomic\"]:\n",
    "            if col in tasks_df:\n",
    "                tasks_df[col] = tasks_df[col].astype(\"int32\")\n",
    "        # floats\n",
    "        for col in [\"t_arrival_time\",\"b_mb\",\"rho_cyc_per_mb\",\"c_cycles\",\"mem_mb\",\"deadline_s\",\"deadline_time\",\"split_ratio\"]:\n",
    "            if col in tasks_df:\n",
    "                tasks_df[col] = tasks_df[col].astype(\"float32\")\n",
    "\n",
    "    if len(arrivals_df):\n",
    "        for col in [\"episode_id\",\"t_slot\",\"agent_id\",\"task_id\"]:\n",
    "            if col in arrivals_df:\n",
    "                arrivals_df[col] = arrivals_df[col].astype(\"int32\")\n",
    "        for col in [\"t_time\"]:\n",
    "            if col in arrivals_df:\n",
    "                arrivals_df[col] = arrivals_df[col].astype(\"float32\")\n",
    "\n",
    "    if len(agents_df):\n",
    "        for col in [\"agent_id\"]:\n",
    "            agents_df[col] = agents_df[col].astype(\"int32\")\n",
    "        for col in [\"f_local\",\"m_local\",\"lam_sec\"]:\n",
    "            agents_df[col] = agents_df[col].astype(\"float64\")\n",
    "\n",
    "    return {\n",
    "        \"episodes\": episodes_df,\n",
    "        \"agents\":   agents_df,\n",
    "        \"arrivals\": arrivals_df,\n",
    "        \"tasks\":    tasks_df\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# save & plotting utilities\n",
    "# -------------------------\n",
    "def save_dataset(dfs: Dict[str, pd.DataFrame], out_dir: str = \".\") -> Dict[str, str]:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    paths: Dict[str, str] = {}\n",
    "    for name, df in dfs.items():\n",
    "        csv_path = os.path.join(out_dir, f\"{name}.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        paths[name + \"_csv\"] = csv_path\n",
    "    return paths\n",
    "\n",
    "def _config_fingerprint(cfg: GlobalConfig) -> str:\n",
    "    s = json.dumps({\n",
    "        \"scenario\": cfg.name,\n",
    "        \"Episode\": asdict(cfg.Episode),\n",
    "        \"AgentRanges\": asdict(cfg.AgentRanges),\n",
    "        \"TaskDist\": asdict(cfg.TaskDist)\n",
    "    }, sort_keys=True).encode(\"utf-8\")\n",
    "    return hashlib.sha256(s).hexdigest()[:16]\n",
    "\n",
    "def save_meta(cfg: GlobalConfig, out_dir: str = \".\", qcap: float = 0.99) -> str:\n",
    "    meta = {\n",
    "        \"schema_version\": \"1.0.0\",\n",
    "        \"scenario\": cfg.name,\n",
    "        \"seed\": cfg.Episode.seed,\n",
    "        \"fingerprint\": _config_fingerprint(cfg),\n",
    "        \"generated_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"env\": {\"python\": platform.python_version(), \"user\": getpass.getuser()},\n",
    "        \"Episode\": asdict(cfg.Episode),\n",
    "        \"N_agents\": cfg.N_agents,\n",
    "        \"AgentRanges\": asdict(cfg.AgentRanges),\n",
    "        \"TaskDist\": asdict(cfg.TaskDist),\n",
    "        \"units\": {\n",
    "            \"Delta\": \"seconds\",\n",
    "            \"lam_sec\": \"tasks per second (per agent)\",\n",
    "            \"per_slot_rate\": \"lam_sec * Delta\",\n",
    "            \"b_mb\": \"MB\",\n",
    "            \"rho_cyc_per_mb\": \"CPU cycles per MB\",\n",
    "            \"c_cycles\": \"CPU cycles\",\n",
    "            \"mem_mb\": \"MB\",\n",
    "            \"deadline_s\": \"seconds (relative); deadline_time = t_arrival_time + deadline_s\",\n",
    "            \"f_local\": \"Hz\",\n",
    "            \"m_local\": \"MB\"\n",
    "        },\n",
    "        \"notes\": {\n",
    "            \"policy_agnostic\": True,\n",
    "            \"queueing\": \"not simulated here\",\n",
    "            \"clipping\": {\n",
    "                \"enabled\": True,\n",
    "                \"method\": \"lognormal analytic quantile cap\",\n",
    "                \"qcap\": qcap,\n",
    "                \"z_table_keys\": sorted(list(_Z_TABLE.keys()))\n",
    "            },\n",
    "            \"action_space_hint\": \"derived from non_atomic; final decision belongs to environment\"\n",
    "        }\n",
    "    }\n",
    "    path = os.path.join(out_dir, f\"dataset_meta.json\")\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "    return path\n",
    "\n",
    "def summarize_and_plot(dfs: Dict[str, pd.DataFrame], out_dir: str) -> None:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    tasks = dfs[\"tasks\"].copy()\n",
    "    arrivals = dfs[\"arrivals\"].copy()\n",
    "    episodes = dfs[\"episodes\"].copy()\n",
    "\n",
    "    # ---- summary stats\n",
    "    def q(series: pd.Series, p: float):\n",
    "        return float(np.nanquantile(series.dropna(), p)) if len(series.dropna()) else float(\"nan\")\n",
    "\n",
    "    tasks_per_hour = float(len(tasks)) / float(episodes.iloc[0][\"hours\"]) if len(episodes) and episodes.iloc[0][\"hours\"] > 0 else float(\"nan\")\n",
    "\n",
    "    # modality distribution\n",
    "    mod_counts = tasks[\"modality\"].value_counts(dropna=False) if len(tasks) else pd.Series(dtype=int)\n",
    "    mod_dist = {str(k): int(v) for k, v in mod_counts.to_dict().items()}\n",
    "\n",
    "    summary = {\n",
    "        \"n_tasks\": [len(tasks)],\n",
    "        \"n_arrivals\": [len(arrivals)],\n",
    "        \"tasks_per_hour\": [tasks_per_hour],\n",
    "        \"b_mb_median\": [q(tasks[\"b_mb\"], 0.5)],\n",
    "        \"b_mb_p90\": [q(tasks[\"b_mb\"], 0.9)],\n",
    "        \"b_mb_p99\": [q(tasks[\"b_mb\"], 0.99)],\n",
    "        \"rho_median\": [q(tasks[\"rho_cyc_per_mb\"], 0.5)],\n",
    "        \"rho_p90\": [q(tasks[\"rho_cyc_per_mb\"], 0.9)],\n",
    "        \"c_cycles_median\": [q(tasks[\"c_cycles\"], 0.5)],\n",
    "        \"c_cycles_p90\": [q(tasks[\"c_cycles\"], 0.9)],\n",
    "        \"c_cycles_p99\": [q(tasks[\"c_cycles\"], 0.99)],\n",
    "        \"deadline_share\": [float((tasks[\"has_deadline\"]==1).mean()) if len(tasks) else float(\"nan\")],\n",
    "        \"non_atomic_share\": [float((tasks[\"non_atomic\"]==1).mean()) if len(tasks) else float(\"nan\")],\n",
    "        \"modality_counts_json\": [json.dumps(mod_dist)]\n",
    "    }\n",
    "    pd.DataFrame(summary).to_csv(os.path.join(out_dir, f\"summary_stats.csv\"), index=False)\n",
    "\n",
    "    # ---- plots (each in its own figure)\n",
    "    def hist_plot(series: pd.Series, title: str, fname: str, logx: bool=False):\n",
    "        plt.figure()\n",
    "        s = series.dropna()\n",
    "        if len(s) == 0:\n",
    "            plt.title(title + \" (no data)\")\n",
    "        else:\n",
    "            plt.hist(s, bins=50)\n",
    "            if logx:\n",
    "                plt.xscale('log')\n",
    "            plt.title(title)\n",
    "            plt.xlabel(title)\n",
    "            plt.ylabel(\"count\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, fname), dpi=160)\n",
    "        plt.close()\n",
    "\n",
    "    hist_plot(tasks[\"b_mb\"],            title=\"Task size (MB)\",                fname=f\"hist_b_mb.png\", logx=True)\n",
    "    hist_plot(tasks[\"rho_cyc_per_mb\"],  title=\"Compute density (cycles/MB)\",   fname=f\"hist_rho.png\",  logx=True)\n",
    "    hist_plot(tasks[\"c_cycles\"],        title=\"Total cycles\",                  fname=f\"hist_c_cycles.png\", logx=True)\n",
    "    hist_plot(tasks[\"deadline_s\"],      title=\"Deadline (s)\",                  fname=f\"hist_deadline_s.png\", logx=False)\n",
    "    hist_plot(tasks.loc[tasks[\"non_atomic\"]==1, \"split_ratio\"], title=\"Split ratio (only non-atomic)\", fname=f\"hist_split_ratio.png\", logx=False)\n",
    "\n",
    "    # arrivals per agent\n",
    "    if len(arrivals):\n",
    "        per_agent = arrivals.groupby(\"agent_id\").size()\n",
    "        plt.figure()\n",
    "        plt.bar(per_agent.index.astype(str), per_agent.values)\n",
    "        plt.title(\"Arrivals per agent\")\n",
    "        plt.xlabel(\"agent_id\")\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f\"bar_arrivals_per_agent.png\"), dpi=160)\n",
    "        plt.close()\n",
    "\n",
    "# -------------------------\n",
    "# scenario presets (light / moderate / heavy)\n",
    "# -------------------------\n",
    "HOURS = 1\n",
    "DEFAULT_DELTA = 1.0\n",
    "DEFAULT_T_SLOTS = int(HOURS * 3600 / DEFAULT_DELTA)\n",
    "\n",
    "BASE_EPISODE = EpisodeConf(Delta=DEFAULT_DELTA, T_slots=DEFAULT_T_SLOTS, seed=GLOBAL_SEED)\n",
    "BASE_AGENT_RANGES = AgentRanges(\n",
    "    lam_sec_min=0.02, lam_sec_max=0.80,\n",
    "    f_local_min=0.8e9, f_local_max=2.4e9,\n",
    "    m_local_min=3e3,  m_local_max=8e3 # MB\n",
    ")\n",
    "BASE_TASK_DIST = TaskFeatureDist()\n",
    "\n",
    "SCENARIOS: List[GlobalConfig] = [\n",
    "    GlobalConfig(\n",
    "        name=\"light\",\n",
    "        N_agents=18,\n",
    "        Episode=replace(BASE_EPISODE, seed=GLOBAL_SEED + 101),\n",
    "        AgentRanges=replace(BASE_AGENT_RANGES, lam_sec_min=0.01, lam_sec_max=0.05),\n",
    "        TaskDist=replace(BASE_TASK_DIST,\n",
    "            b_median=2.0,  b_sigma_g=1.55,\n",
    "            rho_median=1.0e9, rho_sigma_g=1.45,\n",
    "            mem_median=64.0, mem_sigma_g=1.40,\n",
    "            p_deadline=0.15, deadline_min=0.8, deadline_max=2.0,\n",
    "            p_non_atomic=0.25, split_ratio_min=0.25, split_ratio_max=0.75)\n",
    "    ),\n",
    "    GlobalConfig(\n",
    "        name=\"moderate\",\n",
    "        N_agents=18,\n",
    "        Episode=replace(BASE_EPISODE, seed=GLOBAL_SEED + 202),\n",
    "        AgentRanges=replace(BASE_AGENT_RANGES, lam_sec_min=0.05, lam_sec_max=0.20),\n",
    "        TaskDist=replace(BASE_TASK_DIST,\n",
    "            b_median=3.0,  b_sigma_g=1.60,\n",
    "            rho_median=1.2e9, rho_sigma_g=1.50,\n",
    "            mem_median=64.0, mem_sigma_g=1.45,\n",
    "            p_deadline=0.25, deadline_min=0.5, deadline_max=1.5,\n",
    "            p_non_atomic=0.35, split_ratio_min=0.30, split_ratio_max=0.80)\n",
    "    ),\n",
    "    GlobalConfig(\n",
    "        name=\"heavy\",\n",
    "        N_agents=18,\n",
    "        Episode=replace(BASE_EPISODE, seed=GLOBAL_SEED + 303),\n",
    "        AgentRanges=replace(BASE_AGENT_RANGES, lam_sec_min=0.20, lam_sec_max=0.80),\n",
    "        TaskDist=replace(BASE_TASK_DIST,\n",
    "            b_median=5.0,  b_sigma_g=1.70,\n",
    "            rho_median=1.5e9, rho_sigma_g=1.55,\n",
    "            mem_median=64.0, mem_sigma_g=1.50,\n",
    "            p_deadline=0.35, deadline_min=0.3, deadline_max=1.0,\n",
    "            p_non_atomic=0.45, split_ratio_min=0.40, split_ratio_max=0.85)\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# main driver\n",
    "# -------------------------\n",
    "def main_generate(cfg: GlobalConfig, episodes: int = 1, out_root: str = \"./datasets\", qcap: float = 0.99) -> Dict[str, str]:\n",
    "    \"\"\"Generate 'episodes' episodes for one scenario (fixed agent pool per scenario).\"\"\"\n",
    "    _validate_cfg(cfg)\n",
    "    out_dir = os.path.join(out_root, cfg.name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # build agents once per scenario to keep them consistent across its episodes\n",
    "    rng_agents = np.random.default_rng(cfg.Episode.seed + 10_000)\n",
    "    agents = build_agents(cfg, rng_agents)\n",
    "\n",
    "    all_paths: Dict[str, str] = {}\n",
    "    for ep in range(episodes):\n",
    "        ep_dir = os.path.join(out_dir, f\"ep_{ep:03d}\")\n",
    "        os.makedirs(ep_dir, exist_ok=True)\n",
    "\n",
    "        dfs = run_episode(cfg, agents, episode_id=ep, qcap=qcap)\n",
    "        paths = save_dataset(dfs, out_dir=ep_dir)\n",
    "        summarize_and_plot(dfs, out_dir=ep_dir)\n",
    "        all_paths.update({f\"ep{ep}_{k}\": v for k, v in paths.items()})\n",
    "\n",
    "    meta_path = save_meta(cfg, out_dir=out_dir, qcap=qcap)\n",
    "    all_paths[\"meta\"] = meta_path\n",
    "    return all_paths\n",
    "\n",
    "def generate_all_scenarios(episodes_each: int = 1, out_root: str = \"./datasets\", qcap: float = 0.99) -> Dict[str, Dict[str, str]]:\n",
    "    results: Dict[str, Dict[str, str]] = {}\n",
    "    for cfg in SCENARIOS:\n",
    "        results[cfg.name] = main_generate(cfg, episodes=episodes_each, out_root=out_root, qcap=qcap)\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out = generate_all_scenarios(episodes_each=1, out_root=\"./datasets\")\n",
    "    print(json.dumps(out, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
