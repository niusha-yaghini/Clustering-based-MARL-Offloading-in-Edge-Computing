{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"light\": {\n",
      "    \"meta\": \"./datasets\\\\light\\\\dataset_meta.json\"\n",
      "  },\n",
      "  \"moderate\": {\n",
      "    \"meta\": \"./datasets\\\\moderate\\\\dataset_meta.json\"\n",
      "  },\n",
      "  \"heavy\": {\n",
      "    \"meta\": \"./datasets\\\\heavy\\\\dataset_meta.json\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Data generator for Edge–MEC–Cloud with Poisson arrivals (per-second),\n",
    "lognormal task features (parameterized by median & sigma_g), and policy-agnostic outputs.\n",
    "\n",
    "Now supports THREE SCENARIOS (light / moderate / heavy) similar in spirit to HOODIE experiments.\n",
    "For each scenario we:\n",
    "  - synthesize time-stamped arrivals and task features for one or more episodes\n",
    "  - save CSV + (optionally) Parquet + a dataset_meta.json\n",
    "  - plot distribution figures (PNG) for key variables\n",
    "  - export a summary_stats.csv with quantiles/means\n",
    "\n",
    "No routing/decisions here; purely input data synthesis for later algorithms.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, asdict, replace\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, math, os, json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# reproducibility\n",
    "# -------------------------\n",
    "GLOBAL_SEED = 42\n",
    "rng_global = np.random.default_rng(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "\n",
    "# -------------------------\n",
    "# configuration dataclasses\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class EpisodeConf:\n",
    "    Delta: float      # seconds per slot\n",
    "    T_slots: int      # number of slots in the episode\n",
    "    seed: int\n",
    "\n",
    "@dataclass\n",
    "class AgentRanges:\n",
    "    # arrival rate per SECOND (will be multiplied by Delta per slot)\n",
    "    lam_sec_min: float\n",
    "    lam_sec_max: float\n",
    "    \n",
    "    # optional local capacities (kept as meta for later)\n",
    "    f_local_min: float\n",
    "    f_local_max: float\n",
    "    m_local_min: float\n",
    "    m_local_max: float\n",
    "\n",
    "@dataclass\n",
    "class TaskFeatureDist:\n",
    "    # Lognormal parameterization via median and sigma_g (geometric std).\n",
    "    b_median: float = 3.0          # MB\n",
    "    b_sigma_g: float = 0.6\n",
    "\n",
    "    rho_median: float = 1.2e9      # cycles / MB\n",
    "    rho_sigma_g: float = 0.5\n",
    "\n",
    "    mem_median: float = 64.0       # MB\n",
    "    mem_sigma_g: float = 0.5\n",
    "\n",
    "    p_deadline: float = 0.25\n",
    "    deadline_min: float = 0.3      # seconds (relative)\n",
    "    deadline_max: float = 1.5\n",
    "\n",
    "    p_non_atomic: float = 0.35\n",
    "    split_ratio_min: float = 0.30  # fraction of task size that CAN be split\n",
    "    split_ratio_max: float = 0.80\n",
    "\n",
    "@dataclass\n",
    "class GlobalConfig:\n",
    "    name: str\n",
    "    N_agents: int\n",
    "    Episode: EpisodeConf\n",
    "    AgentRanges: AgentRanges\n",
    "    TaskDist: TaskFeatureDist\n",
    "\n",
    "# -------------------------\n",
    "# helpers\n",
    "# -------------------------\n",
    "def lognormal_from_median_sigma_g(rng: np.random.Generator, median: float, sigma_g: float) -> float:\n",
    "    \"\"\"\n",
    "    Draw from LogNormal with given median and geometric std:\n",
    "      X ~ LogNormal(mu, sigma) where median = exp(mu), sigma_g = exp(sigma).\n",
    "      => mu = ln(median), sigma = ln(sigma_g)\n",
    "    \"\"\"\n",
    "    mu = math.log(max(median, 1e-12))\n",
    "    sigma = math.log(max(sigma_g, 1.0 + 1e-6))\n",
    "    return float(rng.lognormal(mean=mu, sigma=sigma))\n",
    "\n",
    "# -------------------------\n",
    "# entities\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class Agent:\n",
    "    agent_id: int\n",
    "    f_local: float\n",
    "    m_local: float\n",
    "    lam_sec: float   # Poisson rate per second (not per-slot)\n",
    "\n",
    "def build_agents(cfg: GlobalConfig, rng: np.random.Generator) -> List[Agent]:\n",
    "    agents: List[Agent] = []\n",
    "    for i in range(cfg.N_agents):\n",
    "        lam_sec = rng.uniform(cfg.AgentRanges.lam_sec_min, cfg.AgentRanges.lam_sec_max)\n",
    "        f_loc   = rng.uniform(cfg.AgentRanges.f_local_min, cfg.AgentRanges.f_local_max)\n",
    "        m_loc   = rng.uniform(cfg.AgentRanges.m_local_min, cfg.AgentRanges.m_local_max)\n",
    "        agents.append(Agent(agent_id=i, f_local=f_loc, m_local=m_loc, lam_sec=lam_sec))\n",
    "    return agents\n",
    "\n",
    "# -------------------------\n",
    "# task features\n",
    "# -------------------------\n",
    "def sample_task_features(cfg: GlobalConfig, rng: np.random.Generator) -> Dict[str, float]:\n",
    "    d = cfg.TaskDist\n",
    "    b_mb   = lognormal_from_median_sigma_g(rng, d.b_median,   d.b_sigma_g)\n",
    "    rho    = lognormal_from_median_sigma_g(rng, d.rho_median, d.rho_sigma_g)\n",
    "    c      = b_mb * rho                              # total cycles\n",
    "    mem_mb = lognormal_from_median_sigma_g(rng, d.mem_median, d.mem_sigma_g)\n",
    "    modality = rng.choice([\"image\",\"video\",\"text\",\"sensor\"], p=[0.3,0.2,0.3,0.2])\n",
    "    has_deadline = int(rng.random() < d.p_deadline)\n",
    "    deadline_s   = np.nan\n",
    "    if has_deadline:\n",
    "        deadline_s = float(rng.uniform(d.deadline_min, d.deadline_max))\n",
    "    non_atomic = int(rng.random() < d.p_non_atomic)\n",
    "    split_ratio = float(rng.uniform(d.split_ratio_min, d.split_ratio_max)) if non_atomic else 0.0\n",
    "    \n",
    "    return dict(\n",
    "        b_mb=b_mb, rho=rho, c_cycles=c, mem_mb=mem_mb, modality=modality, has_deadline=has_deadline, \n",
    "        deadline_s=deadline_s, non_atomic=non_atomic, split_ratio=split_ratio\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# episode generator (arrivals only)\n",
    "# -------------------------\n",
    "def run_episode(cfg: GlobalConfig, agents: List[Agent], episode_id: int = 0) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generate time-stamped arrivals and task features for one episode.\n",
    "    \"\"\"\n",
    "    rng_local = np.random.default_rng(cfg.Episode.seed + episode_id)\n",
    "\n",
    "    rows_episodes: List[Dict] = []\n",
    "    rows_agents:   List[Dict] = [asdict(a) for a in agents]\n",
    "    rows_arrivals: List[Dict] = []\n",
    "    rows_tasks:    List[Dict] = []\n",
    "\n",
    "    Delta   = cfg.Episode.Delta\n",
    "    T_slots = cfg.Episode.T_slots\n",
    "\n",
    "    task_id_counter = 0\n",
    "\n",
    "    for t in range(T_slots):\n",
    "        t_time = t * Delta\n",
    "        for a in agents:\n",
    "            # per-slot rate from per-second rate:\n",
    "            lam_slot = a.lam_sec * Delta\n",
    "            n_new = rng_local.poisson(lam=lam_slot)\n",
    "            if n_new <= 0:\n",
    "                continue\n",
    "            for _ in range(n_new):\n",
    "                feat = sample_task_features(cfg, rng_local)\n",
    "\n",
    "                # absolute deadline time (NaN if none)\n",
    "                if np.isnan(feat[\"deadline_s\"]):\n",
    "                    deadline_time = np.nan\n",
    "                else:\n",
    "                    deadline_time = t_time + feat[\"deadline_s\"]\n",
    "\n",
    "                action_space_hint = \"continuous\" if feat[\"non_atomic\"] == 1 else \"discrete\"\n",
    "\n",
    "                rows_arrivals.append({\n",
    "                    \"scenario\": cfg.name,\n",
    "                    \"episode_id\": episode_id,\n",
    "                    \"t_slot\": t,\n",
    "                    \"t_time\": t_time,\n",
    "                    \"agent_id\": a.agent_id,\n",
    "                    \"task_id\": task_id_counter\n",
    "                })\n",
    "\n",
    "                rows_tasks.append({\n",
    "                    \"scenario\": cfg.name,\n",
    "                    \"episode_id\": episode_id,\n",
    "                    \"task_id\": task_id_counter,\n",
    "                    \"agent_id\": a.agent_id,\n",
    "                    \"t_arrival_slot\": t,\n",
    "                    \"t_arrival_time\": t_time,\n",
    "                    \"b_mb\": feat[\"b_mb\"],\n",
    "                    \"rho_cyc_per_mb\": feat[\"rho\"],\n",
    "                    \"c_cycles\": feat[\"c_cycles\"],\n",
    "                    \"mem_mb\": feat[\"mem_mb\"],\n",
    "                    \"modality\": feat[\"modality\"],\n",
    "                    \"has_deadline\": feat[\"has_deadline\"],\n",
    "                    \"deadline_s\": feat[\"deadline_s\"],\n",
    "                    \"deadline_time\": deadline_time,\n",
    "                    \"non_atomic\": feat[\"non_atomic\"],\n",
    "                    \"split_ratio\": feat[\"split_ratio\"],\n",
    "                    \"action_space_hint\": action_space_hint\n",
    "                })\n",
    "\n",
    "                task_id_counter += 1\n",
    "\n",
    "    rows_episodes.append({\n",
    "        \"scenario\": cfg.name,\n",
    "        \"episode_id\": episode_id,\n",
    "        \"Delta\": Delta,\n",
    "        \"T_slots\": T_slots,\n",
    "        \"hours\": T_slots * Delta / 3600.0,\n",
    "        \"N_agents\": len(agents),\n",
    "        \"seed\": cfg.Episode.seed + episode_id\n",
    "    })\n",
    "\n",
    "    episodes_df = pd.DataFrame(rows_episodes)\n",
    "    agents_df   = pd.DataFrame(rows_agents)\n",
    "    arrivals_df = pd.DataFrame(rows_arrivals)\n",
    "    tasks_df    = pd.DataFrame(rows_tasks)\n",
    "\n",
    "    # Optimize dtypes (optional but useful)\n",
    "    if len(tasks_df):\n",
    "        tasks_df[\"modality\"] = tasks_df[\"modality\"].astype(\"category\")\n",
    "        tasks_df[\"action_space_hint\"] = tasks_df[\"action_space_hint\"].astype(\"category\")\n",
    "\n",
    "    return {\n",
    "        \"episodes\": episodes_df,\n",
    "        \"agents\":   agents_df,\n",
    "        \"arrivals\": arrivals_df,\n",
    "        \"tasks\":    tasks_df\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# save & plotting utilities\n",
    "# -------------------------\n",
    "def save_dataset(dfs: Dict[str, pd.DataFrame], out_dir: str = \".\") -> Dict[str, str]:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    paths: Dict[str, str] = {}\n",
    "    for name, df in dfs.items():\n",
    "        csv_path = os.path.join(out_dir, f\"{name}.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        paths[name + \"_csv\"] = csv_path\n",
    "    return paths\n",
    "\n",
    "def save_meta(cfg: GlobalConfig, out_dir: str = \".\") -> str:\n",
    "    meta = {\n",
    "        \"scenario\": cfg.name,\n",
    "        \"seed\": cfg.Episode.seed,\n",
    "        \"Delta\": cfg.Episode.Delta,\n",
    "        \"T_slots\": cfg.Episode.T_slots,\n",
    "        \"N_agents\": cfg.N_agents,\n",
    "        \"AgentRanges\": asdict(cfg.AgentRanges),\n",
    "        \"TaskDist\": asdict(cfg.TaskDist),\n",
    "        \"notes\": {\n",
    "            \"rates_unit\": \"lam_sec is per-second; per-slot rate = lam_sec * Delta\",\n",
    "            \"b_unit\": \"MB\",\n",
    "            \"rho_unit\": \"cycles per MB\",\n",
    "            \"c_unit\": \"cycles\",\n",
    "            \"deadline_s\": \"relative seconds; deadline_time = t_arrival_time + deadline_s\",\n",
    "            \"non_atomic\": \"1 means task can be split; split_ratio = fraction of size that can be split\"\n",
    "        }\n",
    "    }\n",
    "    path = os.path.join(out_dir, f\"dataset_meta.json\")\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "    return path\n",
    "\n",
    "def summarize_and_plot(dfs: Dict[str, pd.DataFrame], out_dir: str) -> None:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    tasks = dfs[\"tasks\"].copy()\n",
    "    arrivals = dfs[\"arrivals\"].copy()\n",
    "\n",
    "    # ---- summary stats\n",
    "    def q(s, p):\n",
    "        return float(np.nanquantile(s, p)) if len(s.dropna()) else float(\"nan\")\n",
    "\n",
    "    summary = {\n",
    "        \"n_tasks\": [len(tasks)],\n",
    "        \"n_arrivals\": [len(arrivals)],\n",
    "        \"b_mb_median\": [q(tasks[\"b_mb\"], 0.5)],\n",
    "        \"b_mb_p90\": [q(tasks[\"b_mb\"], 0.9)],\n",
    "        \"rho_median\": [q(tasks[\"rho_cyc_per_mb\"], 0.5)],\n",
    "        \"c_cycles_median\": [q(tasks[\"c_cycles\"], 0.5)],\n",
    "        \"deadline_share\": [float((tasks[\"has_deadline\"]==1).mean()) if len(tasks) else float(\"nan\")],\n",
    "        \"non_atomic_share\": [float((tasks[\"non_atomic\"]==1).mean()) if len(tasks) else float(\"nan\")]\n",
    "    }\n",
    "    pd.DataFrame(summary).to_csv(os.path.join(out_dir, f\"summary_stats.csv\"), index=False)\n",
    "\n",
    "    # ---- plots (each in its own figure)\n",
    "    def hist_plot(series: pd.Series, title: str, fname: str, logx: bool=False):\n",
    "        plt.figure()\n",
    "        s = series.dropna()\n",
    "        if len(s) == 0:\n",
    "            plt.title(title + \" (no data)\")\n",
    "        else:\n",
    "            # Use automatic bins; avoid specifying colors to keep neutral styling\n",
    "            plt.hist(s, bins=50)\n",
    "            if logx:\n",
    "                plt.xscale('log')\n",
    "            plt.title(title)\n",
    "            plt.xlabel(title)\n",
    "            plt.ylabel(\"count\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, fname), dpi=160)\n",
    "        plt.close()\n",
    "\n",
    "    hist_plot(tasks[\"b_mb\"],           title=\"Task size (MB)\",              fname=f\"hist_b_mb.png\", logx=True)\n",
    "    hist_plot(tasks[\"rho_cyc_per_mb\"], title=\"Compute density (cycles/MB)\", fname=f\"hist_rho.png\",  logx=True)\n",
    "    hist_plot(tasks[\"c_cycles\"],       title=\"Total cycles\",                fname=f\"hist_c_cycles.png\", logx=True)\n",
    "    hist_plot(tasks[\"deadline_s\"],     title=\"Deadline (s)\",                fname=f\"hist_deadline_s.png\", logx=False)\n",
    "    hist_plot(tasks.loc[tasks[\"non_atomic\"]==1, \"split_ratio\"], title=\"Split ratio (only non-atomic)\", fname=f\"hist_split_ratio.png\", logx=False)\n",
    "\n",
    "    # arrivals per agent\n",
    "    if len(arrivals):\n",
    "        per_agent = arrivals.groupby(\"agent_id\").size()\n",
    "        plt.figure()\n",
    "        plt.bar(per_agent.index.astype(str), per_agent.values)\n",
    "        plt.title(\"Arrivals per agent\")\n",
    "        plt.xlabel(\"agent_id\")\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f\"bar_arrivals_per_agent.png\"), dpi=160)\n",
    "        plt.close()\n",
    "\n",
    "# -------------------------\n",
    "# scenario presets (light / moderate / heavy)\n",
    "# -------------------------\n",
    "HOURS = 1\n",
    "DEFAULT_DELTA = 1.0\n",
    "DEFAULT_T_SLOTS = int(HOURS * 3600 / DEFAULT_DELTA)\n",
    "\n",
    "BASE_EPISODE = EpisodeConf(Delta=DEFAULT_DELTA, T_slots=DEFAULT_T_SLOTS, seed=GLOBAL_SEED)\n",
    "BASE_AGENT_RANGES = AgentRanges(\n",
    "    lam_sec_min=0.02, lam_sec_max=0.80,\n",
    "    f_local_min=0.8e9, f_local_max=2.4e9,\n",
    "    m_local_min=3e9,  m_local_max=8e9\n",
    ")\n",
    "BASE_TASK_DIST = TaskFeatureDist()\n",
    "\n",
    "SCENARIOS: List[GlobalConfig] = [\n",
    "    GlobalConfig(\n",
    "        name=\"light\",\n",
    "        N_agents=18,\n",
    "        Episode=replace(BASE_EPISODE, seed=GLOBAL_SEED + 101),\n",
    "        AgentRanges=replace(BASE_AGENT_RANGES, lam_sec_min=0.01, lam_sec_max=0.05),\n",
    "        TaskDist=replace(BASE_TASK_DIST,\n",
    "            b_median=2.0, b_sigma_g=0.55,\n",
    "            rho_median=1.0e9, rho_sigma_g=0.45,\n",
    "            p_deadline=0.15, deadline_min=0.8, deadline_max=2.0,\n",
    "            p_non_atomic=0.25, split_ratio_min=0.25, split_ratio_max=0.75)\n",
    "    ),\n",
    "    GlobalConfig(\n",
    "        name=\"moderate\",\n",
    "        N_agents=18,\n",
    "        Episode=replace(BASE_EPISODE, seed=GLOBAL_SEED + 202),\n",
    "        AgentRanges=replace(BASE_AGENT_RANGES, lam_sec_min=0.05, lam_sec_max=0.20),\n",
    "        TaskDist=replace(BASE_TASK_DIST,\n",
    "            b_median=3.0, b_sigma_g=0.60,\n",
    "            rho_median=1.2e9, rho_sigma_g=0.50,\n",
    "            p_deadline=0.25, deadline_min=0.5, deadline_max=1.5,\n",
    "            p_non_atomic=0.35, split_ratio_min=0.30, split_ratio_max=0.80)\n",
    "    ),\n",
    "    GlobalConfig(\n",
    "        name=\"heavy\",\n",
    "        N_agents=18,\n",
    "        Episode=replace(BASE_EPISODE, seed=GLOBAL_SEED + 303),\n",
    "        AgentRanges=replace(BASE_AGENT_RANGES, lam_sec_min=0.20, lam_sec_max=0.80),\n",
    "        TaskDist=replace(BASE_TASK_DIST,\n",
    "            b_median=5.0, b_sigma_g=0.70,\n",
    "            rho_median=1.5e9,  rho_sigma_g=0.55,\n",
    "            p_deadline=0.35,   deadline_min=0.3,     deadline_max=1.0,\n",
    "            p_non_atomic=0.45, split_ratio_min=0.40, split_ratio_max=0.85)\n",
    "    )\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# main driver\n",
    "# -------------------------\n",
    "def main_generate(cfg: GlobalConfig, episodes: int = 1, out_root: str = \"./datasets\") -> Dict[str, str]:\n",
    "    \"\"\"Generate 'episodes' episodes for one scenario (fixed agent pool per scenario).\"\"\"\n",
    "    out_dir = os.path.join(out_root, cfg.name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # build agents once per scenario to keep them consistent across its episodes\n",
    "    rng_agents = np.random.default_rng(cfg.Episode.seed + 10_000)\n",
    "    agents = build_agents(cfg, rng_agents)\n",
    "\n",
    "    all_paths: Dict[str, str] = {}\n",
    "    for ep in range(episodes):\n",
    "        dfs = run_episode(cfg, agents, episode_id=ep)\n",
    "        paths = save_dataset(dfs, out_dir=out_dir)\n",
    "        summarize_and_plot(dfs, out_dir=out_dir)\n",
    "\n",
    "    meta_path = save_meta(cfg, out_dir=out_dir)\n",
    "    all_paths[\"meta\"] = meta_path\n",
    "    return all_paths\n",
    "\n",
    "def generate_all_scenarios(episodes_each: int = 1, out_root: str = \"./datasets\") -> Dict[str, Dict[str, str]]:\n",
    "    results: Dict[str, Dict[str, str]] = {}\n",
    "    for cfg in SCENARIOS:\n",
    "        results[cfg.name] = main_generate(cfg, episodes=episodes_each, out_root=out_root)\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # change episodes_each if you want multiple episodes per scenario\n",
    "    out = generate_all_scenarios(episodes_each=1, out_root=\"./datasets\")\n",
    "    print(json.dumps(out, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
